{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "# Cross validation example\n",
    "\n",
    "Cross validation can provide a better estimate of performance than a single split of your dataset. We have often observed that running Glimr with a single split produces a configuration that is highly overfit to this validation dataset, and that generalizes poorly to independent testing data. Glimr provides tools to perform cross validation to address this.\n",
    "\n",
    "When performing a cross validation, each model configuration is run in multiple trials with different cross-validation folds. Post experiment analysis can be used to identify the model configuration with the best average performance, or to build ensembles of models trained on different portions of the data.\n",
    "\n",
    "Revisiting the MNIST example, we demonstrate the formulation of cross validation dataloaders and the experiment analysis tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "## Create a cross validation data loader\n",
    "\n",
    "Cross validation requires a dataloader that accepts `cv_index` and `cv_folds` arguments that represent the fold index and number of folds. The `Search` class will populate your data search space with these arguments automatically.\n",
    "\n",
    "This data loader below uses stratified k-fold cross validation to build class-balanced folds. Since each trial will run a separate fold, random arguments like the split seed must be fixed across trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def cv_dataloader(batch_size, random_brightness, max_delta, cv_index, cv_folds):\n",
    "    \"\"\"Cross-validation MNIST data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        The number of samples to batch.\n",
    "    random_brightness : bool\n",
    "        Whether to apply random brightness augmentation.\n",
    "    max_delta : float\n",
    "        The random brightness augmentation parameter.\n",
    "    cv_index : int\n",
    "        The index of the requested fold.\n",
    "    cv_folds : int\n",
    "        The number of folds in the cross validation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_ds : tf.data.Dataset\n",
    "        A batched training set for fold `cv_index` used to build models.\n",
    "    validation_ds : tf.data.Dataset.\n",
    "        A batched validation set for fold `cv_index` used to evaluate models.\n",
    "    \"\"\"\n",
    "\n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "    # combine training, validation sets\n",
    "    merged = (\n",
    "        np.concatenate((train[0], validation[0]), axis=0),\n",
    "        np.concatenate((train[1], validation[1]), axis=0),\n",
    "    )\n",
    "\n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(\n",
    "            features.shape[0], features.shape[1] * features.shape[2]\n",
    "        )\n",
    "\n",
    "    # stratified k-fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=0)\n",
    "    train_index, validation_index = [\n",
    "        (i, o) for (i, o) in skf.split(merged[0], merged[1])\n",
    "    ][cv_index]\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(merged[0][train_index]), tf.float32) / 255.0\n",
    "    train_labels = merged[1][train_index]\n",
    "    validation_features = (\n",
    "        tf.cast(mnist_flat(merged[0][validation_index]), tf.float32) / 255.0\n",
    "    )\n",
    "    validation_labels = merged[1][validation_index]\n",
    "\n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "\n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    validation_ds = validation_ds.batch(batch_size)\n",
    "\n",
    "    # apply augmentation\n",
    "    if random_brightness:\n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta), y)\n",
    "        )\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "# Setting up the search space and model building funciton\n",
    "\n",
    "The search space and model building function are not impacted by the choice to use cross validation. Reuse everything from the starter example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "from glimr.optimization import optimization_space\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "# layer 1 hyperparameters\n",
    "activations = tune.choice(\n",
    "    [\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"]\n",
    ")\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": tune.choice([64, 48, 32, 16]),\n",
    "}\n",
    "\n",
    "# loss hyperparameters\n",
    "loss = tune.choice(\n",
    "    [\n",
    "        {\"name\": \"categorical_hinge\", \"loss\": tf.keras.losses.CategoricalHinge},\n",
    "        {\n",
    "            \"name\": \"categorical_crossentropy\",\n",
    "            \"loss\": tf.keras.losses.CategoricalCrossentropy,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# metrics for reporting - fixed non-hyperparameters\n",
    "metrics = {\n",
    "    \"name\": \"auc\",\n",
    "    \"metric\": tf.keras.metrics.AUC,\n",
    "    \"kwargs\": {\"from_logits\": True},\n",
    "}\n",
    "\n",
    "# task layer hyperparameters\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": 10,\n",
    "    \"loss\": loss,\n",
    "    \"loss_weight\": (1.0,),\n",
    "    \"metrics\": metrics,\n",
    "}\n",
    "\n",
    "# optimizer search space\n",
    "optimization = optimization_space()\n",
    "\n",
    "# data loader keyword arguments to control loading, augmentation, and batching\n",
    "data = {\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"random_brightness\": tune.choice(\n",
    "        [True, False]\n",
    "    ),  # whether to perform random brightness transformation\n",
    "    \"max_delta\": tune.quniform(0.01, 0.15, 0.01),\n",
    "}\n",
    "\n",
    "\n",
    "# model builder function\n",
    "def builder(config):\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "        return x\n",
    "\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "    x = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"layer1\"][\"units\"],\n",
    "        config[\"layer1\"][\"activation\"],\n",
    "        config[\"layer1\"][\"dropout\"],\n",
    "        \"layer1\",\n",
    "    )\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"tasks\"][task_name][\"units\"],\n",
    "        config[\"tasks\"][task_name][\"activation\"],\n",
    "        config[\"tasks\"][task_name][\"dropout\"],\n",
    "        task_name,\n",
    "    )\n",
    "    named = {f\"{task_name}\": output}\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "    losses, loss_weights = keras_losses(config)\n",
    "    metrics = keras_metrics(config)\n",
    "\n",
    "    return model, losses, loss_weights, metrics\n",
    "\n",
    "\n",
    "# assemble the search space\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\"mnist\": task},\n",
    "    \"data\": data,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "# Using Search with `cv_folds`\n",
    "\n",
    "Creating a `Search` instance with the `cv_folds` argument is all that is needed to instruct `ray.tune` to perform a cross validation.\n",
    "\n",
    "Since `cv_folds` trials will be run for each configuration, the total number of trials will be `cv_folds` * `num_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264a521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-14 20:35:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:13:23.06        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.2/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 40.000: None | Iter 10.000: 0.6836938261985779<br>Logical resource usage: 1.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  data/batch_size</th><th style=\"text-align: right;\">  data/cv_index</th><th style=\"text-align: right;\">  data/max_delta</th><th>data/random_brightne\n",
       "ss      </th><th>layer1/activation  </th><th style=\"text-align: right;\">  layer1/dropout</th><th style=\"text-align: right;\">  layer1/units</th><th style=\"text-align: right;\">  optimization/beta_1</th><th style=\"text-align: right;\">  optimization/beta_2</th><th style=\"text-align: right;\">     optimization/ema_mom\n",
       "entum</th><th style=\"text-align: right;\">  optimization/ema_ove\n",
       "rwrite_frequency</th><th style=\"text-align: right;\">        optimization/learnin\n",
       "g_rate</th><th>optimization/method  </th><th style=\"text-align: right;\">     optimization/momentu\n",
       "m</th><th style=\"text-align: right;\">  optimization/rho</th><th>optimization/use_ema  </th><th>tasks/mnist/activati\n",
       "on         </th><th style=\"text-align: right;\">  tasks/mnist/dropout</th><th>tasks/mnist/loss    </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mnist_auc</th><th style=\"text-align: right;\">  mnist_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_cc513_00000</td><td>TERMINATED</td><td>127.0.0.1:26113</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.14</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00801</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.68</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_4580</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        284.843 </td><td style=\"text-align: right;\">   0.532334</td><td style=\"text-align: right;\"> 0.967834   </td></tr>\n",
       "<tr><td>trainable_cc513_00001</td><td>TERMINATED</td><td>127.0.0.1:26114</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.14</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00801</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.68</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_7b40</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">        404.57  </td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1          </td></tr>\n",
       "<tr><td>trainable_cc513_00002</td><td>TERMINATED</td><td>127.0.0.1:26115</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.14</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00801</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.68</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_adc0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        278.392 </td><td style=\"text-align: right;\">   0.525885</td><td style=\"text-align: right;\"> 0.978172   </td></tr>\n",
       "<tr><td>trainable_cc513_00003</td><td>TERMINATED</td><td>127.0.0.1:26116</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.14</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00801</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.68</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_6240</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">        404.191 </td><td style=\"text-align: right;\">   0.577989</td><td style=\"text-align: right;\"> 1.13911    </td></tr>\n",
       "<tr><td>trainable_cc513_00004</td><td>TERMINATED</td><td>127.0.0.1:26117</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.14</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00801</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.68</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_b6c0</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        233.65  </td><td style=\"text-align: right;\">   0.524599</td><td style=\"text-align: right;\"> 0.976114   </td></tr>\n",
       "<tr><td>trainable_cc513_00005</td><td>TERMINATED</td><td>127.0.0.1:26118</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.06</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00121</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.78</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_ee40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         50.9296</td><td style=\"text-align: right;\">   0.457667</td><td style=\"text-align: right;\"> 7.61078    </td></tr>\n",
       "<tr><td>trainable_cc513_00006</td><td>TERMINATED</td><td>127.0.0.1:26119</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.06</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00121</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.78</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_6280</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         50.6545</td><td style=\"text-align: right;\">   0.468607</td><td style=\"text-align: right;\"> 7.69124    </td></tr>\n",
       "<tr><td>trainable_cc513_00007</td><td>TERMINATED</td><td>127.0.0.1:26120</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.06</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00121</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.78</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_c1c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         50.7243</td><td style=\"text-align: right;\">   0.481231</td><td style=\"text-align: right;\"> 7.24291    </td></tr>\n",
       "<tr><td>trainable_cc513_00008</td><td>TERMINATED</td><td>127.0.0.1:26121</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.06</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00121</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.78</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_f500</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         98.1939</td><td style=\"text-align: right;\">   0.391374</td><td style=\"text-align: right;\"> 8.03516    </td></tr>\n",
       "<tr><td>trainable_cc513_00009</td><td>TERMINATED</td><td>127.0.0.1:26122</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.06</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00121</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.78</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_e840</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         78.5442</td><td style=\"text-align: right;\">   0.458898</td><td style=\"text-align: right;\"> 6.91978    </td></tr>\n",
       "<tr><td>trainable_cc513_00010</td><td>TERMINATED</td><td>127.0.0.1:26144</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00534</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.6 </td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_19c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         93.2999</td><td style=\"text-align: right;\">   0.495875</td><td style=\"text-align: right;\"> 7.69507    </td></tr>\n",
       "<tr><td>trainable_cc513_00011</td><td>TERMINATED</td><td>127.0.0.1:26145</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00534</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.6 </td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_1b40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         93.3841</td><td style=\"text-align: right;\">   0.51153 </td><td style=\"text-align: right;\"> 8.44412    </td></tr>\n",
       "<tr><td>trainable_cc513_00012</td><td>TERMINATED</td><td>127.0.0.1:26146</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00534</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.6 </td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_1140</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        131.477 </td><td style=\"text-align: right;\">   0.540977</td><td style=\"text-align: right;\"> 6.49432    </td></tr>\n",
       "<tr><td>trainable_cc513_00013</td><td>TERMINATED</td><td>127.0.0.1:26152</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00534</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.6 </td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_f580</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        109.042 </td><td style=\"text-align: right;\">   0.540435</td><td style=\"text-align: right;\"> 7.31921    </td></tr>\n",
       "<tr><td>trainable_cc513_00014</td><td>TERMINATED</td><td>127.0.0.1:26156</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00534</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.6 </td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_0d40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        109.016 </td><td style=\"text-align: right;\">   0.499523</td><td style=\"text-align: right;\"> 8.49593    </td></tr>\n",
       "<tr><td>trainable_cc513_00015</td><td>TERMINATED</td><td>127.0.0.1:26180</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.05</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00469</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.62</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_29c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         89.631 </td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1.19209e-07</td></tr>\n",
       "<tr><td>trainable_cc513_00016</td><td>TERMINATED</td><td>127.0.0.1:26182</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.05</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00469</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.62</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_2000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         90.0291</td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1.19209e-07</td></tr>\n",
       "<tr><td>trainable_cc513_00017</td><td>TERMINATED</td><td>127.0.0.1:26194</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.05</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00469</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.62</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_dec0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         89.7414</td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1.19209e-07</td></tr>\n",
       "<tr><td>trainable_cc513_00018</td><td>TERMINATED</td><td>127.0.0.1:26197</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.05</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00469</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.62</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_f300</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         89.7909</td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1.19209e-07</td></tr>\n",
       "<tr><td>trainable_cc513_00019</td><td>TERMINATED</td><td>127.0.0.1:26205</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.05</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00469</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.62</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_a080</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         90.6657</td><td style=\"text-align: right;\">   0.5     </td><td style=\"text-align: right;\"> 1.19209e-07</td></tr>\n",
       "<tr><td>trainable_cc513_00020</td><td>TERMINATED</td><td>127.0.0.1:26208</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00103</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_2f40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         48.681 </td><td style=\"text-align: right;\">   0.970276</td><td style=\"text-align: right;\"> 0.318416   </td></tr>\n",
       "<tr><td>trainable_cc513_00021</td><td>TERMINATED</td><td>127.0.0.1:26233</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00103</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_dd00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.2794</td><td style=\"text-align: right;\">   0.969539</td><td style=\"text-align: right;\"> 0.309341   </td></tr>\n",
       "<tr><td>trainable_cc513_00022</td><td>TERMINATED</td><td>127.0.0.1:26234</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00103</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_fa00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.3986</td><td style=\"text-align: right;\">   0.970445</td><td style=\"text-align: right;\"> 0.312068   </td></tr>\n",
       "<tr><td>trainable_cc513_00023</td><td>TERMINATED</td><td>127.0.0.1:26341</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00103</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_df40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.7402</td><td style=\"text-align: right;\">   0.968701</td><td style=\"text-align: right;\"> 0.313976   </td></tr>\n",
       "<tr><td>trainable_cc513_00024</td><td>TERMINATED</td><td>127.0.0.1:26447</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00103</td><td>adam                 </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_fc80</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.6157</td><td style=\"text-align: right;\">   0.970632</td><td style=\"text-align: right;\"> 0.312806   </td></tr>\n",
       "<tr><td>trainable_cc513_00025</td><td>TERMINATED</td><td>127.0.0.1:26456</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00119</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_f900</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        142.911 </td><td style=\"text-align: right;\">   0.672126</td><td style=\"text-align: right;\"> 1.06405    </td></tr>\n",
       "<tr><td>trainable_cc513_00026</td><td>TERMINATED</td><td>127.0.0.1:26458</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00119</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_c100</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         46.3267</td><td style=\"text-align: right;\">   0.515086</td><td style=\"text-align: right;\"> 1.12427    </td></tr>\n",
       "<tr><td>trainable_cc513_00027</td><td>TERMINATED</td><td>127.0.0.1:26476</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00119</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_ca00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         46.0819</td><td style=\"text-align: right;\">   0.600374</td><td style=\"text-align: right;\"> 1.11956    </td></tr>\n",
       "<tr><td>trainable_cc513_00028</td><td>TERMINATED</td><td>127.0.0.1:26814</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00119</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_2c80</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        109.051 </td><td style=\"text-align: right;\">   0.573628</td><td style=\"text-align: right;\"> 1.09423    </td></tr>\n",
       "<tr><td>trainable_cc513_00029</td><td>TERMINATED</td><td>127.0.0.1:26943</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00119</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_d700</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         44.9526</td><td style=\"text-align: right;\">   0.529965</td><td style=\"text-align: right;\"> 1.13149    </td></tr>\n",
       "<tr><td>trainable_cc513_00030</td><td>TERMINATED</td><td>127.0.0.1:27001</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00108</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_5ec0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         84.8982</td><td style=\"text-align: right;\">   0.907175</td><td style=\"text-align: right;\"> 0.771732   </td></tr>\n",
       "<tr><td>trainable_cc513_00031</td><td>TERMINATED</td><td>127.0.0.1:27295</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00108</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_58c0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        127.605 </td><td style=\"text-align: right;\">   0.951481</td><td style=\"text-align: right;\"> 0.489976   </td></tr>\n",
       "<tr><td>trainable_cc513_00032</td><td>TERMINATED</td><td>127.0.0.1:27464</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00108</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_3480</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        169.006 </td><td style=\"text-align: right;\">   0.95385 </td><td style=\"text-align: right;\"> 0.507506   </td></tr>\n",
       "<tr><td>trainable_cc513_00033</td><td>TERMINATED</td><td>127.0.0.1:27543</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00108</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_e440</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">        150.749 </td><td style=\"text-align: right;\">   0.890729</td><td style=\"text-align: right;\"> 0.915194   </td></tr>\n",
       "<tr><td>trainable_cc513_00034</td><td>TERMINATED</td><td>127.0.0.1:27672</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00108</td><td>rms                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_fa80</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        170.029 </td><td style=\"text-align: right;\">   0.852569</td><td style=\"text-align: right;\"> 1.13618    </td></tr>\n",
       "<tr><td>trainable_cc513_00035</td><td>TERMINATED</td><td>127.0.0.1:28074</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00637</td><td>rms                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.57</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_8640</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        226.776 </td><td style=\"text-align: right;\">   0.659915</td><td style=\"text-align: right;\"> 7.07653    </td></tr>\n",
       "<tr><td>trainable_cc513_00036</td><td>TERMINATED</td><td>127.0.0.1:28122</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00637</td><td>rms                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.57</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_db80</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        276.987 </td><td style=\"text-align: right;\">   0.736935</td><td style=\"text-align: right;\"> 5.62525    </td></tr>\n",
       "<tr><td>trainable_cc513_00037</td><td>TERMINATED</td><td>127.0.0.1:28123</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00637</td><td>rms                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.57</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_d540</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        384.09  </td><td style=\"text-align: right;\">   0.72191 </td><td style=\"text-align: right;\"> 7.84145    </td></tr>\n",
       "<tr><td>trainable_cc513_00038</td><td>TERMINATED</td><td>127.0.0.1:28141</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00637</td><td>rms                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.57</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_91c0</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">        356.026 </td><td style=\"text-align: right;\">   0.66168 </td><td style=\"text-align: right;\"> 7.88044    </td></tr>\n",
       "<tr><td>trainable_cc513_00039</td><td>TERMINATED</td><td>127.0.0.1:28146</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00637</td><td>rms                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.57</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_4780</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        326.633 </td><td style=\"text-align: right;\">   0.62312 </td><td style=\"text-align: right;\"> 9.25565    </td></tr>\n",
       "<tr><td>trainable_cc513_00040</td><td>TERMINATED</td><td>127.0.0.1:28148</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.63</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.0096 </td><td>adagrad              </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_c580</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        178.92  </td><td style=\"text-align: right;\">   0.982294</td><td style=\"text-align: right;\"> 0.256924   </td></tr>\n",
       "<tr><td>trainable_cc513_00041</td><td>TERMINATED</td><td>127.0.0.1:28155</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.63</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.0096 </td><td>adagrad              </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_ba80</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        182.139 </td><td style=\"text-align: right;\">   0.982922</td><td style=\"text-align: right;\"> 0.248843   </td></tr>\n",
       "<tr><td>trainable_cc513_00042</td><td>TERMINATED</td><td>127.0.0.1:28174</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.63</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.0096 </td><td>adagrad              </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_e740</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        179.001 </td><td style=\"text-align: right;\">   0.982863</td><td style=\"text-align: right;\"> 0.250941   </td></tr>\n",
       "<tr><td>trainable_cc513_00043</td><td>TERMINATED</td><td>127.0.0.1:28178</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.63</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.0096 </td><td>adagrad              </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_2f00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        179.399 </td><td style=\"text-align: right;\">   0.983242</td><td style=\"text-align: right;\"> 0.252438   </td></tr>\n",
       "<tr><td>trainable_cc513_00044</td><td>TERMINATED</td><td>127.0.0.1:28181</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.63</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.0096 </td><td>adagrad              </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_a980</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        175.948 </td><td style=\"text-align: right;\">   0.982544</td><td style=\"text-align: right;\"> 0.253214   </td></tr>\n",
       "<tr><td>trainable_cc513_00045</td><td>TERMINATED</td><td>127.0.0.1:28185</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00231</td><td>sgd                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.55</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_a440</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.1138</td><td style=\"text-align: right;\">   0.787496</td><td style=\"text-align: right;\"> 3.16309    </td></tr>\n",
       "<tr><td>trainable_cc513_00046</td><td>TERMINATED</td><td>127.0.0.1:28189</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00231</td><td>sgd                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.55</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_03c0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         72.6276</td><td style=\"text-align: right;\">   0.53678 </td><td style=\"text-align: right;\"> 9.19242    </td></tr>\n",
       "<tr><td>trainable_cc513_00047</td><td>TERMINATED</td><td>127.0.0.1:28194</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00231</td><td>sgd                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.55</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_8340</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         74.9263</td><td style=\"text-align: right;\">   0.488375</td><td style=\"text-align: right;\">10.7541     </td></tr>\n",
       "<tr><td>trainable_cc513_00048</td><td>TERMINATED</td><td>127.0.0.1:28207</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00231</td><td>sgd                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.55</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_8b40</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         52.8083</td><td style=\"text-align: right;\">   0.556959</td><td style=\"text-align: right;\"> 8.17928    </td></tr>\n",
       "<tr><td>trainable_cc513_00049</td><td>TERMINATED</td><td>127.0.0.1:28209</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00231</td><td>sgd                  </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.55</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_2440</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         44.2663</td><td style=\"text-align: right;\">   0.661416</td><td style=\"text-align: right;\"> 5.8941     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 20:23:32,176\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:23:32,395\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:23:32,525\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:24:00,316\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:24:19,758\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:25:13,467\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:25:13,647\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:25:51,669\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:25:57,989\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:26:18,169\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:26:35,257\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:27:08,487\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:27:09,018\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:27:19,882\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:27:26,613\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:27:29,612\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:27:32,163\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:27:35,801\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:27:57,041\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:28:03,504\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:03,965\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:15,943\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:22,447\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:24,734\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:30,837\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:28:55,453\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:29:25,838\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:29:26,059\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:29:37,649\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:29:54,764\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:30:00,185\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:30:31,677\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:31:03,940\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:31:19,170\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:31:29,489\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:32:52,350\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:33:07,229\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:33:43,468\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:34:04,809\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:34:11,421\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:34:12,090\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:34:28,104\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:34:29,896\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:34:35,304\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-14 20:35:03,435\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:06,656\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:09,139\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:30,164\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:41,933\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:58,444\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-14 20:35:58,498\tINFO tune.py:1148 -- Total run time: 803.60 seconds (803.05 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# pass `cv_folds` parameter to Search for cross validation\n",
    "tuner = Search(space, builder, cv_dataloader, \"mnist_auc\", cv_folds=5)\n",
    "\n",
    "# make a temporary directory to store outputs - cleanup at end\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run trials using default settings\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"cross_validation\", num_samples=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e3a03-73e4-48f0-9123-11d26aa3fa69",
   "metadata": {},
   "source": [
    "## Create an experiment DataFrame for analysis\n",
    "\n",
    "`glimr.analysis` contains functions for building Pandas DataFrames that contain trial information like performance, checkpoint location, and cross validation information. These DataFrames can be used for visualizaton or for analysis tasks like identifing the best performing checkpoints in each fold, or the configuration with the best average performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3efc79b9-01d7-44a9-bf0b-a57187e2a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config_enum\n",
       "0    0.500000\n",
       "1    0.511530\n",
       "2    0.907175\n",
       "3    0.589370\n",
       "4    0.982863\n",
       "5    0.781657\n",
       "6    0.473656\n",
       "7    0.573628\n",
       "8    0.692875\n",
       "9    0.970612\n",
       "Name: mnist_auc, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from glimr.analysis import default_checkpoints, experiment_table\n",
    "\n",
    "# create a dataframe of checkpointed epochs from all trials (folds + configurations)\n",
    "exp_dir = temp_dir.name + \"/cross_validation\"\n",
    "df = experiment_table(exp_dir, checkpointed=True)\n",
    "\n",
    "# filter table to select checkpoints that correspond to best epoch\n",
    "df = default_checkpoints(df)\n",
    "\n",
    "# configuraton median performance across folds\n",
    "print(df.groupby(\"config_enum\")[\"mnist_auc\"].apply(np.median))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
