{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "# Cross validation example\n",
    "\n",
    "Cross validation can provide a better estimate of performance than a single split of your dataset. We have often observed that running Glimr with a single split produces a configuration that is highly overfit to this validation dataset, and that generalizes poorly to independent testing data. Glimr provides tools to perform cross validation to address this.\n",
    "\n",
    "When performing a cross validation, each model configuration is run in multiple trials with different cross-validation folds. Post experiment analysis can be used to identify the model configuration with the best average performance, or to build ensembles of models trained on different portions of the data.\n",
    "\n",
    "Revisiting the MNIST example, we demonstrate the formulation of cross validation dataloaders and the experiment analysis tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "## Create a cross validation data loader\n",
    "\n",
    "Cross validation requires a dataloader that accepts `cv_index` and `cv_folds` arguments that represent the fold index and number of folds. The `Search` class will populate your data search space with these arguments automatically.\n",
    "\n",
    "This data loader below uses stratified k-fold cross validation to build class-balanced folds. Since each trial will run a separate fold, random arguments like the split seed must be fixed across trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def cv_dataloader(batch_size, random_brightness, max_delta, cv_index, cv_folds):\n",
    "    \"\"\"Cross-validation MNIST data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        The number of samples to batch.\n",
    "    random_brightness : bool\n",
    "        Whether to apply random brightness augmentation.\n",
    "    max_delta : float\n",
    "        The random brightness augmentation parameter.\n",
    "    cv_index : int\n",
    "        The index of the requested fold.\n",
    "    cv_folds : int\n",
    "        The number of folds in the cross validation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_ds : tf.data.Dataset\n",
    "        A batched training set for fold `cv_index` used to build models.\n",
    "    validation_ds : tf.data.Dataset.\n",
    "        A batched validation set for fold `cv_index` used to evaluate models.\n",
    "    \"\"\"\n",
    "\n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "    # combine training, validation sets\n",
    "    merged = (\n",
    "        np.concatenate((train[0], validation[0]), axis=0),\n",
    "        np.concatenate((train[1], validation[1]), axis=0),\n",
    "    )\n",
    "\n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(\n",
    "            features.shape[0], features.shape[1] * features.shape[2]\n",
    "        )\n",
    "\n",
    "    # stratified k-fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=0)\n",
    "    train_index, validation_index = [\n",
    "        (i, o) for (i, o) in skf.split(merged[0], merged[1])\n",
    "    ][cv_index]\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(merged[0][train_index]), tf.float32) / 255.0\n",
    "    train_labels = merged[1][train_index]\n",
    "    validation_features = (\n",
    "        tf.cast(mnist_flat(merged[0][validation_index]), tf.float32) / 255.0\n",
    "    )\n",
    "    validation_labels = merged[1][validation_index]\n",
    "\n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "\n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    validation_ds = validation_ds.batch(batch_size)\n",
    "\n",
    "    # apply augmentation\n",
    "    if random_brightness:\n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta), y)\n",
    "        )\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "# Setting up the search space and model building funciton\n",
    "\n",
    "The search space and model building function are not impacted by the choice to use cross validation. Reuse everything from the starter example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "from glimr.optimization import optimization_space\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "# layer 1 hyperparameters\n",
    "activations = tune.choice(\n",
    "    [\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"]\n",
    ")\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": tune.choice([64, 48, 32, 16]),\n",
    "}\n",
    "\n",
    "# loss hyperparameters\n",
    "loss = tune.choice(\n",
    "    [\n",
    "        {\"name\": \"categorical_hinge\", \"loss\": tf.keras.losses.CategoricalHinge},\n",
    "        {\n",
    "            \"name\": \"categorical_crossentropy\",\n",
    "            \"loss\": tf.keras.losses.CategoricalCrossentropy,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# metrics for reporting - fixed non-hyperparameters\n",
    "metrics = {\n",
    "    \"name\": \"auc\",\n",
    "    \"metric\": tf.keras.metrics.AUC,\n",
    "    \"kwargs\": {\"from_logits\": True},\n",
    "}\n",
    "\n",
    "# task layer hyperparameters\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": 10,\n",
    "    \"loss\": loss,\n",
    "    \"loss_weight\": (1.0,),\n",
    "    \"metrics\": metrics,\n",
    "}\n",
    "\n",
    "# optimizer search space\n",
    "optimization = optimization_space()\n",
    "\n",
    "# data loader keyword arguments to control loading, augmentation, and batching\n",
    "data = {\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"random_brightness\": tune.choice(\n",
    "        [True, False]\n",
    "    ),  # whether to perform random brightness transformation\n",
    "    \"max_delta\": tune.quniform(0.01, 0.15, 0.01),\n",
    "}\n",
    "\n",
    "\n",
    "# model builder function\n",
    "def builder(config):\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "        return x\n",
    "\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "    x = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"layer1\"][\"units\"],\n",
    "        config[\"layer1\"][\"activation\"],\n",
    "        config[\"layer1\"][\"dropout\"],\n",
    "        \"layer1\",\n",
    "    )\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"tasks\"][task_name][\"units\"],\n",
    "        config[\"tasks\"][task_name][\"activation\"],\n",
    "        config[\"tasks\"][task_name][\"dropout\"],\n",
    "        task_name,\n",
    "    )\n",
    "    named = {f\"{task_name}\": output}\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "    losses, loss_weights = keras_losses(config)\n",
    "    metrics = keras_metrics(config)\n",
    "\n",
    "    return model, losses, loss_weights, metrics\n",
    "\n",
    "\n",
    "# assemble the search space\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\"mnist\": task},\n",
    "    \"data\": data,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "# Using Search with `cv_folds`\n",
    "\n",
    "Creating a `Search` instance with the `cv_folds` argument is all that is needed to instruct `ray.tune` to perform a cross validation.\n",
    "\n",
    "Since `cv_folds` trials will be run for each configuration, the total number of trials will be `cv_folds` * `num_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264a521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-16 10:21:17</td></tr>\n",
       "<tr><td>Running for: </td><td>00:10:13.94        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.8/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 40.000: None | Iter 10.000: 0.6249027848243713<br>Logical resource usage: 1.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  data/batch_size</th><th style=\"text-align: right;\">  data/cv_index</th><th style=\"text-align: right;\">  data/max_delta</th><th>data/random_brightne\n",
       "ss      </th><th>layer1/activation  </th><th style=\"text-align: right;\">  layer1/dropout</th><th style=\"text-align: right;\">  layer1/units</th><th style=\"text-align: right;\">  optimization/beta_1</th><th style=\"text-align: right;\">  optimization/beta_2</th><th style=\"text-align: right;\">     optimization/ema_mom\n",
       "entum</th><th style=\"text-align: right;\">  optimization/ema_ove\n",
       "rwrite_frequency</th><th style=\"text-align: right;\">        optimization/learnin\n",
       "g_rate</th><th>optimization/method  </th><th style=\"text-align: right;\">     optimization/momentu\n",
       "m</th><th style=\"text-align: right;\">  optimization/rho</th><th>optimization/use_ema  </th><th>tasks/mnist/activati\n",
       "on       </th><th style=\"text-align: right;\">  tasks/mnist/dropout</th><th>tasks/mnist/loss    </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mnist_auc</th><th style=\"text-align: right;\">  mnist_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_b3782_00000</td><td>TERMINATED</td><td>127.0.0.1:44598</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.07</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00579</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.99</td><td>False                 </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_2ec0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        164.773 </td><td style=\"text-align: right;\">   0.981891</td><td style=\"text-align: right;\">    0.272438</td></tr>\n",
       "<tr><td>trainable_b3782_00001</td><td>TERMINATED</td><td>127.0.0.1:44599</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.07</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00579</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.99</td><td>False                 </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_1a40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        158.709 </td><td style=\"text-align: right;\">   0.982476</td><td style=\"text-align: right;\">    0.264139</td></tr>\n",
       "<tr><td>trainable_b3782_00002</td><td>TERMINATED</td><td>127.0.0.1:44600</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.07</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00579</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.99</td><td>False                 </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_18c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        158.567 </td><td style=\"text-align: right;\">   0.982645</td><td style=\"text-align: right;\">    0.265305</td></tr>\n",
       "<tr><td>trainable_b3782_00003</td><td>TERMINATED</td><td>127.0.0.1:44601</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.07</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00579</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.99</td><td>False                 </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8bc0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        161.586 </td><td style=\"text-align: right;\">   0.982383</td><td style=\"text-align: right;\">    0.268057</td></tr>\n",
       "<tr><td>trainable_b3782_00004</td><td>TERMINATED</td><td>127.0.0.1:44602</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.07</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00579</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.99</td><td>False                 </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_21c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        158.595 </td><td style=\"text-align: right;\">   0.982253</td><td style=\"text-align: right;\">    0.267615</td></tr>\n",
       "<tr><td>trainable_b3782_00005</td><td>TERMINATED</td><td>127.0.0.1:44603</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00473</td><td>sgd                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_9b00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         42.6774</td><td style=\"text-align: right;\">   0.975802</td><td style=\"text-align: right;\">    0.353804</td></tr>\n",
       "<tr><td>trainable_b3782_00006</td><td>TERMINATED</td><td>127.0.0.1:44604</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00473</td><td>sgd                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8c00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         42.9652</td><td style=\"text-align: right;\">   0.976527</td><td style=\"text-align: right;\">    0.340146</td></tr>\n",
       "<tr><td>trainable_b3782_00007</td><td>TERMINATED</td><td>127.0.0.1:44605</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00473</td><td>sgd                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_a140</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         42.7899</td><td style=\"text-align: right;\">   0.976287</td><td style=\"text-align: right;\">    0.343468</td></tr>\n",
       "<tr><td>trainable_b3782_00008</td><td>TERMINATED</td><td>127.0.0.1:44606</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00473</td><td>sgd                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_a1c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         43.071 </td><td style=\"text-align: right;\">   0.975802</td><td style=\"text-align: right;\">    0.344816</td></tr>\n",
       "<tr><td>trainable_b3782_00009</td><td>TERMINATED</td><td>127.0.0.1:44607</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00473</td><td>sgd                  </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8140</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         43.1981</td><td style=\"text-align: right;\">   0.976469</td><td style=\"text-align: right;\">    0.343753</td></tr>\n",
       "<tr><td>trainable_b3782_00010</td><td>TERMINATED</td><td>127.0.0.1:44625</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.14</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.003  </td><td>adadelta             </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_6580</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.6124</td><td style=\"text-align: right;\">   0.584935</td><td style=\"text-align: right;\">    6.68379 </td></tr>\n",
       "<tr><td>trainable_b3782_00011</td><td>TERMINATED</td><td>127.0.0.1:44626</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.14</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.003  </td><td>adadelta             </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_4640</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">        160.167 </td><td style=\"text-align: right;\">   0.644128</td><td style=\"text-align: right;\">    6.34489 </td></tr>\n",
       "<tr><td>trainable_b3782_00012</td><td>TERMINATED</td><td>127.0.0.1:44627</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.14</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.003  </td><td>adadelta             </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_5800</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         60.3165</td><td style=\"text-align: right;\">   0.508036</td><td style=\"text-align: right;\">    7.43811 </td></tr>\n",
       "<tr><td>trainable_b3782_00013</td><td>TERMINATED</td><td>127.0.0.1:44628</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.14</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.003  </td><td>adadelta             </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_a240</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         47.4091</td><td style=\"text-align: right;\">   0.529896</td><td style=\"text-align: right;\">    8.01085 </td></tr>\n",
       "<tr><td>trainable_b3782_00014</td><td>TERMINATED</td><td>127.0.0.1:44629</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.14</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.003  </td><td>adadelta             </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_5900</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         48.1262</td><td style=\"text-align: right;\">   0.493171</td><td style=\"text-align: right;\">    6.94869 </td></tr>\n",
       "<tr><td>trainable_b3782_00015</td><td>TERMINATED</td><td>127.0.0.1:44676</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00045</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.83</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_95c0</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         75.7924</td><td style=\"text-align: right;\">   0.938711</td><td style=\"text-align: right;\">    0.675069</td></tr>\n",
       "<tr><td>trainable_b3782_00016</td><td>TERMINATED</td><td>127.0.0.1:44677</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00045</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.83</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_cfc0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         86.0308</td><td style=\"text-align: right;\">   0.946132</td><td style=\"text-align: right;\">    0.666003</td></tr>\n",
       "<tr><td>trainable_b3782_00017</td><td>TERMINATED</td><td>127.0.0.1:44678</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00045</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.83</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_f5c0</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         76.253 </td><td style=\"text-align: right;\">   0.945256</td><td style=\"text-align: right;\">    0.665817</td></tr>\n",
       "<tr><td>trainable_b3782_00018</td><td>TERMINATED</td><td>127.0.0.1:44683</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00045</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.83</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_23c0</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         87.382 </td><td style=\"text-align: right;\">   0.946613</td><td style=\"text-align: right;\">    0.656014</td></tr>\n",
       "<tr><td>trainable_b3782_00019</td><td>TERMINATED</td><td>127.0.0.1:44775</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00045</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.83</td><td>True                  </td><td>linear</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_8f00</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         88.9792</td><td style=\"text-align: right;\">   0.939093</td><td style=\"text-align: right;\">    0.673396</td></tr>\n",
       "<tr><td>trainable_b3782_00020</td><td>TERMINATED</td><td>127.0.0.1:44777</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00242</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.61</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_5a40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         48.8554</td><td style=\"text-align: right;\">   0.445005</td><td style=\"text-align: right;\">    7.36085 </td></tr>\n",
       "<tr><td>trainable_b3782_00021</td><td>TERMINATED</td><td>127.0.0.1:44781</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00242</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.61</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_a880</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         49.1638</td><td style=\"text-align: right;\">   0.505311</td><td style=\"text-align: right;\">    7.64172 </td></tr>\n",
       "<tr><td>trainable_b3782_00022</td><td>TERMINATED</td><td>127.0.0.1:44792</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00242</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.61</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_26c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         49.5464</td><td style=\"text-align: right;\">   0.478471</td><td style=\"text-align: right;\">    7.72336 </td></tr>\n",
       "<tr><td>trainable_b3782_00023</td><td>TERMINATED</td><td>127.0.0.1:44797</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00242</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.61</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_8dc0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         49.3604</td><td style=\"text-align: right;\">   0.493304</td><td style=\"text-align: right;\">    6.86962 </td></tr>\n",
       "<tr><td>trainable_b3782_00024</td><td>TERMINATED</td><td>127.0.0.1:44802</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00242</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.61</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_abc0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         50.3622</td><td style=\"text-align: right;\">   0.485667</td><td style=\"text-align: right;\">    7.01126 </td></tr>\n",
       "<tr><td>trainable_b3782_00025</td><td>TERMINATED</td><td>127.0.0.1:44803</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00057</td><td>adadelta             </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_2140</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         91.8363</td><td style=\"text-align: right;\">   0.571921</td><td style=\"text-align: right;\">    6.12101 </td></tr>\n",
       "<tr><td>trainable_b3782_00026</td><td>TERMINATED</td><td>127.0.0.1:44807</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00057</td><td>adadelta             </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_3980</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         92.149 </td><td style=\"text-align: right;\">   0.502673</td><td style=\"text-align: right;\">    7.33403 </td></tr>\n",
       "<tr><td>trainable_b3782_00027</td><td>TERMINATED</td><td>127.0.0.1:44810</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00057</td><td>adadelta             </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_b700</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         91.2002</td><td style=\"text-align: right;\">   0.495001</td><td style=\"text-align: right;\">    7.35522 </td></tr>\n",
       "<tr><td>trainable_b3782_00028</td><td>TERMINATED</td><td>127.0.0.1:44812</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00057</td><td>adadelta             </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_6640</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         91.1188</td><td style=\"text-align: right;\">   0.499501</td><td style=\"text-align: right;\">    6.78972 </td></tr>\n",
       "<tr><td>trainable_b3782_00029</td><td>TERMINATED</td><td>127.0.0.1:44815</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00057</td><td>adadelta             </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>elu   </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_e1c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         90.2132</td><td style=\"text-align: right;\">   0.480345</td><td style=\"text-align: right;\">    6.38867 </td></tr>\n",
       "<tr><td>trainable_b3782_00030</td><td>TERMINATED</td><td>127.0.0.1:44816</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.12</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_e300</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        166.463 </td><td style=\"text-align: right;\">   0.930037</td><td style=\"text-align: right;\">   14.7935  </td></tr>\n",
       "<tr><td>trainable_b3782_00031</td><td>TERMINATED</td><td>127.0.0.1:44819</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.12</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_1540</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        208.449 </td><td style=\"text-align: right;\">   0.935741</td><td style=\"text-align: right;\">   14.8188  </td></tr>\n",
       "<tr><td>trainable_b3782_00032</td><td>TERMINATED</td><td>127.0.0.1:44824</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.12</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_fe40</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        209.684 </td><td style=\"text-align: right;\">   0.934831</td><td style=\"text-align: right;\">   14.4123  </td></tr>\n",
       "<tr><td>trainable_b3782_00033</td><td>TERMINATED</td><td>127.0.0.1:44829</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.12</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_d080</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        209.941 </td><td style=\"text-align: right;\">   0.945925</td><td style=\"text-align: right;\">   14.821   </td></tr>\n",
       "<tr><td>trainable_b3782_00034</td><td>TERMINATED</td><td>127.0.0.1:44832</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.12</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">                 0.79</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adagrad              </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.51</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_2c00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        168.394 </td><td style=\"text-align: right;\">   0.945916</td><td style=\"text-align: right;\">   13.7577  </td></tr>\n",
       "<tr><td>trainable_b3782_00035</td><td>TERMINATED</td><td>127.0.0.1:44836</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00322</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_3d80</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        132.997 </td><td style=\"text-align: right;\">   0.638557</td><td style=\"text-align: right;\">   13.0527  </td></tr>\n",
       "<tr><td>trainable_b3782_00036</td><td>TERMINATED</td><td>127.0.0.1:44839</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00322</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_03c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         88.3621</td><td style=\"text-align: right;\">   0.584964</td><td style=\"text-align: right;\">   13.6891  </td></tr>\n",
       "<tr><td>trainable_b3782_00037</td><td>TERMINATED</td><td>127.0.0.1:44843</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00322</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_c740</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        110.542 </td><td style=\"text-align: right;\">   0.552943</td><td style=\"text-align: right;\">   12.6615  </td></tr>\n",
       "<tr><td>trainable_b3782_00038</td><td>TERMINATED</td><td>127.0.0.1:44845</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00322</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_3a40</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        215.279 </td><td style=\"text-align: right;\">   0.630349</td><td style=\"text-align: right;\">   13.2131  </td></tr>\n",
       "<tr><td>trainable_b3782_00039</td><td>TERMINATED</td><td>127.0.0.1:44847</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00322</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>relu  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_2740</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         89.6592</td><td style=\"text-align: right;\">   0.689899</td><td style=\"text-align: right;\">   14.0644  </td></tr>\n",
       "<tr><td>trainable_b3782_00040</td><td>TERMINATED</td><td>127.0.0.1:44857</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.62</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00533</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.58</td><td>True                  </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_3000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         92.4644</td><td style=\"text-align: right;\">   0.868625</td><td style=\"text-align: right;\">    0.336879</td></tr>\n",
       "<tr><td>trainable_b3782_00041</td><td>TERMINATED</td><td>127.0.0.1:44858</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.62</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00533</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.58</td><td>True                  </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_0540</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         92.648 </td><td style=\"text-align: right;\">   0.836012</td><td style=\"text-align: right;\">    0.367212</td></tr>\n",
       "<tr><td>trainable_b3782_00042</td><td>TERMINATED</td><td>127.0.0.1:44862</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.62</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00533</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.58</td><td>True                  </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_9540</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         91.1365</td><td style=\"text-align: right;\">   0.800537</td><td style=\"text-align: right;\">    0.44639 </td></tr>\n",
       "<tr><td>trainable_b3782_00043</td><td>TERMINATED</td><td>127.0.0.1:44869</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.62</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00533</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.58</td><td>True                  </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_21c0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         88.9861</td><td style=\"text-align: right;\">   0.871193</td><td style=\"text-align: right;\">    0.30832 </td></tr>\n",
       "<tr><td>trainable_b3782_00044</td><td>TERMINATED</td><td>127.0.0.1:44870</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.62</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00533</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.58</td><td>True                  </td><td>gelu  </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8ac0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         88.9092</td><td style=\"text-align: right;\">   0.74183 </td><td style=\"text-align: right;\">    0.531207</td></tr>\n",
       "<tr><td>trainable_b3782_00045</td><td>TERMINATED</td><td>127.0.0.1:44887</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00756</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.66</td><td>False                 </td><td>selu  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_cd80</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        140.336 </td><td style=\"text-align: right;\">   0.978927</td><td style=\"text-align: right;\">    0.330299</td></tr>\n",
       "<tr><td>trainable_b3782_00046</td><td>TERMINATED</td><td>127.0.0.1:44891</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00756</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.66</td><td>False                 </td><td>selu  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_fe40</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        143.24  </td><td style=\"text-align: right;\">   0.980768</td><td style=\"text-align: right;\">    0.295676</td></tr>\n",
       "<tr><td>trainable_b3782_00047</td><td>TERMINATED</td><td>127.0.0.1:44894</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00756</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.66</td><td>False                 </td><td>selu  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_7f00</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        136.1   </td><td style=\"text-align: right;\">   0.979998</td><td style=\"text-align: right;\">    0.315812</td></tr>\n",
       "<tr><td>trainable_b3782_00048</td><td>TERMINATED</td><td>127.0.0.1:44899</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              3</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00756</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.66</td><td>False                 </td><td>selu  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_1540</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        128.025 </td><td style=\"text-align: right;\">   0.978998</td><td style=\"text-align: right;\">    0.345777</td></tr>\n",
       "<tr><td>trainable_b3782_00049</td><td>TERMINATED</td><td>127.0.0.1:44902</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00756</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.66</td><td>False                 </td><td>selu  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_0700</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        110.805 </td><td style=\"text-align: right;\">   0.978807</td><td style=\"text-align: right;\">    0.352881</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 10:11:51,779\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:11:51,920\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:11:52,343\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:11:52,495\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:11:52,669\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:12:46,665\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:12:46,849\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:12:48,052\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:12:59,645\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:13:47,656\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:13:48,054\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:13:48,237\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:13:50,832\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:13:54,284\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:14:10,511\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:14:11,436\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:14:20,801\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:14:34,224\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:14:39,535\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:14:43,237\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:14:44,070\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:14:46,980\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:14:51,312\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:15:08,591\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:15:23,183\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:15:51,021\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:16:02,305\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:16:15,090\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:16:18,836\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:16:21,265\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:17:37,624\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:17:39,400\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:17:57,533\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:13,146\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:13,735\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:20,215\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:24,033\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:29,886\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:18:47,167\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:19:18,082\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:19:18,438\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:19:36,784\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:19:51,574\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:19:51,688\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:20:01,722\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '5811840f')}\n",
      "2023-12-16 10:20:49,219\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:20:55,260\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:20:55,890\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:21:03,506\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:21:17,015\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'tasks/mnist/loss/loss': ('__ref_ph', '4ff9a407')}\n",
      "2023-12-16 10:21:17,074\tINFO tune.py:1148 -- Total run time: 614.48 seconds (613.93 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# pass `cv_folds` parameter to Search for cross validation\n",
    "tuner = Search(space, builder, cv_dataloader, \"mnist_auc\", cv_folds=5)\n",
    "\n",
    "# make a temporary directory to store outputs - cleanup at end\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run trials using default settings\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"cross_validation\", num_samples=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e3a03-73e4-48f0-9123-11d26aa3fa69",
   "metadata": {},
   "source": [
    "## Create an experiment DataFrame for analysis\n",
    "\n",
    "`glimr.analysis` contains functions for building Pandas DataFrames that contain trial information like performance, checkpoint location, and cross validation information. These DataFrames can be used for visualizaton or for analysis tasks like identifing the best performing checkpoints in each fold, or the configuration with the best average performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efc79b9-01d7-44a9-bf0b-a57187e2a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mnist_auc')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from glimr.analysis import default_checkpoints, experiment_table\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# create a dataframe of checkpointed epochs from all trials (folds + configurations)\n",
    "exp_dir = temp_dir.name + \"/cross_validation\"\n",
    "df = experiment_table(exp_dir, checkpointed=True)\n",
    "\n",
    "# filter table to select checkpoints that correspond to best epoch\n",
    "df = default_checkpoints(df)\n",
    "\n",
    "# create parallel plot of config performance\n",
    "performance = []\n",
    "for enum in set(df[\"config_enum\"]):\n",
    "    config = df.loc[df[\"config_enum\"]==enum, :].sort_values(by=\"cv_index\")\n",
    "    performance.append(np.array(config[\"mnist_auc\"]))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for config in performance:\n",
    "    ax.plot(config)\n",
    "plt.xlabel(\"fold\")\n",
    "plt.xticks(range(max(df[\"cv_index\"]+1)))\n",
    "plt.ylabel(\"mnist_auc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea354e-31af-4b1a-a4b7-caf789d732c9",
   "metadata": {},
   "source": [
    "## Experiment DataFrame queries\n",
    "\n",
    "`glimr.analysis` contains functions to query the top performing trials or the configurations with the best performance over all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04c968d-1a5b-488d-ad17-1435b9f1c4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trial_#</th>\n",
       "      <th>subdir</th>\n",
       "      <th>exp_dir</th>\n",
       "      <th>mnist_auc</th>\n",
       "      <th>mnist_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>config</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>cv_index</th>\n",
       "      <th>config_enum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>trainable_b3782_00002_2_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>40.483688</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.567129</td>\n",
       "      <td>44600</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.567129</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "      <td>trainable_b3782_00001_1_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982476</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>40.380822</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.708772</td>\n",
       "      <td>44599</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.708772</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>40</td>\n",
       "      <td>trainable_b3782_00003_3_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982383</td>\n",
       "      <td>0.268057</td>\n",
       "      <td>39.995779</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>161.585937</td>\n",
       "      <td>44601</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>161.585937</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>trainable_b3782_00004_4_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982253</td>\n",
       "      <td>0.267615</td>\n",
       "      <td>40.535871</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.594500</td>\n",
       "      <td>44602</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.594500</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202</td>\n",
       "      <td>42</td>\n",
       "      <td>trainable_b3782_00048_48_batch_size=32,cv_inde...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982221</td>\n",
       "      <td>0.284125</td>\n",
       "      <td>31.209845</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>76.925258</td>\n",
       "      <td>44899</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'gelu', 'dropout': 0...</td>\n",
       "      <td>76.925258</td>\n",
       "      <td>2</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  trial_#                                             subdir  \\\n",
       "0     11        2  trainable_b3782_00002_2_batch_size=32,cv_index...   \n",
       "1    232       50  trainable_b3782_00001_1_batch_size=32,cv_index...   \n",
       "2    196       40  trainable_b3782_00003_3_batch_size=32,cv_index...   \n",
       "3     71       16  trainable_b3782_00004_4_batch_size=32,cv_index...   \n",
       "4    202       42  trainable_b3782_00048_48_batch_size=32,cv_inde...   \n",
       "\n",
       "                                             exp_dir  mnist_auc  mnist_loss  \\\n",
       "0  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982645    0.265305   \n",
       "1  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982476    0.264139   \n",
       "2  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982383    0.268057   \n",
       "3  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982253    0.267615   \n",
       "4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982221    0.284125   \n",
       "\n",
       "   time_this_iter_s  should_checkpoint   done  training_iteration  ...  \\\n",
       "0         40.483688               True   True                   4  ...   \n",
       "1         40.380822               True   True                   4  ...   \n",
       "2         39.995779               True   True                   4  ...   \n",
       "3         40.535871               True   True                   4  ...   \n",
       "4         31.209845               True  False                   2  ...   \n",
       "\n",
       "  time_total_s    pid       hostname    node_ip  \\\n",
       "0   158.567129  44600  FSMC07RG6YWKG  127.0.0.1   \n",
       "1   158.708772  44599  FSMC07RG6YWKG  127.0.0.1   \n",
       "2   161.585937  44601  FSMC07RG6YWKG  127.0.0.1   \n",
       "3   158.594500  44602  FSMC07RG6YWKG  127.0.0.1   \n",
       "4    76.925258  44899  FSMC07RG6YWKG  127.0.0.1   \n",
       "\n",
       "                                              config time_since_restore  \\\n",
       "0  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.567129   \n",
       "1  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.708772   \n",
       "2  {'layer1': {'activation': 'sigmoid', 'dropout'...         161.585937   \n",
       "3  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.594500   \n",
       "4  {'layer1': {'activation': 'gelu', 'dropout': 0...          76.925258   \n",
       "\n",
       "  iterations_since_restore                                    checkpoint_path  \\\n",
       "0                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "1                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "2                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "3                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "4                        2  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "\n",
       "   cv_index  config_enum  \n",
       "0         2            2  \n",
       "1         1            2  \n",
       "2         3            2  \n",
       "3         4            2  \n",
       "4         3            6  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glimr.analysis import top_k_configs, top_k_trials\n",
    "\n",
    "# the top 5 trials from all folds\n",
    "top_k_trials(df, \"mnist_auc\", k=5, fold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47e2d18-5430-4ce4-85dc-0dda0dcd3a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trial_#</th>\n",
       "      <th>subdir</th>\n",
       "      <th>exp_dir</th>\n",
       "      <th>mnist_auc</th>\n",
       "      <th>mnist_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>config</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>checkpoint_path</th>\n",
       "      <th>cv_index</th>\n",
       "      <th>config_enum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>trainable_b3782_00002_2_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.265305</td>\n",
       "      <td>40.483688</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.567129</td>\n",
       "      <td>44600</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.567129</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>50</td>\n",
       "      <td>trainable_b3782_00001_1_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982476</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>40.380822</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.708772</td>\n",
       "      <td>44599</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.708772</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>40</td>\n",
       "      <td>trainable_b3782_00003_3_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982383</td>\n",
       "      <td>0.268057</td>\n",
       "      <td>39.995779</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>161.585937</td>\n",
       "      <td>44601</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>161.585937</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>trainable_b3782_00004_4_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.982253</td>\n",
       "      <td>0.267615</td>\n",
       "      <td>40.535871</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>158.594500</td>\n",
       "      <td>44602</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>158.594500</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>trainable_b3782_00000_0_batch_size=32,cv_index...</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.272438</td>\n",
       "      <td>43.040012</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>164.773453</td>\n",
       "      <td>44598</td>\n",
       "      <td>FSMC07RG6YWKG</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>{'layer1': {'activation': 'sigmoid', 'dropout'...</td>\n",
       "      <td>164.773453</td>\n",
       "      <td>4</td>\n",
       "      <td>/var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  trial_#                                             subdir  \\\n",
       "0     11        2  trainable_b3782_00002_2_batch_size=32,cv_index...   \n",
       "1    232       50  trainable_b3782_00001_1_batch_size=32,cv_index...   \n",
       "2    196       40  trainable_b3782_00003_3_batch_size=32,cv_index...   \n",
       "3     71       16  trainable_b3782_00004_4_batch_size=32,cv_index...   \n",
       "5     63       14  trainable_b3782_00000_0_batch_size=32,cv_index...   \n",
       "\n",
       "                                             exp_dir  mnist_auc  mnist_loss  \\\n",
       "0  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982645    0.265305   \n",
       "1  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982476    0.264139   \n",
       "2  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982383    0.268057   \n",
       "3  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.982253    0.267615   \n",
       "5  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   0.981891    0.272438   \n",
       "\n",
       "   time_this_iter_s  should_checkpoint  done  training_iteration  ...  \\\n",
       "0         40.483688               True  True                   4  ...   \n",
       "1         40.380822               True  True                   4  ...   \n",
       "2         39.995779               True  True                   4  ...   \n",
       "3         40.535871               True  True                   4  ...   \n",
       "5         43.040012               True  True                   4  ...   \n",
       "\n",
       "  time_total_s    pid       hostname    node_ip  \\\n",
       "0   158.567129  44600  FSMC07RG6YWKG  127.0.0.1   \n",
       "1   158.708772  44599  FSMC07RG6YWKG  127.0.0.1   \n",
       "2   161.585937  44601  FSMC07RG6YWKG  127.0.0.1   \n",
       "3   158.594500  44602  FSMC07RG6YWKG  127.0.0.1   \n",
       "5   164.773453  44598  FSMC07RG6YWKG  127.0.0.1   \n",
       "\n",
       "                                              config time_since_restore  \\\n",
       "0  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.567129   \n",
       "1  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.708772   \n",
       "2  {'layer1': {'activation': 'sigmoid', 'dropout'...         161.585937   \n",
       "3  {'layer1': {'activation': 'sigmoid', 'dropout'...         158.594500   \n",
       "5  {'layer1': {'activation': 'sigmoid', 'dropout'...         164.773453   \n",
       "\n",
       "  iterations_since_restore                                    checkpoint_path  \\\n",
       "0                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "1                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "2                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "3                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "5                        4  /var/folders/tz/qttd962d27n1g_l3f83f9s95byzb9n...   \n",
       "\n",
       "   cv_index  config_enum  \n",
       "0         2            2  \n",
       "1         1            2  \n",
       "2         3            2  \n",
       "3         4            2  \n",
       "5         0            2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the configuration with the best median performance over all folds\n",
    "top_k_configs(df, \"mnist_auc\", k=1, statistic=np.median)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
