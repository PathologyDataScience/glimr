{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "## MNIST example\n",
    "\n",
    "This notebook demonstrates and end-to-end application of the glimr package.\n",
    "\n",
    "Using MNIST classification as a simple example, we demonstrate the steps to create a search space, model builder, and dataloader for use in tuning. This provides a concrete example of topics like using the `glimr.utils` and `glimr.keras` functions to create hyperparameters and to correctly name losses and metrics for training and reporting.\n",
    "\n",
    "This is followed by a demonstration of the `Search` class to show how to setup and run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af13097",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../../glimr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "# Creating the search space\n",
    "\n",
    "First let's create a search space for a simple two layer network for a multiclass MNIST classifier.\n",
    "\n",
    "This search space will consist of hyperparameters for each layer, for loss, for gradient optimization, and for data loading and preprocessing. Below we build these components incrementally and examine each in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b201379",
   "metadata": {},
   "source": [
    "### The first layer\n",
    "\n",
    "For the first layer we define the possible layer activations, dropout rate, and number of units. Where defining a range hyperparameter, we use `tune.quniform` which creates a quantized floating point hyperparameter. Where choosing among discrete options, we use `tune.choice` which performs a random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optimization search space from glimr\n",
    "from pprint import pprint\n",
    "from ray import tune\n",
    "\n",
    "# define the possible layer activations\n",
    "activations = tune.choice(\n",
    "    [\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"]\n",
    ")\n",
    "\n",
    "# define the layer 1 hyperparameters\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": tune.choice([64, 48, 32, 16]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03432503",
   "metadata": {},
   "source": [
    "### Defining losses and metrics\n",
    "\n",
    "Since losses and their parameters can have a significant impact on performance, we may want to treat them as tunable hyperparameters. For example, properties like label smoothing thresholds can be searched to identify optimal values. Here we define a nested dictionary that randomizes choice of a hinge or cross entropy loss, and that defines label smoothing as a hyperparameter for cross entropy. Each loss has a `name` that defines how this loss is registered and reported by Ray Tune, and a `loss` parameter that defines a `tf.keras.losses.Loss` subclass. An optional `kwargs` dictionary is used to customize the class instance when it is created during a trial.\n",
    "\n",
    "Loss weights are assigned for each loss, and can set as hyperparameters, although here we set the loss weight to 1.\n",
    "\n",
    "Metrics provide feedback on model performance and are how Ray Tune ranks models, so they are not hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6f3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 23:36:18.425886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# set the loss as a hyperparameter\n",
    "loss = tune.choice(\n",
    "    [\n",
    "        {\"name\": \"categorical_hinge\", \"loss\": tf.keras.losses.CategoricalHinge},\n",
    "        {\n",
    "            \"name\": \"categorical_crossentropy\",\n",
    "            \"loss\": tf.keras.losses.CategoricalCrossentropy,\n",
    "            \"kwargs\": {\"label_smoothing\": tune.quniform(0.0, 0.2, 0.01)},\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# use a fixed loss weight\n",
    "loss_weight = (1.0,)\n",
    "\n",
    "# set fixed metrics for reporting to Ray Tune\n",
    "metrics = {\n",
    "    \"name\": \"auc\",\n",
    "    \"metric\": tf.keras.metrics.AUC,\n",
    "    \"kwargs\": {\"from_logits\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf253b9",
   "metadata": {},
   "source": [
    "### Define the second layer / task\n",
    "\n",
    "We refer to the terminal outputs / layers of a network as _tasks_. Each task is named to allow automatic linking of metrics and losses at compilation time for multi-task networks, and to simplify the naming and selection of the metric used by Ray to identify the best model/trial.\n",
    "\n",
    "The specific formulation of a task depends on the model builder function, but here we define a task as a layer that has additional loss, loss weight, and metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857a5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": 10,\n",
    "    \"loss\": loss,\n",
    "    \"loss_weight\": loss_weight,\n",
    "    \"metrics\": metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d63479",
   "metadata": {},
   "source": [
    "### Optimization hyperparameters\n",
    "\n",
    "Optimization hyperparameters include the maximum number of epochs for a trial, the gradient descent algorithm, and the algorithm hyperparameters like learning rate or momentum.\n",
    "\n",
    "Glimr defines an optimization search space and an optimization builder in `glimr.keras.keras_optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e9c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.optimization import optimization_space\n",
    "\n",
    "optimization = optimization_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90526c8d",
   "metadata": {},
   "source": [
    "### Data loader hyperparameters\n",
    "\n",
    "Data loader hyperparameters include a required `batch_size` hyperparameter, as well as user-defined hyperparameters to control loading and preprocessing behavior. Here we define a variable batch size, and randomize the application of a brightness transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader keyword arguments to control loading, augmentation, and batching\n",
    "data = {\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"random_brightness\": tune.choice(\n",
    "        [True, False]\n",
    "    ),  # whether to perform random brightness transformation\n",
    "    \"max_delta\": tune.quniform(0.01, 0.15, 0.01),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e4c92",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The keys `data`, `optimization`, and `tasks` are all required keys that `glimr.search.Search` uses to build models during trials. For `tasks`, a dictionary maps the user-designated task names to the task dictionaries like the one defined above. A multi-task model will contain multiple task key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6784ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {   'batch_size': <ray.tune.search.sample.Categorical object at 0x7fc93b30baf0>,\n",
      "                'max_delta': <ray.tune.search.sample.Float object at 0x7fc93b30ba60>,\n",
      "                'random_brightness': <ray.tune.search.sample.Categorical object at 0x7fc93b30b760>},\n",
      "    'layer1': {   'activation': <ray.tune.search.sample.Categorical object at 0x7fc951074250>,\n",
      "                  'dropout': <ray.tune.search.sample.Float object at 0x7fc951074190>,\n",
      "                  'units': <ray.tune.search.sample.Categorical object at 0x7fc953ae5460>},\n",
      "    'optimization': {   'beta_1': <ray.tune.search.sample.Float object at 0x7fc93b266040>,\n",
      "                        'beta_2': <ray.tune.search.sample.Float object at 0x7fc93b266100>,\n",
      "                        'ema_momentum': <ray.tune.search.sample.Float object at 0x7fc93b2661f0>,\n",
      "                        'ema_overwrite_frequency': <ray.tune.search.sample.Categorical object at 0x7fc93b266400>,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': <ray.tune.search.sample.Float object at 0x7fc953ae5520>,\n",
      "                        'method': <ray.tune.search.sample.Categorical object at 0x7fc953ae5e80>,\n",
      "                        'momentum': <ray.tune.search.sample.Float object at 0x7fc953ae5370>,\n",
      "                        'rho': <ray.tune.search.sample.Float object at 0x7fc953ae5d00>,\n",
      "                        'use_ema': <ray.tune.search.sample.Categorical object at 0x7fc93b266250>},\n",
      "    'tasks': {   'mnist': {   'activation': <ray.tune.search.sample.Categorical object at 0x7fc951074250>,\n",
      "                              'dropout': <ray.tune.search.sample.Float object at 0x7fc953ae5130>,\n",
      "                              'loss': <ray.tune.search.sample.Categorical object at 0x7fc959e281c0>,\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'kwargs': {'from_logits': True},\n",
      "                                             'metric': <class 'keras.src.metrics.confusion_metrics.AUC'>,\n",
      "                                             'name': 'auc'},\n",
      "                              'units': 10}}}\n"
     ]
    }
   ],
   "source": [
    "# put it all together\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\"mnist\": task},\n",
    "    \"data\": data,\n",
    "}\n",
    "\n",
    "# display search space\n",
    "pprint(space, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd4332",
   "metadata": {},
   "source": [
    "### Sample a config from the search space and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec37d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {'batch_size': 64, 'max_delta': 0.04, 'random_brightness': True},\n",
      "    'layer1': {'activation': 'selu', 'dropout': 0.0, 'units': 16},\n",
      "    'optimization': {   'beta_1': 0.61,\n",
      "                        'beta_2': 0.73,\n",
      "                        'ema_momentum': 0.9500000000000001,\n",
      "                        'ema_overwrite_frequency': 5,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': 0.00855,\n",
      "                        'method': 'adadelta',\n",
      "                        'momentum': 0.09,\n",
      "                        'rho': 0.9,\n",
      "                        'use_ema': True},\n",
      "    'tasks': {   'mnist': {   'activation': 'selu',\n",
      "                              'dropout': 0.15000000000000002,\n",
      "                              'loss': {   'loss': <class 'keras.src.losses.CategoricalHinge'>,\n",
      "                                          'name': 'categorical_hinge'},\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'kwargs': {'from_logits': True},\n",
      "                                             'metric': <class 'keras.src.metrics.confusion_metrics.AUC'>,\n",
      "                                             'name': 'auc'},\n",
      "                              'units': 10}}}\n"
     ]
    }
   ],
   "source": [
    "from glimr.utils import sample_space\n",
    "\n",
    "config = sample_space(space)\n",
    "pprint(config, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844b5b2",
   "metadata": {},
   "source": [
    "# Implement the model-building function\n",
    "\n",
    "The model-builder function transforms a sample of the space into a `tf.keras.Model`, and loss, loss weight, and metric inputs for model compilation. This is a user-defined function to provide maximum flexibility in the models that can be used with glimr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "\n",
    "\n",
    "def builder(config):\n",
    "    # a helper function for building layers\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        # dense layer\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "\n",
    "        # add dropout if necessary\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # create input layer\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "\n",
    "    # build layer 1\n",
    "    x = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"layer1\"][\"units\"],\n",
    "        config[\"layer1\"][\"activation\"],\n",
    "        config[\"layer1\"][\"dropout\"],\n",
    "        \"layer1\",\n",
    "    )\n",
    "\n",
    "    # build output / task layer\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"tasks\"][task_name][\"units\"],\n",
    "        config[\"tasks\"][task_name][\"activation\"],\n",
    "        config[\"tasks\"][task_name][\"dropout\"],\n",
    "        task_name,\n",
    "    )\n",
    "\n",
    "    # build named output dict\n",
    "    named = {f\"{task_name}\": output}\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "\n",
    "    # create a loss dictionary\n",
    "    losses, loss_weights = keras_losses(config)\n",
    "\n",
    "    # create a metric dictionary\n",
    "    metrics = keras_metrics(config)\n",
    "\n",
    "    return model, losses, loss_weights, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "# Create a data loading function\n",
    "\n",
    "Write a function to load and batch mnist samples. Flatten the images and apply a one-hot encoding to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dataloader(batch_size, random_brightness, max_delta):\n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(\n",
    "            features.shape[0], features.shape[1] * features.shape[2]\n",
    "        )\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(train[0]), tf.float32) / 255.0\n",
    "    train_labels = train[1]\n",
    "    validation_features = tf.cast(mnist_flat(validation[0]), tf.float32) / 255.0\n",
    "    validation_labels = validation[1]\n",
    "\n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "\n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    validation_ds = validation_ds.batch(batch_size)\n",
    "\n",
    "    # apply augmentation\n",
    "    if random_brightness:\n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta), y)\n",
    "        )\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795438a8",
   "metadata": {},
   "source": [
    "### Test the search space, model builder, and dataloader\n",
    "\n",
    "Before doing a hyperparameter search, let's test this combination to verify that the models can train.\n",
    "\n",
    "We generate a sample configuration from the search space and build, compile, and train a model with this config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a779c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {'batch_size': 64, 'max_delta': 0.1, 'random_brightness': False},\n",
      "    'layer1': {'activation': 'elu', 'dropout': 0.05, 'units': 64},\n",
      "    'optimization': {   'beta_1': 0.99,\n",
      "                        'beta_2': 0.5700000000000001,\n",
      "                        'ema_momentum': 0.9500000000000001,\n",
      "                        'ema_overwrite_frequency': 1,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': 0.00134,\n",
      "                        'method': 'adam',\n",
      "                        'momentum': 0.09,\n",
      "                        'rho': 0.93,\n",
      "                        'use_ema': True},\n",
      "    'tasks': {   'mnist': {   'activation': 'selu',\n",
      "                              'dropout': 0.05,\n",
      "                              'loss': {   'loss': <class 'keras.src.losses.CategoricalHinge'>,\n",
      "                                          'name': 'categorical_hinge'},\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'kwargs': {'from_logits': True},\n",
      "                                             'metric': <class 'keras.src.metrics.confusion_metrics.AUC'>,\n",
      "                                             'name': 'auc'},\n",
      "                              'units': 10}}}\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.0275 - auc: 0.8670 - val_loss: 0.7695 - val_auc: 0.9169\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7710 - auc: 0.9037 - val_loss: 0.7074 - val_auc: 0.9091\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7752 - auc: 0.9011 - val_loss: 0.6906 - val_auc: 0.9081\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7645 - auc: 0.8987 - val_loss: 0.6821 - val_auc: 0.9074\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7623 - auc: 0.9023 - val_loss: 0.6715 - val_auc: 0.9129\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7669 - auc: 0.9005 - val_loss: 0.6935 - val_auc: 0.9060\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7578 - auc: 0.9013 - val_loss: 0.6917 - val_auc: 0.9067\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7337 - auc: 0.9042 - val_loss: 0.7058 - val_auc: 0.9142\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7726 - auc: 0.9067 - val_loss: 0.7995 - val_auc: 0.9091\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.8159 - auc: 0.8968 - val_loss: 0.7426 - val_auc: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc93b54fdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glimr.keras import keras_optimizer\n",
    "import ray\n",
    "\n",
    "# sample a configuration\n",
    "config = sample_space(space)\n",
    "\n",
    "# display the configuration\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config, indent=4)\n",
    "\n",
    "# build the model\n",
    "model, losses, loss_weights, metrics = builder(config)\n",
    "\n",
    "# build the optimizer\n",
    "optimizer = keras_optimizer(config[\"optimization\"])\n",
    "\n",
    "# test compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=losses, metrics=metrics, loss_weights=loss_weights\n",
    ")\n",
    "\n",
    "# build dataset and train\n",
    "train_ds, val_ds = dataloader(**config[\"data\"])\n",
    "model.fit(x=train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "# Using Search for hyperparameter tuning\n",
    "\n",
    "The `Search` class implements the hyperparameter tuning process of Ray Tune. It provides sensible defaults for the many options available in Ray Tune, but also allows fine grained access to these options through class methods and attributes. Options can be added or assigned incrementally to alter reporting, checkpointing, trial stopping criteria, and resources used in experiments.\n",
    "\n",
    "We begin with a basic experiment using the AsyncHyperBandScheduler which performs a random search but terminates poorly performing trials early.\n",
    "\n",
    "By default if a reporter is not set, however, Ray Tune will display a dynamic table of ongoing experiments and results if running in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264a521b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-18 23:40:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:44.08        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.2/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 40.000: None | Iter 10.000: 0.8322619199752808<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  data/batch_size</th><th style=\"text-align: right;\">  data/max_delta</th><th>data/random_brightne\n",
       "ss      </th><th>layer1/activation  </th><th style=\"text-align: right;\">  layer1/dropout</th><th style=\"text-align: right;\">  layer1/units</th><th style=\"text-align: right;\">  optimization/beta_1</th><th style=\"text-align: right;\">  optimization/beta_2</th><th style=\"text-align: right;\">     optimization/ema_mom\n",
       "entum</th><th style=\"text-align: right;\">  optimization/ema_ove\n",
       "rwrite_frequency</th><th style=\"text-align: right;\">        optimization/learnin\n",
       "g_rate</th><th>optimization/method  </th><th style=\"text-align: right;\">     optimization/momentu\n",
       "m</th><th style=\"text-align: right;\">  optimization/rho</th><th>optimization/use_ema  </th><th>tasks/mnist/activati\n",
       "on         </th><th style=\"text-align: right;\">  tasks/mnist/dropout</th><th>tasks/mnist/loss    </th><th style=\"text-align: right;\">     tasks/mnist/loss/kwa\n",
       "rgs/label_smoothing</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mnist_auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_de878_00000</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>linear             </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.93</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00619</td><td>rms                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.52</td><td>True                  </td><td>linear  </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_d700</td><td style=\"text-align: right;\">0.18</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         50.8516</td><td style=\"text-align: right;\">   0.493286</td></tr>\n",
       "<tr><td>trainable_de878_00001</td><td>TERMINATED</td><td>127.0.0.1:60869</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">                 0.94</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00716</td><td>sgd                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.96</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_db80</td><td style=\"text-align: right;\">0.11</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        111.575 </td><td style=\"text-align: right;\">   0.806389</td></tr>\n",
       "<tr><td>trainable_de878_00002</td><td>TERMINATED</td><td>127.0.0.1:60881</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.6 </td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00561</td><td>adam                 </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.58</td><td>False                 </td><td>linear  </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_8900</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         24.9513</td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_de878_00003</td><td>TERMINATED</td><td>127.0.0.1:60886</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.13</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.61</td><td style=\"text-align: right;\">                 0.85</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00239</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.8 </td><td>False                 </td><td>relu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_a280</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         41.9394</td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_de878_00004</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.13</td><td>True </td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.77</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00177</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.7 </td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_a540</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.2755</td><td style=\"text-align: right;\">   0.949764</td></tr>\n",
       "<tr><td>trainable_de878_00005</td><td>TERMINATED</td><td>127.0.0.1:60881</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.01</td><td>False</td><td>linear             </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">                 0.94</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00806</td><td>adagrad              </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.94</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_4ac0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         14.1069</td><td style=\"text-align: right;\">   0.966592</td></tr>\n",
       "<tr><td>trainable_de878_00006</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">                 0.5 </td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00431</td><td>rms                  </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.97</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_4540</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         32.9424</td><td style=\"text-align: right;\">   0.979522</td></tr>\n",
       "<tr><td>trainable_de878_00007</td><td>TERMINATED</td><td>127.0.0.1:60881</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.87</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00413</td><td>adagrad              </td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">              0.53</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_a880</td><td style=\"text-align: right;\">0.12</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         79.8709</td><td style=\"text-align: right;\">   0.792142</td></tr>\n",
       "<tr><td>trainable_de878_00008</td><td>TERMINATED</td><td>127.0.0.1:60886</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.61</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00881</td><td>adagrad              </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.59</td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_3240</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.0218</td><td style=\"text-align: right;\">   0.771079</td></tr>\n",
       "<tr><td>trainable_de878_00009</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.98</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00068</td><td>rms                  </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.76</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_75c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         17.932 </td><td style=\"text-align: right;\">   0.972443</td></tr>\n",
       "<tr><td>trainable_de878_00010</td><td>TERMINATED</td><td>127.0.0.1:60886</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.85</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00065</td><td>rms                  </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.86</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_7e00</td><td style=\"text-align: right;\">0.16</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         17.1867</td><td style=\"text-align: right;\">   0.941023</td></tr>\n",
       "<tr><td>trainable_de878_00011</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.11</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00806</td><td>adam                 </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.51</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_bc40</td><td style=\"text-align: right;\">0.12</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         11.1158</td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_de878_00012</td><td>TERMINATED</td><td>127.0.0.1:60886</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00797</td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.53</td><td>True                  </td><td>gelu    </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_a1c0</td><td style=\"text-align: right;\">0.14</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         28.8241</td><td style=\"text-align: right;\">   0.661148</td></tr>\n",
       "<tr><td>trainable_de878_00013</td><td>TERMINATED</td><td>127.0.0.1:60869</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.13</td><td>True </td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.65</td><td style=\"text-align: right;\">                 0.88</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00407</td><td>rms                  </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.78</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_6600</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         32.3706</td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_de878_00014</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.1 </td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.57</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00644</td><td>adagrad              </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              1   </td><td>False                 </td><td>selu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_6b80</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         13.5509</td><td style=\"text-align: right;\">   0.982668</td></tr>\n",
       "<tr><td>trainable_de878_00015</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.1 </td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">0.96</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00032</td><td>adagrad              </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.64</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_7780</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         15.3329</td><td style=\"text-align: right;\">   0.546063</td></tr>\n",
       "<tr><td>trainable_de878_00016</td><td>TERMINATED</td><td>127.0.0.1:60881</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.82</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00222</td><td>adagrad              </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.59</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_07c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         51.6471</td><td style=\"text-align: right;\">   0.875746</td></tr>\n",
       "<tr><td>trainable_de878_00017</td><td>TERMINATED</td><td>127.0.0.1:60886</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.02</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">                 0.68</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00099</td><td>adam                 </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.85</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_bf00</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         41.9218</td><td style=\"text-align: right;\">   0.5014  </td></tr>\n",
       "<tr><td>trainable_de878_00018</td><td>TERMINATED</td><td>127.0.0.1:60859</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.11</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.67</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00599</td><td>adam                 </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.77</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_6fc0</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         31.4901</td><td style=\"text-align: right;\">   0.684004</td></tr>\n",
       "<tr><td>trainable_de878_00019</td><td>TERMINATED</td><td>127.0.0.1:60869</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.1 </td><td>True </td><td>relu               </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">                 0.77</td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00059</td><td>rms                  </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.97</td><td>True                  </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_e400</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         51.5242</td><td style=\"text-align: right;\">   0.722278</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_de878_00000</td><td>2023-07-18_23-37-51</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.493286</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             50.8516</td><td style=\"text-align: right;\">           4.19224</td><td style=\"text-align: right;\">       50.8516</td><td style=\"text-align: right;\"> 1689741471</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00000</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00001</td><td>2023-07-18_23-39-08</td><td>True  </td><td>                </td><td>aa21c5b667b34fb981d65b5fe19b6fdf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        13</td><td style=\"text-align: right;\">   0.806389</td><td>127.0.0.1</td><td style=\"text-align: right;\">60869</td><td>True               </td><td style=\"text-align: right;\">            111.575 </td><td style=\"text-align: right;\">           5.4263 </td><td style=\"text-align: right;\">      111.575 </td><td style=\"text-align: right;\"> 1689741548</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  13</td><td>de878_00001</td><td style=\"text-align: right;\">    0.0187962</td></tr>\n",
       "<tr><td>trainable_de878_00002</td><td>2023-07-18_23-37-54</td><td>True  </td><td>                </td><td>1cca9fb64d6f43a794f4857fac0711f5</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">60881</td><td>True               </td><td style=\"text-align: right;\">             24.9513</td><td style=\"text-align: right;\">           2.21023</td><td style=\"text-align: right;\">       24.9513</td><td style=\"text-align: right;\"> 1689741474</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>de878_00002</td><td style=\"text-align: right;\">    0.0153432</td></tr>\n",
       "<tr><td>trainable_de878_00003</td><td>2023-07-18_23-38-22</td><td>True  </td><td>                </td><td>dce8aefef80147d9859787bd7481c058</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">60886</td><td>True               </td><td style=\"text-align: right;\">             41.9394</td><td style=\"text-align: right;\">          11.9291 </td><td style=\"text-align: right;\">       41.9394</td><td style=\"text-align: right;\"> 1689741502</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00003</td><td style=\"text-align: right;\">    0.0129352</td></tr>\n",
       "<tr><td>trainable_de878_00004</td><td>2023-07-18_23-38-07</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.949764</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             15.2755</td><td style=\"text-align: right;\">           4.82893</td><td style=\"text-align: right;\">       15.2755</td><td style=\"text-align: right;\"> 1689741487</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00004</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00005</td><td>2023-07-18_23-38-08</td><td>True  </td><td>                </td><td>1cca9fb64d6f43a794f4857fac0711f5</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.966592</td><td>127.0.0.1</td><td style=\"text-align: right;\">60881</td><td>True               </td><td style=\"text-align: right;\">             14.1069</td><td style=\"text-align: right;\">           4.46322</td><td style=\"text-align: right;\">       14.1069</td><td style=\"text-align: right;\"> 1689741488</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00005</td><td style=\"text-align: right;\">    0.0153432</td></tr>\n",
       "<tr><td>trainable_de878_00006</td><td>2023-07-18_23-38-41</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.979522</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             32.9424</td><td style=\"text-align: right;\">           4.50059</td><td style=\"text-align: right;\">       32.9424</td><td style=\"text-align: right;\"> 1689741521</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00006</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00007</td><td>2023-07-18_23-39-28</td><td>True  </td><td>                </td><td>1cca9fb64d6f43a794f4857fac0711f5</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.792142</td><td>127.0.0.1</td><td style=\"text-align: right;\">60881</td><td>True               </td><td style=\"text-align: right;\">             79.8709</td><td style=\"text-align: right;\">           6.29037</td><td style=\"text-align: right;\">       79.8709</td><td style=\"text-align: right;\"> 1689741568</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>de878_00007</td><td style=\"text-align: right;\">    0.0153432</td></tr>\n",
       "<tr><td>trainable_de878_00008</td><td>2023-07-18_23-38-44</td><td>True  </td><td>                </td><td>dce8aefef80147d9859787bd7481c058</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.771079</td><td>127.0.0.1</td><td style=\"text-align: right;\">60886</td><td>True               </td><td style=\"text-align: right;\">             21.0218</td><td style=\"text-align: right;\">           3.46894</td><td style=\"text-align: right;\">       21.0218</td><td style=\"text-align: right;\"> 1689741524</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>de878_00008</td><td style=\"text-align: right;\">    0.0129352</td></tr>\n",
       "<tr><td>trainable_de878_00009</td><td>2023-07-18_23-38-59</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.972443</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             17.932 </td><td style=\"text-align: right;\">           2.5991 </td><td style=\"text-align: right;\">       17.932 </td><td style=\"text-align: right;\"> 1689741539</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>de878_00009</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00010</td><td>2023-07-18_23-39-01</td><td>True  </td><td>                </td><td>dce8aefef80147d9859787bd7481c058</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.941023</td><td>127.0.0.1</td><td style=\"text-align: right;\">60886</td><td>True               </td><td style=\"text-align: right;\">             17.1867</td><td style=\"text-align: right;\">           3.52556</td><td style=\"text-align: right;\">       17.1867</td><td style=\"text-align: right;\"> 1689741541</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00010</td><td style=\"text-align: right;\">    0.0129352</td></tr>\n",
       "<tr><td>trainable_de878_00011</td><td>2023-07-18_23-39-10</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             11.1158</td><td style=\"text-align: right;\">           2.58578</td><td style=\"text-align: right;\">       11.1158</td><td style=\"text-align: right;\"> 1689741550</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00011</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00012</td><td>2023-07-18_23-39-30</td><td>True  </td><td>                </td><td>dce8aefef80147d9859787bd7481c058</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.661148</td><td>127.0.0.1</td><td style=\"text-align: right;\">60886</td><td>True               </td><td style=\"text-align: right;\">             28.8241</td><td style=\"text-align: right;\">           2.25381</td><td style=\"text-align: right;\">       28.8241</td><td style=\"text-align: right;\"> 1689741570</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>de878_00012</td><td style=\"text-align: right;\">    0.0129352</td></tr>\n",
       "<tr><td>trainable_de878_00013</td><td>2023-07-18_23-39-41</td><td>True  </td><td>                </td><td>aa21c5b667b34fb981d65b5fe19b6fdf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">60869</td><td>True               </td><td style=\"text-align: right;\">             32.3706</td><td style=\"text-align: right;\">           5.23777</td><td style=\"text-align: right;\">       32.3706</td><td style=\"text-align: right;\"> 1689741581</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>de878_00013</td><td style=\"text-align: right;\">    0.0187962</td></tr>\n",
       "<tr><td>trainable_de878_00014</td><td>2023-07-18_23-39-24</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982668</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             13.5509</td><td style=\"text-align: right;\">           2.41024</td><td style=\"text-align: right;\">       13.5509</td><td style=\"text-align: right;\"> 1689741564</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00014</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00015</td><td>2023-07-18_23-39-40</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.546063</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             15.3329</td><td style=\"text-align: right;\">           3.3458 </td><td style=\"text-align: right;\">       15.3329</td><td style=\"text-align: right;\"> 1689741580</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>de878_00015</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00016</td><td>2023-07-18_23-40-20</td><td>True  </td><td>                </td><td>1cca9fb64d6f43a794f4857fac0711f5</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        14</td><td style=\"text-align: right;\">   0.875746</td><td>127.0.0.1</td><td style=\"text-align: right;\">60881</td><td>True               </td><td style=\"text-align: right;\">             51.6471</td><td style=\"text-align: right;\">           2.07126</td><td style=\"text-align: right;\">       51.6471</td><td style=\"text-align: right;\"> 1689741620</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  14</td><td>de878_00016</td><td style=\"text-align: right;\">    0.0153432</td></tr>\n",
       "<tr><td>trainable_de878_00017</td><td>2023-07-18_23-40-12</td><td>True  </td><td>                </td><td>dce8aefef80147d9859787bd7481c058</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.5014  </td><td>127.0.0.1</td><td style=\"text-align: right;\">60886</td><td>True               </td><td style=\"text-align: right;\">             41.9218</td><td style=\"text-align: right;\">           6.97737</td><td style=\"text-align: right;\">       41.9218</td><td style=\"text-align: right;\"> 1689741612</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>de878_00017</td><td style=\"text-align: right;\">    0.0129352</td></tr>\n",
       "<tr><td>trainable_de878_00018</td><td>2023-07-18_23-40-11</td><td>True  </td><td>                </td><td>6a87543b7e2449d4942a9400dfe498cb</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.684004</td><td>127.0.0.1</td><td style=\"text-align: right;\">60859</td><td>True               </td><td style=\"text-align: right;\">             31.4901</td><td style=\"text-align: right;\">           6.90457</td><td style=\"text-align: right;\">       31.4901</td><td style=\"text-align: right;\"> 1689741611</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>de878_00018</td><td style=\"text-align: right;\">    0.0194161</td></tr>\n",
       "<tr><td>trainable_de878_00019</td><td>2023-07-18_23-40-32</td><td>True  </td><td>                </td><td>aa21c5b667b34fb981d65b5fe19b6fdf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.722278</td><td>127.0.0.1</td><td style=\"text-align: right;\">60869</td><td>True               </td><td style=\"text-align: right;\">             51.5242</td><td style=\"text-align: right;\">           3.06298</td><td style=\"text-align: right;\">       51.5242</td><td style=\"text-align: right;\"> 1689741632</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>de878_00019</td><td style=\"text-align: right;\">    0.0187962</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Initialize a Search instance with the search space, model builder, and\n",
    "# data loader. The name of the metric and indicate to Ray how to measure\n",
    "# model performance, and are provided in format task_metric. This is the\n",
    "# convention when building models using glimr.keras.keras_metrics.\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# make a temporary directory to store outputs - cleanup at end\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run trials using default settings\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"default\", num_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175cfde",
   "metadata": {},
   "source": [
    "### Display information about the best trial\n",
    "\n",
    "The output from `Search.experiment` contains information on each trial's performance and configuration, and can be used for trial analysis and for keeping the best checkpointed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7c05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best result auc: 0.9826675057411194\n",
      "best configuration:\n",
      "{   'builder': <function builder at 0x7fc92531c160>,\n",
      "    'data': {'batch_size': 128, 'max_delta': 0.1, 'random_brightness': True},\n",
      "    'fit_kwargs': {},\n",
      "    'layer1': {   'activation': 'selu',\n",
      "                  'dropout': 0.15000000000000002,\n",
      "                  'units': 16},\n",
      "    'loader': <function dataloader at 0x7fc9253871f0>,\n",
      "    'optimization': {   'beta_1': 0.5700000000000001,\n",
      "                        'beta_2': 0.86,\n",
      "                        'ema_momentum': 0.9400000000000001,\n",
      "                        'ema_overwrite_frequency': 1,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': 0.00644,\n",
      "                        'method': 'adagrad',\n",
      "                        'momentum': 0.07,\n",
      "                        'rho': 1.0,\n",
      "                        'use_ema': False},\n",
      "    'tasks': {   'mnist': {   'activation': 'selu',\n",
      "                              'dropout': 0.1,\n",
      "                              'loss': {   'loss': <class 'keras.src.losses.CategoricalHinge'>,\n",
      "                                          'name': 'categorical_hinge'},\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'kwargs': {'from_logits': True},\n",
      "                                             'metric': <class 'keras.src.metrics.confusion_metrics.AUC'>,\n",
      "                                             'name': 'auc'},\n",
      "                              'units': 10}}}\n",
      "contents of best trial checkpoint:\n",
      "['fingerprint.pb', 'keras_metadata.pb', 'variables', 'saved_model.pb', 'assets']\n"
     ]
    }
   ],
   "source": [
    "# get information about the best trial\n",
    "best_result = results.get_best_result()\n",
    "best_auc = best_result.metrics[\"mnist_auc\"]\n",
    "best_config = best_result.metrics[\"config\"]\n",
    "best_checkpoint = best_result.checkpoint.to_directory()\n",
    "\n",
    "# display\n",
    "print(f\"best result auc: {best_auc}\")\n",
    "print(\"best configuration:\")\n",
    "pprint(best_config, indent=4)\n",
    "print(\"contents of best trial checkpoint:\")\n",
    "print(os.listdir(os.path.join(best_checkpoint, \"checkpoint\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a830f",
   "metadata": {},
   "source": [
    "### Experiment performance statistics for default settings\n",
    "\n",
    "Let's plot the performance of trials from the default experiment which uses an AsyncHyperband scheduler with a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf4d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'AUC')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get dataframe from default experiment\n",
    "default_table = results.get_dataframe()\n",
    "default_auc = np.array(default_table[\"mnist_auc\"])\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(-np.sort(-default_auc))\n",
    "plt.xlabel(\"trial\")\n",
    "plt.ylabel(\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4ba37",
   "metadata": {},
   "source": [
    "### Using a population-based training scheduler\n",
    "\n",
    "Let's change the scheduler to population-based training (PBT). PBT optimizes resource utililzation by replacing poorly performing trials with \"mutated\" versions of top performing trials.\n",
    "\n",
    "We recommend creating a new `Search` object for every experiment to avoid issues with Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8c2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-18 23:43:50</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:15.62        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.5/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  data/batch_size</th><th style=\"text-align: right;\">  data/max_delta</th><th>data/random_brightne\n",
       "ss      </th><th>layer1/activation  </th><th style=\"text-align: right;\">  layer1/dropout</th><th style=\"text-align: right;\">  layer1/units</th><th style=\"text-align: right;\">  optimization/beta_1</th><th style=\"text-align: right;\">  optimization/beta_2</th><th style=\"text-align: right;\">     optimization/ema_mom\n",
       "entum</th><th style=\"text-align: right;\">  optimization/ema_ove\n",
       "rwrite_frequency</th><th style=\"text-align: right;\">        optimization/learnin\n",
       "g_rate</th><th>optimization/method  </th><th style=\"text-align: right;\">     optimization/momentu\n",
       "m</th><th style=\"text-align: right;\">  optimization/rho</th><th>optimization/use_ema  </th><th>tasks/mnist/activati\n",
       "on         </th><th style=\"text-align: right;\">  tasks/mnist/dropout</th><th>tasks/mnist/loss    </th><th style=\"text-align: right;\">     tasks/mnist/loss/kwa\n",
       "rgs/label_smoothing</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mnist_auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_66517_00000</td><td>TERMINATED</td><td>127.0.0.1:60992</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.01</td><td>False</td><td>linear             </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.92</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.006  </td><td>rms                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.59</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_f900</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         44.0003</td><td style=\"text-align: right;\">   0.983807</td></tr>\n",
       "<tr><td>trainable_66517_00001</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.73</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00867</td><td>adam                 </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.53</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8c40</td><td style=\"text-align: right;\">0.16</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         37.1161</td><td style=\"text-align: right;\">   0.502739</td></tr>\n",
       "<tr><td>trainable_66517_00002</td><td>TERMINATED</td><td>127.0.0.1:60997</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.15</td><td>False</td><td>selu               </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.96</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.0039 </td><td>adam                 </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">              0.82</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_7b40</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         20.6217</td><td style=\"text-align: right;\">   0.980258</td></tr>\n",
       "<tr><td>trainable_66517_00003</td><td>TERMINATED</td><td>127.0.0.1:61003</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.13</td><td>False</td><td>selu               </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.98</td><td style=\"text-align: right;\">                 0.95</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00712</td><td>adam                 </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.77</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_4a00</td><td style=\"text-align: right;\">0.12</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         54.8792</td><td style=\"text-align: right;\">   0.621437</td></tr>\n",
       "<tr><td>trainable_66517_00004</td><td>TERMINATED</td><td>127.0.0.1:60997</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">                 0.98</td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00657</td><td>adadelta             </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.79</td><td>False                 </td><td>linear  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_6f40</td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         13.3868</td><td style=\"text-align: right;\">   0.400597</td></tr>\n",
       "<tr><td>trainable_66517_00005</td><td>TERMINATED</td><td>127.0.0.1:60992</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.1 </td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.74</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00873</td><td>adadelta             </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.59</td><td>True                  </td><td>gelu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_37c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         70.5027</td><td style=\"text-align: right;\">   0.72643 </td></tr>\n",
       "<tr><td>trainable_66517_00006</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>gelu               </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.57</td><td style=\"text-align: right;\">0.98</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00391</td><td>rms                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.65</td><td>False                 </td><td>relu    </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_7780</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         21.9233</td><td style=\"text-align: right;\">   0.730474</td></tr>\n",
       "<tr><td>trainable_66517_00007</td><td>TERMINATED</td><td>127.0.0.1:60997</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">                 0.69</td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00822</td><td>adagrad              </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.88</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_87c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         29.9384</td><td style=\"text-align: right;\">   0.942733</td></tr>\n",
       "<tr><td>trainable_66517_00008</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.13</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00017</td><td>adam                 </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.63</td><td>True                  </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_3d00</td><td style=\"text-align: right;\">0.13</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         50.2309</td><td style=\"text-align: right;\">   0.732626</td></tr>\n",
       "<tr><td>trainable_66517_00009</td><td>TERMINATED</td><td>127.0.0.1:60997</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.97</td><td style=\"text-align: right;\">                 0.94</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00846</td><td>rms                  </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.99</td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_3740</td><td style=\"text-align: right;\">0.13</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.7766</td><td style=\"text-align: right;\">   0.423679</td></tr>\n",
       "<tr><td>trainable_66517_00010</td><td>TERMINATED</td><td>127.0.0.1:61003</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.08</td><td>False</td><td>linear             </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.82</td><td style=\"text-align: right;\">                 0.67</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00227</td><td>adam                 </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.87</td><td>False                 </td><td>softplus</td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_a7c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         18.2781</td><td style=\"text-align: right;\">   0.976063</td></tr>\n",
       "<tr><td>trainable_66517_00011</td><td>TERMINATED</td><td>127.0.0.1:61003</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.02</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.94</td><td style=\"text-align: right;\">                 0.82</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00934</td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.79</td><td>True                  </td><td>linear  </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_c740</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         14.7201</td><td style=\"text-align: right;\">   0.494539</td></tr>\n",
       "<tr><td>trainable_66517_00012</td><td>TERMINATED</td><td>127.0.0.1:60992</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.11</td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.91</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00886</td><td>adam                 </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.56</td><td>False                 </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_7c80</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         14.0853</td><td style=\"text-align: right;\">   0.983268</td></tr>\n",
       "<tr><td>trainable_66517_00013</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.04</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.53</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.97</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00874</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.77</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_80c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         11.7794</td><td style=\"text-align: right;\">   0.527371</td></tr>\n",
       "<tr><td>trainable_66517_00014</td><td>TERMINATED</td><td>127.0.0.1:61003</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.09</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00947</td><td>adadelta             </td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">              0.85</td><td>False                 </td><td>relu    </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_8b80</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         10.4219</td><td style=\"text-align: right;\">   0.551788</td></tr>\n",
       "<tr><td>trainable_66517_00015</td><td>TERMINATED</td><td>127.0.0.1:60992</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.05</td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.52</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.0029 </td><td>adadelta             </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.76</td><td>False                 </td><td>gelu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_7f40</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         52.1877</td><td style=\"text-align: right;\">   0.885778</td></tr>\n",
       "<tr><td>trainable_66517_00016</td><td>TERMINATED</td><td>127.0.0.1:60997</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>softplus           </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.64</td><td style=\"text-align: right;\">                 0.56</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00555</td><td>rms                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.63</td><td>True                  </td><td>linear  </td><td style=\"text-align: right;\">                 0.2 </td><td>{&#x27;name&#x27;: &#x27;categ_67c0</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         27.9648</td><td style=\"text-align: right;\">   0.498791</td></tr>\n",
       "<tr><td>trainable_66517_00017</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.08</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.51</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00177</td><td>adagrad              </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.76</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_fc80</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         19.1491</td><td style=\"text-align: right;\">   0.930684</td></tr>\n",
       "<tr><td>trainable_66517_00018</td><td>TERMINATED</td><td>127.0.0.1:61003</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>gelu               </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                 0.65</td><td style=\"text-align: right;\">                 1   </td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.00694</td><td>adagrad              </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">              0.9 </td><td>True                  </td><td>selu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_2b40</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         35.37  </td><td style=\"text-align: right;\">   0.950355</td></tr>\n",
       "<tr><td>trainable_66517_00019</td><td>TERMINATED</td><td>127.0.0.1:60993</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.09</td><td>True </td><td>linear             </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">                 0.74</td><td style=\"text-align: right;\">                 0.78</td><td style=\"text-align: right;\">0.99</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00928</td><td>rms                  </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.79</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_0d00</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         13.905 </td><td style=\"text-align: right;\">   0.982293</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">   trial_id</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_66517_00000</td><td>2023-07-18_23-41-32</td><td>True  </td><td>                </td><td>417f9ae5c1854903be27731328334b0a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.983807</td><td>127.0.0.1</td><td style=\"text-align: right;\">60992</td><td>True               </td><td style=\"text-align: right;\">             44.0003</td><td style=\"text-align: right;\">           3.38668</td><td style=\"text-align: right;\">       44.0003</td><td style=\"text-align: right;\"> 1689741692</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00000</td><td style=\"text-align: right;\">    0.0121198</td></tr>\n",
       "<tr><td>trainable_66517_00001</td><td>2023-07-18_23-41-37</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.502739</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             37.1161</td><td style=\"text-align: right;\">           2.4406 </td><td style=\"text-align: right;\">       37.1161</td><td style=\"text-align: right;\"> 1689741697</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">66517_00001</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "<tr><td>trainable_66517_00002</td><td>2023-07-18_23-41-32</td><td>True  </td><td>                </td><td>1d23d69fdb16408d99865784ef1c6842</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.980258</td><td>127.0.0.1</td><td style=\"text-align: right;\">60997</td><td>True               </td><td style=\"text-align: right;\">             20.6217</td><td style=\"text-align: right;\">           3.37932</td><td style=\"text-align: right;\">       20.6217</td><td style=\"text-align: right;\"> 1689741692</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00002</td><td style=\"text-align: right;\">    0.0152733</td></tr>\n",
       "<tr><td>trainable_66517_00003</td><td>2023-07-18_23-42-19</td><td>True  </td><td>                </td><td>6b6dd25ba6614851a9c1be3d148e2244</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        19</td><td style=\"text-align: right;\">   0.621437</td><td>127.0.0.1</td><td style=\"text-align: right;\">61003</td><td>True               </td><td style=\"text-align: right;\">             54.8792</td><td style=\"text-align: right;\">           2.79446</td><td style=\"text-align: right;\">       54.8792</td><td style=\"text-align: right;\"> 1689741739</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">66517_00003</td><td style=\"text-align: right;\">    0.0148442</td></tr>\n",
       "<tr><td>trainable_66517_00004</td><td>2023-07-18_23-41-45</td><td>True  </td><td>                </td><td>1d23d69fdb16408d99865784ef1c6842</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.400597</td><td>127.0.0.1</td><td style=\"text-align: right;\">60997</td><td>True               </td><td style=\"text-align: right;\">             13.3868</td><td style=\"text-align: right;\">           2.30602</td><td style=\"text-align: right;\">       13.3868</td><td style=\"text-align: right;\"> 1689741705</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00004</td><td style=\"text-align: right;\">    0.0152733</td></tr>\n",
       "<tr><td>trainable_66517_00005</td><td>2023-07-18_23-42-43</td><td>True  </td><td>                </td><td>417f9ae5c1854903be27731328334b0a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        24</td><td style=\"text-align: right;\">   0.72643 </td><td>127.0.0.1</td><td style=\"text-align: right;\">60992</td><td>True               </td><td style=\"text-align: right;\">             70.5027</td><td style=\"text-align: right;\">           4.67357</td><td style=\"text-align: right;\">       70.5027</td><td style=\"text-align: right;\"> 1689741763</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">66517_00005</td><td style=\"text-align: right;\">    0.0121198</td></tr>\n",
       "<tr><td>trainable_66517_00006</td><td>2023-07-18_23-41-59</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.730474</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             21.9233</td><td style=\"text-align: right;\">           3.19806</td><td style=\"text-align: right;\">       21.9233</td><td style=\"text-align: right;\"> 1689741719</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">66517_00006</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "<tr><td>trainable_66517_00007</td><td>2023-07-18_23-42-15</td><td>True  </td><td>                </td><td>1d23d69fdb16408d99865784ef1c6842</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.942733</td><td>127.0.0.1</td><td style=\"text-align: right;\">60997</td><td>True               </td><td style=\"text-align: right;\">             29.9384</td><td style=\"text-align: right;\">           5.18302</td><td style=\"text-align: right;\">       29.9384</td><td style=\"text-align: right;\"> 1689741735</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">66517_00007</td><td style=\"text-align: right;\">    0.0152733</td></tr>\n",
       "<tr><td>trainable_66517_00008</td><td>2023-07-18_23-42-49</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.732626</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             50.2309</td><td style=\"text-align: right;\">           7.08993</td><td style=\"text-align: right;\">       50.2309</td><td style=\"text-align: right;\"> 1689741769</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">66517_00008</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "<tr><td>trainable_66517_00009</td><td>2023-07-18_23-42-59</td><td>True  </td><td>                </td><td>1d23d69fdb16408d99865784ef1c6842</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.423679</td><td>127.0.0.1</td><td style=\"text-align: right;\">60997</td><td>True               </td><td style=\"text-align: right;\">             43.7766</td><td style=\"text-align: right;\">           3.32009</td><td style=\"text-align: right;\">       43.7766</td><td style=\"text-align: right;\"> 1689741779</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">66517_00009</td><td style=\"text-align: right;\">    0.0152733</td></tr>\n",
       "<tr><td>trainable_66517_00010</td><td>2023-07-18_23-42-37</td><td>True  </td><td>                </td><td>6b6dd25ba6614851a9c1be3d148e2244</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.976063</td><td>127.0.0.1</td><td style=\"text-align: right;\">61003</td><td>True               </td><td style=\"text-align: right;\">             18.2781</td><td style=\"text-align: right;\">           4.35143</td><td style=\"text-align: right;\">       18.2781</td><td style=\"text-align: right;\"> 1689741757</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00010</td><td style=\"text-align: right;\">    0.0148442</td></tr>\n",
       "<tr><td>trainable_66517_00011</td><td>2023-07-18_23-42-52</td><td>True  </td><td>                </td><td>6b6dd25ba6614851a9c1be3d148e2244</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.494539</td><td>127.0.0.1</td><td style=\"text-align: right;\">61003</td><td>True               </td><td style=\"text-align: right;\">             14.7201</td><td style=\"text-align: right;\">           2.66156</td><td style=\"text-align: right;\">       14.7201</td><td style=\"text-align: right;\"> 1689741772</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00011</td><td style=\"text-align: right;\">    0.0148442</td></tr>\n",
       "<tr><td>trainable_66517_00012</td><td>2023-07-18_23-42-57</td><td>True  </td><td>                </td><td>417f9ae5c1854903be27731328334b0a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.983268</td><td>127.0.0.1</td><td style=\"text-align: right;\">60992</td><td>True               </td><td style=\"text-align: right;\">             14.0853</td><td style=\"text-align: right;\">           2.5364 </td><td style=\"text-align: right;\">       14.0853</td><td style=\"text-align: right;\"> 1689741777</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00012</td><td style=\"text-align: right;\">    0.0121198</td></tr>\n",
       "<tr><td>trainable_66517_00013</td><td>2023-07-18_23-43-02</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.527371</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             11.7794</td><td style=\"text-align: right;\">           2.16247</td><td style=\"text-align: right;\">       11.7794</td><td style=\"text-align: right;\"> 1689741782</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00013</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "<tr><td>trainable_66517_00014</td><td>2023-07-18_23-43-03</td><td>True  </td><td>                </td><td>6b6dd25ba6614851a9c1be3d148e2244</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.551788</td><td>127.0.0.1</td><td style=\"text-align: right;\">61003</td><td>True               </td><td style=\"text-align: right;\">             10.4219</td><td style=\"text-align: right;\">           1.80753</td><td style=\"text-align: right;\">       10.4219</td><td style=\"text-align: right;\"> 1689741783</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00014</td><td style=\"text-align: right;\">    0.0148442</td></tr>\n",
       "<tr><td>trainable_66517_00015</td><td>2023-07-18_23-43-49</td><td>True  </td><td>                </td><td>417f9ae5c1854903be27731328334b0a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        17</td><td style=\"text-align: right;\">   0.885778</td><td>127.0.0.1</td><td style=\"text-align: right;\">60992</td><td>True               </td><td style=\"text-align: right;\">             52.1877</td><td style=\"text-align: right;\">           1.68166</td><td style=\"text-align: right;\">       52.1877</td><td style=\"text-align: right;\"> 1689741829</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  17</td><td style=\"text-align: right;\">66517_00015</td><td style=\"text-align: right;\">    0.0121198</td></tr>\n",
       "<tr><td>trainable_66517_00016</td><td>2023-07-18_23-43-28</td><td>True  </td><td>                </td><td>1d23d69fdb16408d99865784ef1c6842</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.498791</td><td>127.0.0.1</td><td style=\"text-align: right;\">60997</td><td>True               </td><td style=\"text-align: right;\">             27.9648</td><td style=\"text-align: right;\">           6.0755 </td><td style=\"text-align: right;\">       27.9648</td><td style=\"text-align: right;\"> 1689741808</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00016</td><td style=\"text-align: right;\">    0.0152733</td></tr>\n",
       "<tr><td>trainable_66517_00017</td><td>2023-07-18_23-43-21</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.930684</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             19.1491</td><td style=\"text-align: right;\">           4.25242</td><td style=\"text-align: right;\">       19.1491</td><td style=\"text-align: right;\"> 1689741801</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00017</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "<tr><td>trainable_66517_00018</td><td>2023-07-18_23-43-39</td><td>True  </td><td>                </td><td>6b6dd25ba6614851a9c1be3d148e2244</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.950355</td><td>127.0.0.1</td><td style=\"text-align: right;\">61003</td><td>True               </td><td style=\"text-align: right;\">             35.37  </td><td style=\"text-align: right;\">           3.67484</td><td style=\"text-align: right;\">       35.37  </td><td style=\"text-align: right;\"> 1689741819</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">66517_00018</td><td style=\"text-align: right;\">    0.0148442</td></tr>\n",
       "<tr><td>trainable_66517_00019</td><td>2023-07-18_23-43-35</td><td>True  </td><td>                </td><td>8f7b1efc37324c519446670ee14db0f3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982293</td><td>127.0.0.1</td><td style=\"text-align: right;\">60993</td><td>True               </td><td style=\"text-align: right;\">             13.905 </td><td style=\"text-align: right;\">           2.01781</td><td style=\"text-align: right;\">       13.905 </td><td style=\"text-align: right;\"> 1689741815</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">66517_00019</td><td style=\"text-align: right;\">    0.0124559</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# create the PBT trainer - the entire search space eligible for mutation\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\", hyperparam_mutations=space\n",
    ")\n",
    "\n",
    "# run trials with the PBT trainer\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"pbt\", num_samples=20, scheduler=scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d0c46",
   "metadata": {},
   "source": [
    "### Compare PBT and default experiment performance statistics\n",
    "\n",
    "Plot the PBT trial performance alongside the default AsyncHyperband results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70760bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get dataframe from default experiment\n",
    "pbt_table = results.get_dataframe()\n",
    "pbt_auc = np.array(pbt_table[\"mnist_auc\"])\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(-np.sort(-default_auc))\n",
    "ax1.plot(-np.sort(-pbt_auc))\n",
    "ax1.set_title(\"All trials\")\n",
    "ax1.set_xlabel(\"trial\")\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.legend([\"random\", \"population-based\"])\n",
    "ax2.plot(-np.sort(-default_auc)[0:5])\n",
    "ax2.plot(-np.sort(-pbt_auc)[0:5])\n",
    "ax2.set_title(\"Top 5 trials\")\n",
    "ax2.set_xlabel(\"trial\")\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.legend([\"random\", \"population-based\"])\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108775e7",
   "metadata": {},
   "source": [
    "### Change trial resources\n",
    "\n",
    "The `ray.air.ScalingConfig` determines the resources available during experiments, and can be used to set the number of workers and availability of GPUs. Additional parameters are available for running on multiple machine using a Ray cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040a3111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-18 23:49:05</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:16.95        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.7/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 40.000: None | Iter 10.000: 0.8155681490898132<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  data/batch_size</th><th style=\"text-align: right;\">  data/max_delta</th><th>data/random_brightne\n",
       "ss      </th><th>layer1/activation  </th><th style=\"text-align: right;\">  layer1/dropout</th><th style=\"text-align: right;\">  layer1/units</th><th style=\"text-align: right;\">  optimization/beta_1</th><th style=\"text-align: right;\">  optimization/beta_2</th><th style=\"text-align: right;\">     optimization/ema_mom\n",
       "entum</th><th style=\"text-align: right;\">  optimization/ema_ove\n",
       "rwrite_frequency</th><th style=\"text-align: right;\">        optimization/learnin\n",
       "g_rate</th><th>optimization/method  </th><th style=\"text-align: right;\">     optimization/momentu\n",
       "m</th><th style=\"text-align: right;\">  optimization/rho</th><th>optimization/use_ema  </th><th>tasks/mnist/activati\n",
       "on         </th><th style=\"text-align: right;\">  tasks/mnist/dropout</th><th>tasks/mnist/loss    </th><th style=\"text-align: right;\">     tasks/mnist/loss/kwa\n",
       "rgs/label_smoothing</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mnist_auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_45711_00000</td><td>TERMINATED</td><td>127.0.0.1:61080</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.12</td><td>True </td><td>relu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">                 0.99</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00768</td><td>sgd                  </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.66</td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_ffc0</td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        38.1307 </td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_45711_00001</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.1 </td><td>True </td><td>elu                </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.72</td><td style=\"text-align: right;\">                 0.75</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00751</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.71</td><td>False                 </td><td>relu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_1b00</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         7.3992 </td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_45711_00002</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.1 </td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.55</td><td style=\"text-align: right;\">                 0.57</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00252</td><td>adam                 </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">              0.67</td><td>True                  </td><td>relu    </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_1ec0</td><td style=\"text-align: right;\">0.16</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        17.4834 </td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_45711_00003</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.03</td><td>False</td><td>elu                </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">                 0.83</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00577</td><td>adam                 </td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">              0.73</td><td>False                 </td><td>relu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_16c0</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         9.21921</td><td style=\"text-align: right;\">   0       </td></tr>\n",
       "<tr><td>trainable_45711_00004</td><td>TERMINATED</td><td>127.0.0.1:61080</td><td style=\"text-align: right;\">               64</td><td style=\"text-align: right;\">            0.03</td><td>True </td><td>softplus           </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.74</td><td style=\"text-align: right;\">                 0.66</td><td style=\"text-align: right;\">0.93</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0.00214</td><td>adadelta             </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">              0.95</td><td>True                  </td><td>sigmoid </td><td style=\"text-align: right;\">                 0   </td><td>{&#x27;name&#x27;: &#x27;categ_5a40</td><td style=\"text-align: right;\">0.19</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">        43.8613 </td><td style=\"text-align: right;\">   0.687347</td></tr>\n",
       "<tr><td>trainable_45711_00005</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.07</td><td>False</td><td>relu               </td><td style=\"text-align: right;\">            0.1 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.71</td><td style=\"text-align: right;\">0.91</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00256</td><td>adam                 </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.82</td><td>True                  </td><td>gelu    </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_65c0</td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        42.0058 </td><td style=\"text-align: right;\">   0.773386</td></tr>\n",
       "<tr><td>trainable_45711_00006</td><td>TERMINATED</td><td>127.0.0.1:61080</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.04</td><td>True </td><td>selu               </td><td style=\"text-align: right;\">            0.15</td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.81</td><td style=\"text-align: right;\">                 0.7 </td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00189</td><td>adagrad              </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">              0.73</td><td>True                  </td><td>elu     </td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_b8c0</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        16.4699 </td><td style=\"text-align: right;\">   0.935955</td></tr>\n",
       "<tr><td>trainable_45711_00007</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.06</td><td>False</td><td>selu               </td><td style=\"text-align: right;\">            0   </td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.8 </td><td style=\"text-align: right;\">                 0.89</td><td style=\"text-align: right;\">0.92</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">0.00401</td><td>rms                  </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">              0.59</td><td>False                 </td><td>sigmoid </td><td style=\"text-align: right;\">                 0.15</td><td>{&#x27;name&#x27;: &#x27;categ_9c80</td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        15.4527 </td><td style=\"text-align: right;\">   0.963932</td></tr>\n",
       "<tr><td>trainable_45711_00008</td><td>TERMINATED</td><td>127.0.0.1:61080</td><td style=\"text-align: right;\">               32</td><td style=\"text-align: right;\">            0.08</td><td>True </td><td>sigmoid            </td><td style=\"text-align: right;\">            0.2 </td><td style=\"text-align: right;\">            48</td><td style=\"text-align: right;\">                 0.54</td><td style=\"text-align: right;\">                 0.58</td><td style=\"text-align: right;\">0.94</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.00697</td><td>rms                  </td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">              0.84</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.05</td><td>{&#x27;name&#x27;: &#x27;categ_8e80</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">        26.1091 </td><td style=\"text-align: right;\">   0.501639</td></tr>\n",
       "<tr><td>trainable_45711_00009</td><td>TERMINATED</td><td>127.0.0.1:61081</td><td style=\"text-align: right;\">              128</td><td style=\"text-align: right;\">            0.11</td><td>True </td><td>relu               </td><td style=\"text-align: right;\">            0.05</td><td style=\"text-align: right;\">            32</td><td style=\"text-align: right;\">                 0.86</td><td style=\"text-align: right;\">                 0.56</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.00195</td><td>adam                 </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">              0.72</td><td>True                  </td><td>softplus</td><td style=\"text-align: right;\">                 0.1 </td><td>{&#x27;name&#x27;: &#x27;categ_5d00</td><td style=\"text-align: right;\">0.18</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        16.4699 </td><td style=\"text-align: right;\">   0.775439</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">   trial_id</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_45711_00000</td><td>2023-07-18_23-47-38</td><td>True  </td><td>                </td><td>1adb47c4afce41d796438362f073012c</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61080</td><td>True               </td><td style=\"text-align: right;\">            38.1307 </td><td style=\"text-align: right;\">           4.49314</td><td style=\"text-align: right;\">      38.1307 </td><td style=\"text-align: right;\"> 1689742058</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">45711_00000</td><td style=\"text-align: right;\">    0.0119898</td></tr>\n",
       "<tr><td>trainable_45711_00001</td><td>2023-07-18_23-47-19</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">             7.3992 </td><td style=\"text-align: right;\">           1.31765</td><td style=\"text-align: right;\">       7.3992 </td><td style=\"text-align: right;\"> 1689742039</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">45711_00001</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "<tr><td>trainable_45711_00002</td><td>2023-07-18_23-47-37</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">            17.4834 </td><td style=\"text-align: right;\">           5.00419</td><td style=\"text-align: right;\">      17.4834 </td><td style=\"text-align: right;\"> 1689742057</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">45711_00002</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "<tr><td>trainable_45711_00003</td><td>2023-07-18_23-47-46</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">             9.21921</td><td style=\"text-align: right;\">           2.45931</td><td style=\"text-align: right;\">       9.21921</td><td style=\"text-align: right;\"> 1689742066</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">45711_00003</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "<tr><td>trainable_45711_00004</td><td>2023-07-18_23-48-22</td><td>True  </td><td>                </td><td>1adb47c4afce41d796438362f073012c</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        19</td><td style=\"text-align: right;\">   0.687347</td><td>127.0.0.1</td><td style=\"text-align: right;\">61080</td><td>True               </td><td style=\"text-align: right;\">            43.8613 </td><td style=\"text-align: right;\">           1.93431</td><td style=\"text-align: right;\">      43.8613 </td><td style=\"text-align: right;\"> 1689742102</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">45711_00004</td><td style=\"text-align: right;\">    0.0119898</td></tr>\n",
       "<tr><td>trainable_45711_00005</td><td>2023-07-18_23-48-28</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.773386</td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">            42.0058 </td><td style=\"text-align: right;\">           4.55036</td><td style=\"text-align: right;\">      42.0058 </td><td style=\"text-align: right;\"> 1689742108</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">45711_00005</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "<tr><td>trainable_45711_00006</td><td>2023-07-18_23-48-39</td><td>True  </td><td>                </td><td>1adb47c4afce41d796438362f073012c</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.935955</td><td>127.0.0.1</td><td style=\"text-align: right;\">61080</td><td>True               </td><td style=\"text-align: right;\">            16.4699 </td><td style=\"text-align: right;\">           1.45931</td><td style=\"text-align: right;\">      16.4699 </td><td style=\"text-align: right;\"> 1689742119</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">45711_00006</td><td style=\"text-align: right;\">    0.0119898</td></tr>\n",
       "<tr><td>trainable_45711_00007</td><td>2023-07-18_23-48-44</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.963932</td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">            15.4527 </td><td style=\"text-align: right;\">           3.43986</td><td style=\"text-align: right;\">      15.4527 </td><td style=\"text-align: right;\"> 1689742124</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">45711_00007</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "<tr><td>trainable_45711_00008</td><td>2023-07-18_23-49-05</td><td>True  </td><td>                </td><td>1adb47c4afce41d796438362f073012c</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.501639</td><td>127.0.0.1</td><td style=\"text-align: right;\">61080</td><td>True               </td><td style=\"text-align: right;\">            26.1091 </td><td style=\"text-align: right;\">           2.95803</td><td style=\"text-align: right;\">      26.1091 </td><td style=\"text-align: right;\"> 1689742145</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">45711_00008</td><td style=\"text-align: right;\">    0.0119898</td></tr>\n",
       "<tr><td>trainable_45711_00009</td><td>2023-07-18_23-49-01</td><td>True  </td><td>                </td><td>ae969c9cbf9c460bb42fa989f54f44ba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.775439</td><td>127.0.0.1</td><td style=\"text-align: right;\">61081</td><td>True               </td><td style=\"text-align: right;\">            16.4699 </td><td style=\"text-align: right;\">           1.61893</td><td style=\"text-align: right;\">      16.4699 </td><td style=\"text-align: right;\"> 1689742141</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">45711_00009</td><td style=\"text-align: right;\">    0.0117772</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# alter the scaling parameters so that each trial gets 2 cores\n",
    "tuner.set_scaling(\n",
    "    num_workers=1,\n",
    "    use_gpu=False,\n",
    "    resources_per_worker={\"CPU\": 2, \"GPU\": 0},\n",
    ")\n",
    "\n",
    "# run 10 trials with the PBT trainer\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"resources\", num_samples=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfefe22",
   "metadata": {},
   "source": [
    "### Reporting\n",
    "\n",
    "Reporting options can also be set by using `Search.set_reporter` method or by creating a reporter object and assigning this directly to the `Search.reporter` attribute. This allows use of additional parameters not exposed by `set_reporter`.\n",
    "\n",
    "Here we setup a CLI trainer with customized report columns and re-run an experiment. Since we are running in Jupyter, the dynamic table is also automatically displayed too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2a9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:49:38 (running for 00:00:00.25)\n",
      "Memory usage on this node: 9.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/try\n",
      "Number of trials: 8/10 (7 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+----------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_aa42e_00000 | RUNNING  | 127.0.0.1:61097 | sgd      |         0.00912 |             48 |\n",
      "| trainable_aa42e_00001 | PENDING  |                 | adadelta |         0.00587 |             32 |\n",
      "| trainable_aa42e_00002 | PENDING  |                 | rms      |         0.00059 |             32 |\n",
      "| trainable_aa42e_00003 | PENDING  |                 | sgd      |         0.00052 |             64 |\n",
      "| trainable_aa42e_00004 | PENDING  |                 | adam     |         0.00923 |             64 |\n",
      "| trainable_aa42e_00005 | PENDING  |                 | adadelta |         0.00803 |             32 |\n",
      "| trainable_aa42e_00006 | PENDING  |                 | adam     |         0.00664 |             16 |\n",
      "| trainable_aa42e_00007 | PENDING  |                 | rms      |         0.00853 |             64 |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_aa42e_00000</td><td>2023-07-18_23-49-57</td><td>True  </td><td>                </td><td>a3ac4047e98845e783f678aba1b18288</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.943636</td><td>127.0.0.1</td><td style=\"text-align: right;\">61097</td><td>True               </td><td style=\"text-align: right;\">             8.79616</td><td style=\"text-align: right;\">           1.40641</td><td style=\"text-align: right;\">       8.79616</td><td style=\"text-align: right;\"> 1689742197</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00000</td><td style=\"text-align: right;\">    0.0130482</td></tr>\n",
       "<tr><td>trainable_aa42e_00001</td><td>2023-07-18_23-50-18</td><td>True  </td><td>                </td><td>e4c6c3303e554323941f5ff71b0cc52a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.549104</td><td>127.0.0.1</td><td style=\"text-align: right;\">61098</td><td>True               </td><td style=\"text-align: right;\">            13.1109 </td><td style=\"text-align: right;\">           2.55523</td><td style=\"text-align: right;\">      13.1109 </td><td style=\"text-align: right;\"> 1689742218</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00001</td><td style=\"text-align: right;\">    0.0169458</td></tr>\n",
       "<tr><td>trainable_aa42e_00002</td><td>2023-07-18_23-50-22</td><td>True  </td><td>                </td><td>b9c0a5b30b204be9b12891be4927f6d3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982218</td><td>127.0.0.1</td><td style=\"text-align: right;\">61099</td><td>True               </td><td style=\"text-align: right;\">            17.0854 </td><td style=\"text-align: right;\">           3.63675</td><td style=\"text-align: right;\">      17.0854 </td><td style=\"text-align: right;\"> 1689742222</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00002</td><td style=\"text-align: right;\">    0.0168018</td></tr>\n",
       "<tr><td>trainable_aa42e_00003</td><td>2023-07-18_23-50-30</td><td>True  </td><td>                </td><td>80717b5385a84515a05f2c42d946ef0e</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         9</td><td style=\"text-align: right;\">   0.938697</td><td>127.0.0.1</td><td style=\"text-align: right;\">61101</td><td>True               </td><td style=\"text-align: right;\">            24.4535 </td><td style=\"text-align: right;\">           2.0569 </td><td style=\"text-align: right;\">      24.4535 </td><td style=\"text-align: right;\"> 1689742230</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   9</td><td>aa42e_00003</td><td style=\"text-align: right;\">    0.0203612</td></tr>\n",
       "<tr><td>trainable_aa42e_00004</td><td>2023-07-18_23-50-12</td><td>True  </td><td>                </td><td>a3ac4047e98845e783f678aba1b18288</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.97792 </td><td>127.0.0.1</td><td style=\"text-align: right;\">61097</td><td>True               </td><td style=\"text-align: right;\">            15.354  </td><td style=\"text-align: right;\">           3.37139</td><td style=\"text-align: right;\">      15.354  </td><td style=\"text-align: right;\"> 1689742212</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00004</td><td style=\"text-align: right;\">    0.0130482</td></tr>\n",
       "<tr><td>trainable_aa42e_00005</td><td>2023-07-18_23-50-35</td><td>True  </td><td>                </td><td>a3ac4047e98845e783f678aba1b18288</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.944315</td><td>127.0.0.1</td><td style=\"text-align: right;\">61097</td><td>True               </td><td style=\"text-align: right;\">            22.1688 </td><td style=\"text-align: right;\">           1.64533</td><td style=\"text-align: right;\">      22.1688 </td><td style=\"text-align: right;\"> 1689742235</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>aa42e_00005</td><td style=\"text-align: right;\">    0.0130482</td></tr>\n",
       "<tr><td>trainable_aa42e_00006</td><td>2023-07-18_23-50-30</td><td>True  </td><td>                </td><td>e4c6c3303e554323941f5ff71b0cc52a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.967162</td><td>127.0.0.1</td><td style=\"text-align: right;\">61098</td><td>True               </td><td style=\"text-align: right;\">            11.3981 </td><td style=\"text-align: right;\">           1.93006</td><td style=\"text-align: right;\">      11.3981 </td><td style=\"text-align: right;\"> 1689742230</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00006</td><td style=\"text-align: right;\">    0.0169458</td></tr>\n",
       "<tr><td>trainable_aa42e_00007</td><td>2023-07-18_23-50-44</td><td>True  </td><td>                </td><td>b9c0a5b30b204be9b12891be4927f6d3</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61099</td><td>True               </td><td style=\"text-align: right;\">            21.2499 </td><td style=\"text-align: right;\">           4.19278</td><td style=\"text-align: right;\">      21.2499 </td><td style=\"text-align: right;\"> 1689742244</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00007</td><td style=\"text-align: right;\">    0.0168018</td></tr>\n",
       "<tr><td>trainable_aa42e_00008</td><td>2023-07-18_23-50-46</td><td>True  </td><td>                </td><td>80717b5385a84515a05f2c42d946ef0e</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.968094</td><td>127.0.0.1</td><td style=\"text-align: right;\">61101</td><td>True               </td><td style=\"text-align: right;\">            16.5052 </td><td style=\"text-align: right;\">           1.69695</td><td style=\"text-align: right;\">      16.5052 </td><td style=\"text-align: right;\"> 1689742246</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>aa42e_00008</td><td style=\"text-align: right;\">    0.0203612</td></tr>\n",
       "<tr><td>trainable_aa42e_00009</td><td>2023-07-18_23-50-43</td><td>True  </td><td>                </td><td>e4c6c3303e554323941f5ff71b0cc52a</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.535929</td><td>127.0.0.1</td><td style=\"text-align: right;\">61098</td><td>True               </td><td style=\"text-align: right;\">            12.7565 </td><td style=\"text-align: right;\">           2.70256</td><td style=\"text-align: right;\">      12.7565 </td><td style=\"text-align: right;\"> 1689742243</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>aa42e_00009</td><td style=\"text-align: right;\">    0.0169458</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:50:09 (running for 00:00:31.48)\n",
      "Memory usage on this node: 9.6/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: aa42e_00004 with mnist_auc=0.9794985055923462 and parameters={'optimization/method': 'adam', 'optimization/learning_rate': 0.00923, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/try\n",
      "Number of trials: 9/10 (4 PENDING, 4 RUNNING, 1 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_aa42e_00001 | RUNNING    | 127.0.0.1:61098 | adadelta |         0.00587 |             32 |\n",
      "| trainable_aa42e_00002 | RUNNING    | 127.0.0.1:61099 | rms      |         0.00059 |             32 |\n",
      "| trainable_aa42e_00003 | RUNNING    | 127.0.0.1:61101 | sgd      |         0.00052 |             64 |\n",
      "| trainable_aa42e_00004 | RUNNING    | 127.0.0.1:61097 | adam     |         0.00923 |             64 |\n",
      "| trainable_aa42e_00005 | PENDING    |                 | adadelta |         0.00803 |             32 |\n",
      "| trainable_aa42e_00006 | PENDING    |                 | adam     |         0.00664 |             16 |\n",
      "| trainable_aa42e_00007 | PENDING    |                 | rms      |         0.00853 |             64 |\n",
      "| trainable_aa42e_00008 | PENDING    |                 | adagrad  |         0.00733 |             64 |\n",
      "| trainable_aa42e_00000 | TERMINATED | 127.0.0.1:61097 | sgd      |         0.00912 |             48 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:50:39 (running for 00:01:02.09)\n",
      "Memory usage on this node: 9.2/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9443154335021973\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: aa42e_00002 with mnist_auc=0.9822177886962891 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00059, 'layer1/units': 32}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/try\n",
      "Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_aa42e_00007 | RUNNING    | 127.0.0.1:61099 | rms      |         0.00853 |             64 |\n",
      "| trainable_aa42e_00008 | RUNNING    | 127.0.0.1:61101 | adagrad  |         0.00733 |             64 |\n",
      "| trainable_aa42e_00009 | RUNNING    | 127.0.0.1:61098 | adadelta |         0.00257 |             16 |\n",
      "| trainable_aa42e_00000 | TERMINATED | 127.0.0.1:61097 | sgd      |         0.00912 |             48 |\n",
      "| trainable_aa42e_00001 | TERMINATED | 127.0.0.1:61098 | adadelta |         0.00587 |             32 |\n",
      "| trainable_aa42e_00002 | TERMINATED | 127.0.0.1:61099 | rms      |         0.00059 |             32 |\n",
      "| trainable_aa42e_00003 | TERMINATED | 127.0.0.1:61101 | sgd      |         0.00052 |             64 |\n",
      "| trainable_aa42e_00004 | TERMINATED | 127.0.0.1:61097 | adam     |         0.00923 |             64 |\n",
      "| trainable_aa42e_00005 | TERMINATED | 127.0.0.1:61097 | adadelta |         0.00803 |             32 |\n",
      "| trainable_aa42e_00006 | TERMINATED | 127.0.0.1:61098 | adam     |         0.00664 |             16 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:50:46 (running for 00:01:09.01)\n",
      "Memory usage on this node: 8.6/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9443154335021973\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: aa42e_00002 with mnist_auc=0.9822177886962891 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00059, 'layer1/units': 32}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/try\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_aa42e_00000 | TERMINATED | 127.0.0.1:61097 | sgd      |         0.00912 |             48 |\n",
      "| trainable_aa42e_00001 | TERMINATED | 127.0.0.1:61098 | adadelta |         0.00587 |             32 |\n",
      "| trainable_aa42e_00002 | TERMINATED | 127.0.0.1:61099 | rms      |         0.00059 |             32 |\n",
      "| trainable_aa42e_00003 | TERMINATED | 127.0.0.1:61101 | sgd      |         0.00052 |             64 |\n",
      "| trainable_aa42e_00004 | TERMINATED | 127.0.0.1:61097 | adam     |         0.00923 |             64 |\n",
      "| trainable_aa42e_00005 | TERMINATED | 127.0.0.1:61097 | adadelta |         0.00803 |             32 |\n",
      "| trainable_aa42e_00006 | TERMINATED | 127.0.0.1:61098 | adam     |         0.00664 |             16 |\n",
      "| trainable_aa42e_00007 | TERMINATED | 127.0.0.1:61099 | rms      |         0.00853 |             64 |\n",
      "| trainable_aa42e_00008 | TERMINATED | 127.0.0.1:61101 | adagrad  |         0.00733 |             64 |\n",
      "| trainable_aa42e_00009 | TERMINATED | 127.0.0.1:61098 | adadelta |         0.00257 |             16 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import CLIReporter\n",
    "\n",
    "# report every 30 seconds\n",
    "max_report_frequency = 30\n",
    "\n",
    "# set Jupyter preference\n",
    "jupyter = False\n",
    "\n",
    "# set metrics, parameters to display\n",
    "metrics = [f\"{t}_{m}\" for t in space[\"tasks\"] for m in space[\"tasks\"][t][\"metrics\"]]\n",
    "parameters = {\n",
    "    \"optimization/method\": \"method\",\n",
    "    \"optimization/learning_rate\": \"learning rate\",\n",
    "    \"layer1/units\": \"layer1_units\",\n",
    "}\n",
    "\n",
    "# set reporter kwargs\n",
    "reporter_kwargs = {\n",
    "    \"metric_columns\": metrics,\n",
    "    \"parameter_columns\": parameters,\n",
    "    \"max_report_frequency\": max_report_frequency,\n",
    "}\n",
    "\n",
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# assign reporter to attribute and run a short trial\n",
    "tuner.reporter = CLIReporter(**reporter_kwargs)\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"try\", num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab9d8c",
   "metadata": {},
   "source": [
    "### Restarting an interrupted experiment\n",
    "\n",
    "We can restart an experiment that has been interrupted to complete unfinished trials using `Search.restore`.\n",
    "\n",
    "Interrupt the execution of this cell and then execute the cell below to complete the unexecuted trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a93a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:51:26 (running for 00:00:00.20)\n",
      "Memory usage on this node: 8.5/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 8/50 (7 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+----------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00000 | RUNNING  | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | PENDING  |                 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | PENDING  |                 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | PENDING  |                 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | PENDING  |                 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | PENDING  |                 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | PENDING  |                 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | PENDING  |                 | rms      |         0.00064 |             32 |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_eb105_00000</td><td>2023-07-18_23-52-18</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.605388</td><td>127.0.0.1</td><td style=\"text-align: right;\">61130</td><td>True               </td><td style=\"text-align: right;\">            42.7094 </td><td style=\"text-align: right;\">           3.92997</td><td style=\"text-align: right;\">      42.7094 </td><td style=\"text-align: right;\"> 1689742338</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00000</td><td style=\"text-align: right;\">    0.0112081</td></tr>\n",
       "<tr><td>trainable_eb105_00001</td><td>2023-07-18_23-52-02</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.480263</td><td>127.0.0.1</td><td style=\"text-align: right;\">61131</td><td>True               </td><td style=\"text-align: right;\">            13.0845 </td><td style=\"text-align: right;\">           2.63219</td><td style=\"text-align: right;\">      13.0845 </td><td style=\"text-align: right;\"> 1689742322</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00001</td><td style=\"text-align: right;\">    0.0186222</td></tr>\n",
       "<tr><td>trainable_eb105_00002</td><td>2023-07-18_23-52-26</td><td>False </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        19</td><td style=\"text-align: right;\">   0.775372</td><td>127.0.0.1</td><td style=\"text-align: right;\">61132</td><td>True               </td><td style=\"text-align: right;\">            37.3265 </td><td style=\"text-align: right;\">           1.8712 </td><td style=\"text-align: right;\">      37.3265 </td><td style=\"text-align: right;\"> 1689742346</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  19</td><td>eb105_00002</td><td style=\"text-align: right;\">    0.015439 </td></tr>\n",
       "<tr><td>trainable_eb105_00003</td><td>2023-07-18_23-51-58</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.509202</td><td>127.0.0.1</td><td style=\"text-align: right;\">61133</td><td>True               </td><td style=\"text-align: right;\">             9.26188</td><td style=\"text-align: right;\">           1.79699</td><td style=\"text-align: right;\">       9.26188</td><td style=\"text-align: right;\"> 1689742318</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00003</td><td style=\"text-align: right;\">    0.016408 </td></tr>\n",
       "<tr><td>trainable_eb105_00004</td><td>2023-07-18_23-52-18</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.978832</td><td>127.0.0.1</td><td style=\"text-align: right;\">61133</td><td>True               </td><td style=\"text-align: right;\">            19.9414 </td><td style=\"text-align: right;\">           4.58237</td><td style=\"text-align: right;\">      19.9414 </td><td style=\"text-align: right;\"> 1689742338</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00004</td><td style=\"text-align: right;\">    0.016408 </td></tr>\n",
       "<tr><td>trainable_eb105_00005</td><td>2023-07-18_23-52-21</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982704</td><td>127.0.0.1</td><td style=\"text-align: right;\">61131</td><td>True               </td><td style=\"text-align: right;\">            19.3173 </td><td style=\"text-align: right;\">           4.16249</td><td style=\"text-align: right;\">      19.3173 </td><td style=\"text-align: right;\"> 1689742341</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00005</td><td style=\"text-align: right;\">    0.0186222</td></tr>\n",
       "<tr><td>trainable_eb105_00006</td><td>2023-07-18_23-52-25</td><td>False </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   0.972966</td><td>127.0.0.1</td><td style=\"text-align: right;\">61133</td><td>True               </td><td style=\"text-align: right;\">             6.36921</td><td style=\"text-align: right;\">           6.36921</td><td style=\"text-align: right;\">       6.36921</td><td style=\"text-align: right;\"> 1689742345</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>eb105_00006</td><td style=\"text-align: right;\">    0.016408 </td></tr>\n",
       "<tr><td>trainable_eb105_00007</td><td>2023-07-18_23-52-29</td><td>False </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">   0.605372</td><td>127.0.0.1</td><td style=\"text-align: right;\">61130</td><td>True               </td><td style=\"text-align: right;\">            10.2178 </td><td style=\"text-align: right;\">           2.9928 </td><td style=\"text-align: right;\">      10.2178 </td><td style=\"text-align: right;\"> 1689742349</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   3</td><td>eb105_00007</td><td style=\"text-align: right;\">    0.0112081</td></tr>\n",
       "<tr><td>trainable_eb105_00008</td><td>2023-07-18_23-52-28</td><td>False </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">   0.784527</td><td>127.0.0.1</td><td style=\"text-align: right;\">61131</td><td>True               </td><td style=\"text-align: right;\">             6.39498</td><td style=\"text-align: right;\">           6.39498</td><td style=\"text-align: right;\">       6.39498</td><td style=\"text-align: right;\"> 1689742348</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>eb105_00008</td><td style=\"text-align: right;\">    0.0186222</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:51:56 (running for 00:00:30.27)\n",
      "Memory usage on this node: 9.6/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00002 with mnist_auc=0.7731320858001709 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00738, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 8/50 (4 PENDING, 4 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+----------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00000 | RUNNING  | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | RUNNING  | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | RUNNING  | 127.0.0.1:61132 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | RUNNING  | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | PENDING  |                 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | PENDING  |                 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | PENDING  |                 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | PENDING  |                 | rms      |         0.00064 |             32 |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:52:28 (running for 00:01:01.79)\n",
      "Memory usage on this node: 9.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.714351549744606\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00005 with mnist_auc=0.9827035665512085 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0027600000000000003, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 13/50 (4 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00002 | RUNNING    | 127.0.0.1:61132 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00006 | RUNNING    | 127.0.0.1:61133 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | RUNNING    | 127.0.0.1:61130 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | RUNNING    | 127.0.0.1:61131 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | PENDING    |                 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | PENDING    |                 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | PENDING    |                 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | PENDING    |                 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:52:29 (running for 00:01:02.73)\n",
      "Memory usage on this node: 9.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.714351549744606\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00005 with mnist_auc=0.9827035665512085 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0027600000000000003, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 13/50 (4 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00002 | RUNNING    | 127.0.0.1:61132 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00006 | RUNNING    | 127.0.0.1:61133 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | RUNNING    | 127.0.0.1:61130 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | RUNNING    | 127.0.0.1:61131 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | PENDING    |                 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | PENDING    |                 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | PENDING    |                 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | PENDING    |                 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# assign reporter to attribute and run a short trial\n",
    "tuner.reporter = CLIReporter(**reporter_kwargs)\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"restore\", num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "081a42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:52:40 (running for 00:00:00.44)\n",
      "Memory usage on this node: 8.6/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00005 with mnist_auc=0.9827035665512085 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0027600000000000003, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 13/50 (7 PENDING, 1 RUNNING, 5 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00007 | RUNNING    | 127.0.0.1:61130 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00002 | PENDING    | 127.0.0.1:61132 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00008 | PENDING    | 127.0.0.1:61131 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00006 | PENDING    | 127.0.0.1:61133 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00009 | PENDING    |                 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | PENDING    |                 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | PENDING    |                 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | PENDING    |                 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_eb105_00002</td><td>2023-07-18_23-53-14</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">   0.83309 </td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            20.7212 </td><td style=\"text-align: right;\">           2.9054 </td><td style=\"text-align: right;\">      60.0506 </td><td style=\"text-align: right;\"> 1689742394</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  28</td><td>eb105_00002</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00006</td><td>2023-07-18_23-53-12</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">   0.982309</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            18.7695 </td><td style=\"text-align: right;\">           7.05119</td><td style=\"text-align: right;\">      25.1387 </td><td style=\"text-align: right;\"> 1689742392</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00006</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00007</td><td>2023-07-18_23-53-20</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.521897</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            27.2254 </td><td style=\"text-align: right;\">           3.53936</td><td style=\"text-align: right;\">      34.4504 </td><td style=\"text-align: right;\"> 1689742400</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   9</td><td>eb105_00007</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00008</td><td>2023-07-18_23-53-36</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.911586</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            42.7541 </td><td style=\"text-align: right;\">           5.5732 </td><td style=\"text-align: right;\">      49.1491 </td><td style=\"text-align: right;\"> 1689742416</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   8</td><td>eb105_00008</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00009</td><td>2023-07-18_23-53-53</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">   0.913784</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            41.1957 </td><td style=\"text-align: right;\">           3.00925</td><td style=\"text-align: right;\">      41.1957 </td><td style=\"text-align: right;\"> 1689742433</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>eb105_00009</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00010</td><td>2023-07-18_23-53-57</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.946056</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            43.1756 </td><td style=\"text-align: right;\">           4.85786</td><td style=\"text-align: right;\">      43.1756 </td><td style=\"text-align: right;\"> 1689742437</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>eb105_00010</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00011</td><td>2023-07-18_23-53-32</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.484032</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            11.2196 </td><td style=\"text-align: right;\">           2.00628</td><td style=\"text-align: right;\">      11.2196 </td><td style=\"text-align: right;\"> 1689742412</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00011</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00012</td><td>2023-07-18_23-53-41</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982786</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">             9.35969</td><td style=\"text-align: right;\">           1.79664</td><td style=\"text-align: right;\">       9.35969</td><td style=\"text-align: right;\"> 1689742421</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00012</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00013</td><td>2023-07-18_23-54-06</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.899549</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            30.5521 </td><td style=\"text-align: right;\">           4.4808 </td><td style=\"text-align: right;\">      30.5521 </td><td style=\"text-align: right;\"> 1689742446</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>eb105_00013</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00014</td><td>2023-07-18_23-54-14</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.774812</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            32.2647 </td><td style=\"text-align: right;\">           2.91719</td><td style=\"text-align: right;\">      32.2647 </td><td style=\"text-align: right;\"> 1689742454</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00014</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00015</td><td>2023-07-18_23-55-03</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        11</td><td style=\"text-align: right;\">   0.946403</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            69.7673 </td><td style=\"text-align: right;\">           5.10765</td><td style=\"text-align: right;\">      69.7673 </td><td style=\"text-align: right;\"> 1689742503</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  11</td><td>eb105_00015</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00016</td><td>2023-07-18_23-54-11</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            13.7816 </td><td style=\"text-align: right;\">           3.64604</td><td style=\"text-align: right;\">      13.7816 </td><td style=\"text-align: right;\"> 1689742451</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00016</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00017</td><td>2023-07-18_23-54-35</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.879367</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            28.4565 </td><td style=\"text-align: right;\">           6.77909</td><td style=\"text-align: right;\">      28.4565 </td><td style=\"text-align: right;\"> 1689742475</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00017</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00018</td><td>2023-07-18_23-54-41</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">   0.898717</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            29.3509 </td><td style=\"text-align: right;\">           1.94997</td><td style=\"text-align: right;\">      29.3509 </td><td style=\"text-align: right;\"> 1689742481</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>eb105_00018</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00019</td><td>2023-07-18_23-54-28</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.985713</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            14.0679 </td><td style=\"text-align: right;\">           2.06469</td><td style=\"text-align: right;\">      14.0679 </td><td style=\"text-align: right;\"> 1689742468</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00019</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00020</td><td>2023-07-18_23-54-52</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.951899</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            23.3728 </td><td style=\"text-align: right;\">           4.83625</td><td style=\"text-align: right;\">      23.3728 </td><td style=\"text-align: right;\"> 1689742492</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00020</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00021</td><td>2023-07-18_23-54-49</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.979578</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            13.8241 </td><td style=\"text-align: right;\">           1.99315</td><td style=\"text-align: right;\">      13.8241 </td><td style=\"text-align: right;\"> 1689742489</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00021</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00022</td><td>2023-07-18_23-54-51</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.828353</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            10.5245 </td><td style=\"text-align: right;\">           1.97796</td><td style=\"text-align: right;\">      10.5245 </td><td style=\"text-align: right;\"> 1689742491</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00022</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00023</td><td>2023-07-18_23-55-40</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">   0.94106 </td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            50.5376 </td><td style=\"text-align: right;\">           5.05926</td><td style=\"text-align: right;\">      50.5376 </td><td style=\"text-align: right;\"> 1689742540</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   8</td><td>eb105_00023</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00024</td><td>2023-07-18_23-55-14</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.980354</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            22.2796 </td><td style=\"text-align: right;\">           4.26242</td><td style=\"text-align: right;\">      22.2796 </td><td style=\"text-align: right;\"> 1689742514</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00024</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00025</td><td>2023-07-18_23-55-27</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.569554</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            34.61   </td><td style=\"text-align: right;\">           2.98795</td><td style=\"text-align: right;\">      34.61   </td><td style=\"text-align: right;\"> 1689742527</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00025</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00026</td><td>2023-07-18_23-55-26</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.970435</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            22.2602 </td><td style=\"text-align: right;\">           5.22214</td><td style=\"text-align: right;\">      22.2602 </td><td style=\"text-align: right;\"> 1689742526</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00026</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00027</td><td>2023-07-18_23-55-29</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.777731</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            15.1246 </td><td style=\"text-align: right;\">           3.27664</td><td style=\"text-align: right;\">      15.1246 </td><td style=\"text-align: right;\"> 1689742529</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00027</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00028</td><td>2023-07-18_23-56-17</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         9</td><td style=\"text-align: right;\">   0.918146</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            50.9842 </td><td style=\"text-align: right;\">           5.80416</td><td style=\"text-align: right;\">      50.9842 </td><td style=\"text-align: right;\"> 1689742577</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   9</td><td>eb105_00028</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00029</td><td>2023-07-18_23-55-37</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982647</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">             9.73511</td><td style=\"text-align: right;\">           2.0555 </td><td style=\"text-align: right;\">       9.73511</td><td style=\"text-align: right;\"> 1689742537</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00029</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00030</td><td>2023-07-18_23-56-25</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.47532 </td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            55.7787 </td><td style=\"text-align: right;\">           5.44476</td><td style=\"text-align: right;\">      55.7787 </td><td style=\"text-align: right;\"> 1689742585</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00030</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00031</td><td>2023-07-18_23-56-33</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.541515</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            56.5338 </td><td style=\"text-align: right;\">           5.11437</td><td style=\"text-align: right;\">      56.5338 </td><td style=\"text-align: right;\"> 1689742593</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00031</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00032</td><td>2023-07-18_23-56-02</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.569385</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            22.3815 </td><td style=\"text-align: right;\">           4.30203</td><td style=\"text-align: right;\">      22.3815 </td><td style=\"text-align: right;\"> 1689742562</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>eb105_00032</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00033</td><td>2023-07-18_23-56-29</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.602082</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            26.1482 </td><td style=\"text-align: right;\">           3.14802</td><td style=\"text-align: right;\">      26.1482 </td><td style=\"text-align: right;\"> 1689742589</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>eb105_00033</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00034</td><td>2023-07-18_23-56-51</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.953117</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            34.0882 </td><td style=\"text-align: right;\">           3.53699</td><td style=\"text-align: right;\">      34.0882 </td><td style=\"text-align: right;\"> 1689742611</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00034</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00035</td><td>2023-07-18_23-56-59</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.958122</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            33.9989 </td><td style=\"text-align: right;\">           3.25359</td><td style=\"text-align: right;\">      33.9989 </td><td style=\"text-align: right;\"> 1689742619</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00035</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00036</td><td>2023-07-18_23-56-42</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.987313</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            13.2208 </td><td style=\"text-align: right;\">           2.00232</td><td style=\"text-align: right;\">      13.2208 </td><td style=\"text-align: right;\"> 1689742602</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00036</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00037</td><td>2023-07-18_23-56-53</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.678397</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            19.4509 </td><td style=\"text-align: right;\">           3.54928</td><td style=\"text-align: right;\">      19.4509 </td><td style=\"text-align: right;\"> 1689742613</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>eb105_00037</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00038</td><td>2023-07-18_23-57-09</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.804149</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            26.6708 </td><td style=\"text-align: right;\">           3.33724</td><td style=\"text-align: right;\">      26.6708 </td><td style=\"text-align: right;\"> 1689742629</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00038</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00039</td><td>2023-07-18_23-57-02</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.981395</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            10.7208 </td><td style=\"text-align: right;\">           2.67619</td><td style=\"text-align: right;\">      10.7208 </td><td style=\"text-align: right;\"> 1689742622</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00039</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00040</td><td>2023-07-18_23-57-05</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.931416</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            11.3568 </td><td style=\"text-align: right;\">           2.28544</td><td style=\"text-align: right;\">      11.3568 </td><td style=\"text-align: right;\"> 1689742625</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00040</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00041</td><td>2023-07-18_23-57-38</td><td>True  </td><td>                </td><td>5dcdf9e8647c45bebfe87e1979b07af1</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.681485</td><td>127.0.0.1</td><td style=\"text-align: right;\">61147</td><td>True               </td><td style=\"text-align: right;\">            37.9367 </td><td style=\"text-align: right;\">           3.18734</td><td style=\"text-align: right;\">      37.9367 </td><td style=\"text-align: right;\"> 1689742658</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00041</td><td style=\"text-align: right;\">    0.0486069</td></tr>\n",
       "<tr><td>trainable_eb105_00042</td><td>2023-07-18_23-57-15</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.983417</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            12.5799 </td><td style=\"text-align: right;\">           2.08135</td><td style=\"text-align: right;\">      12.5799 </td><td style=\"text-align: right;\"> 1689742635</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00042</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00043</td><td>2023-07-18_23-57-24</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.581   </td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            18.9862 </td><td style=\"text-align: right;\">           5.10769</td><td style=\"text-align: right;\">      18.9862 </td><td style=\"text-align: right;\"> 1689742644</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00043</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00044</td><td>2023-07-18_23-57-28</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.971138</td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            17.9446 </td><td style=\"text-align: right;\">           2.35086</td><td style=\"text-align: right;\">      17.9446 </td><td style=\"text-align: right;\"> 1689742648</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>eb105_00044</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00045</td><td>2023-07-18_23-57-26</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.983501</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            10.9211 </td><td style=\"text-align: right;\">           2.45597</td><td style=\"text-align: right;\">      10.9211 </td><td style=\"text-align: right;\"> 1689742646</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00045</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00046</td><td>2023-07-18_23-57-36</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.503938</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            11.3994 </td><td style=\"text-align: right;\">           2.12418</td><td style=\"text-align: right;\">      11.3994 </td><td style=\"text-align: right;\"> 1689742656</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00046</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "<tr><td>trainable_eb105_00047</td><td>2023-07-18_23-57-37</td><td>True  </td><td>                </td><td>1197f24537e84c52ab1127e105f58ce6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.494621</td><td>127.0.0.1</td><td style=\"text-align: right;\">61149</td><td>True               </td><td style=\"text-align: right;\">            10.9265 </td><td style=\"text-align: right;\">           1.95828</td><td style=\"text-align: right;\">      10.9265 </td><td style=\"text-align: right;\"> 1689742657</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00047</td><td style=\"text-align: right;\">    0.037008 </td></tr>\n",
       "<tr><td>trainable_eb105_00048</td><td>2023-07-18_23-57-42</td><td>True  </td><td>                </td><td>eb38596361fd4b05be6cde660dffabaf</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">61148</td><td>True               </td><td style=\"text-align: right;\">            14.5854 </td><td style=\"text-align: right;\">           2.11427</td><td style=\"text-align: right;\">      14.5854 </td><td style=\"text-align: right;\"> 1689742662</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>eb105_00048</td><td style=\"text-align: right;\">    0.0468159</td></tr>\n",
       "<tr><td>trainable_eb105_00049</td><td>2023-07-18_23-57-55</td><td>True  </td><td>                </td><td>0fde09afe698453db186d568b99a7ed0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.380165</td><td>127.0.0.1</td><td style=\"text-align: right;\">61146</td><td>True               </td><td style=\"text-align: right;\">            19.2073 </td><td style=\"text-align: right;\">           1.69914</td><td style=\"text-align: right;\">      19.2073 </td><td style=\"text-align: right;\"> 1689742675</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>eb105_00049</td><td style=\"text-align: right;\">    0.037323 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:53:11 (running for 00:00:30.94)\n",
      "Memory usage on this node: 9.9/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.743686318397522\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00005 with mnist_auc=0.9827035665512085 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0027600000000000003, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 13/50 (4 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00007 | RUNNING    | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00002 | RUNNING    | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00008 | RUNNING    | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00006 | RUNNING    | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00009 | PENDING    |                 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | PENDING    |                 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | PENDING    |                 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | PENDING    |                 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:53:41 (running for 00:01:01.48)\n",
      "Memory usage on this node: 10.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.743686318397522\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00005 with mnist_auc=0.9827035665512085 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0027600000000000003, 'layer1/units': 64}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 18/50 (4 PENDING, 4 RUNNING, 10 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00009 | RUNNING    | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | RUNNING    | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00012 | RUNNING    | 127.0.0.1:61146 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00013 | RUNNING    | 127.0.0.1:61148 | rms      |         0.00534 |             64 |\n",
      "| trainable_eb105_00014 | PENDING    |                 | adadelta |         0.00616 |             48 |\n",
      "| trainable_eb105_00015 | PENDING    |                 | sgd      |         0.0036  |             16 |\n",
      "| trainable_eb105_00016 | PENDING    |                 | adagrad  |         0.0049  |             48 |\n",
      "| trainable_eb105_00017 | PENDING    |                 | adam     |         0.00919 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:54:14 (running for 00:01:34.09)\n",
      "Memory usage on this node: 10.3/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8372473120689392\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00012 with mnist_auc=0.982785701751709 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.008010000000000001, 'layer1/units': 32}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 23/50 (4 PENDING, 4 RUNNING, 15 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00014 | RUNNING    | 127.0.0.1:61146 | adadelta |         0.00616 |             48 |\n",
      "| trainable_eb105_00015 | RUNNING    | 127.0.0.1:61149 | sgd      |         0.0036  |             16 |\n",
      "| trainable_eb105_00017 | RUNNING    | 127.0.0.1:61148 | adam     |         0.00919 |             64 |\n",
      "| trainable_eb105_00018 | RUNNING    | 127.0.0.1:61147 | adagrad  |         0.00369 |             48 |\n",
      "| trainable_eb105_00019 | PENDING    |                 | rms      |         0.00652 |             16 |\n",
      "| trainable_eb105_00020 | PENDING    |                 | sgd      |         0.00345 |             32 |\n",
      "| trainable_eb105_00021 | PENDING    |                 | sgd      |         0.0055  |             16 |\n",
      "| trainable_eb105_00022 | PENDING    |                 | adam     |         0.00943 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 3 more trials not shown (3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:54:45 (running for 00:02:05.38)\n",
      "Memory usage on this node: 10.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.889158621430397\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00019 with mnist_auc=0.9857134819030762 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.006520000000000001, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 27/50 (4 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00015 | RUNNING    | 127.0.0.1:61149 | sgd      |         0.0036  |             16 |\n",
      "| trainable_eb105_00020 | RUNNING    | 127.0.0.1:61146 | sgd      |         0.00345 |             32 |\n",
      "| trainable_eb105_00021 | RUNNING    | 127.0.0.1:61148 | sgd      |         0.0055  |             16 |\n",
      "| trainable_eb105_00022 | RUNNING    | 127.0.0.1:61147 | adam     |         0.00943 |             64 |\n",
      "| trainable_eb105_00023 | PENDING    |                 | rms      |         0.00184 |             64 |\n",
      "| trainable_eb105_00024 | PENDING    |                 | sgd      |         0.00977 |             32 |\n",
      "| trainable_eb105_00025 | PENDING    |                 | adadelta |         0.00907 |             32 |\n",
      "| trainable_eb105_00026 | PENDING    |                 | adagrad  |         0.00902 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 7 more trials not shown (7 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:55:15 (running for 00:02:35.58)\n",
      "Memory usage on this node: 10.3/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8996827602386475\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00019 with mnist_auc=0.9857134819030762 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.006520000000000001, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 32/50 (4 PENDING, 4 RUNNING, 24 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00023 | RUNNING    | 127.0.0.1:61148 | rms      |         0.00184 |             64 |\n",
      "| trainable_eb105_00025 | RUNNING    | 127.0.0.1:61146 | adadelta |         0.00907 |             32 |\n",
      "| trainable_eb105_00026 | RUNNING    | 127.0.0.1:61149 | adagrad  |         0.00902 |             64 |\n",
      "| trainable_eb105_00027 | RUNNING    | 127.0.0.1:61147 | adagrad  |         0.00595 |             32 |\n",
      "| trainable_eb105_00028 | PENDING    |                 | adadelta |         0.0092  |             16 |\n",
      "| trainable_eb105_00029 | PENDING    |                 | adagrad  |         0.00607 |             64 |\n",
      "| trainable_eb105_00030 | PENDING    |                 | adagrad  |         0.00933 |             32 |\n",
      "| trainable_eb105_00031 | PENDING    |                 | sgd      |         0.00347 |             16 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 12 more trials not shown (12 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:55:45 (running for 00:03:05.62)\n",
      "Memory usage on this node: 10.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8961747139692307\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00019 with mnist_auc=0.9857134819030762 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.006520000000000001, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 37/50 (4 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00028 | RUNNING    | 127.0.0.1:61149 | adadelta |         0.0092  |             16 |\n",
      "| trainable_eb105_00030 | RUNNING    | 127.0.0.1:61147 | adagrad  |         0.00933 |             32 |\n",
      "| trainable_eb105_00031 | RUNNING    | 127.0.0.1:61146 | sgd      |         0.00347 |             16 |\n",
      "| trainable_eb105_00032 | RUNNING    | 127.0.0.1:61148 | sgd      |         0.0055  |             48 |\n",
      "| trainable_eb105_00033 | PENDING    |                 | adam     |         0.00857 |             64 |\n",
      "| trainable_eb105_00034 | PENDING    |                 | sgd      |         0.00031 |             32 |\n",
      "| trainable_eb105_00035 | PENDING    |                 | adadelta |         0.00965 |             64 |\n",
      "| trainable_eb105_00036 | PENDING    |                 | adam     |         0.00084 |             16 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 17 more trials not shown (17 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:56:16 (running for 00:03:36.00)\n",
      "Memory usage on this node: 10.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8961747139692307\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00019 with mnist_auc=0.9857134819030762 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.006520000000000001, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 38/50 (4 PENDING, 4 RUNNING, 30 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00028 | RUNNING    | 127.0.0.1:61149 | adadelta |         0.0092  |             16 |\n",
      "| trainable_eb105_00030 | RUNNING    | 127.0.0.1:61147 | adagrad  |         0.00933 |             32 |\n",
      "| trainable_eb105_00031 | RUNNING    | 127.0.0.1:61146 | sgd      |         0.00347 |             16 |\n",
      "| trainable_eb105_00033 | RUNNING    | 127.0.0.1:61148 | adam     |         0.00857 |             64 |\n",
      "| trainable_eb105_00034 | PENDING    |                 | sgd      |         0.00031 |             32 |\n",
      "| trainable_eb105_00035 | PENDING    |                 | adadelta |         0.00965 |             64 |\n",
      "| trainable_eb105_00036 | PENDING    |                 | adam     |         0.00084 |             16 |\n",
      "| trainable_eb105_00037 | PENDING    |                 | adagrad  |         0.0015  |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 18 more trials not shown (18 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:56:46 (running for 00:04:06.43)\n",
      "Memory usage on this node: 10.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.889158621430397\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00036 with mnist_auc=0.9873133897781372 and parameters={'optimization/method': 'adam', 'optimization/learning_rate': 0.00084, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 43/50 (4 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00034 | RUNNING    | 127.0.0.1:61149 | sgd      |         0.00031 |             32 |\n",
      "| trainable_eb105_00035 | RUNNING    | 127.0.0.1:61147 | adadelta |         0.00965 |             64 |\n",
      "| trainable_eb105_00037 | RUNNING    | 127.0.0.1:61146 | adagrad  |         0.0015  |             64 |\n",
      "| trainable_eb105_00038 | RUNNING    | 127.0.0.1:61148 | sgd      |         0.00458 |             48 |\n",
      "| trainable_eb105_00039 | PENDING    |                 | adagrad  |         0.00703 |             48 |\n",
      "| trainable_eb105_00040 | PENDING    |                 | adam     |         0.00279 |             64 |\n",
      "| trainable_eb105_00041 | PENDING    |                 | rms      |         0.0098  |             16 |\n",
      "| trainable_eb105_00042 | PENDING    |                 | rms      |         0.00606 |             16 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 23 more trials not shown (23 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:57:17 (running for 00:04:36.76)\n",
      "Memory usage on this node: 10.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9199995994567871\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00036 with mnist_auc=0.9873133897781372 and parameters={'optimization/method': 'adam', 'optimization/learning_rate': 0.00084, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 50/50 (4 PENDING, 4 RUNNING, 42 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00041 | RUNNING    | 127.0.0.1:61147 | rms      |         0.0098  |             16 |\n",
      "| trainable_eb105_00043 | RUNNING    | 127.0.0.1:61146 | adadelta |         0.00144 |             16 |\n",
      "| trainable_eb105_00044 | RUNNING    | 127.0.0.1:61148 | sgd      |         0.00248 |             32 |\n",
      "| trainable_eb105_00045 | RUNNING    | 127.0.0.1:61149 | adagrad  |         0.00861 |             64 |\n",
      "| trainable_eb105_00046 | PENDING    |                 | adadelta |         0.00088 |             16 |\n",
      "| trainable_eb105_00047 | PENDING    |                 | adagrad  |         0.0005  |             48 |\n",
      "| trainable_eb105_00048 | PENDING    |                 | adadelta |         0.00367 |             16 |\n",
      "| trainable_eb105_00049 | PENDING    |                 | adagrad  |         0.0039  |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-18 23:57:47 (running for 00:05:07.47)\n",
      "Memory usage on this node: 9.2/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9098411798477173\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00036 with mnist_auc=0.9873133897781372 and parameters={'optimization/method': 'adam', 'optimization/learning_rate': 0.00084, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00049 | RUNNING    | 127.0.0.1:61146 | adagrad  |         0.0039  |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00013 | TERMINATED | 127.0.0.1:61148 | rms      |         0.00534 |             64 |\n",
      "| trainable_eb105_00014 | TERMINATED | 127.0.0.1:61146 | adadelta |         0.00616 |             48 |\n",
      "| trainable_eb105_00015 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.0036  |             16 |\n",
      "| trainable_eb105_00016 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.0049  |             48 |\n",
      "| trainable_eb105_00017 | TERMINATED | 127.0.0.1:61148 | adam     |         0.00919 |             64 |\n",
      "| trainable_eb105_00018 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.00369 |             48 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-18 23:57:55 (running for 00:05:15.62)\n",
      "Memory usage on this node: 9.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8996827602386475\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.39 GiB heap, 0.0/2.0 GiB objects\n",
      "Current best trial: eb105_00036 with mnist_auc=0.9873133897781372 and parameters={'optimization/method': 'adam', 'optimization/learning_rate': 0.00084, 'layer1/units': 16}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpqc0v4ohk/restore\n",
      "Number of trials: 50/50 (50 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   layer1_units |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+----------------|\n",
      "| trainable_eb105_00007 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00064 |             32 |\n",
      "| trainable_eb105_00002 | TERMINATED | 127.0.0.1:61147 | rms      |         0.00738 |             16 |\n",
      "| trainable_eb105_00008 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00693 |             48 |\n",
      "| trainable_eb105_00006 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00384 |             64 |\n",
      "| trainable_eb105_00005 | TERMINATED | 127.0.0.1:61131 | sgd      |         0.00276 |             64 |\n",
      "| trainable_eb105_00000 | TERMINATED | 127.0.0.1:61130 | adagrad  |         0.00558 |             16 |\n",
      "| trainable_eb105_00004 | TERMINATED | 127.0.0.1:61133 | rms      |         0.00215 |             32 |\n",
      "| trainable_eb105_00001 | TERMINATED | 127.0.0.1:61131 | adadelta |         0.0015  |             16 |\n",
      "| trainable_eb105_00003 | TERMINATED | 127.0.0.1:61133 | adadelta |         0.00406 |             64 |\n",
      "| trainable_eb105_00009 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00942 |             48 |\n",
      "| trainable_eb105_00010 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00783 |             48 |\n",
      "| trainable_eb105_00011 | TERMINATED | 127.0.0.1:61146 | adam     |         8e-05   |             64 |\n",
      "| trainable_eb105_00012 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00801 |             32 |\n",
      "| trainable_eb105_00013 | TERMINATED | 127.0.0.1:61148 | rms      |         0.00534 |             64 |\n",
      "| trainable_eb105_00014 | TERMINATED | 127.0.0.1:61146 | adadelta |         0.00616 |             48 |\n",
      "| trainable_eb105_00015 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.0036  |             16 |\n",
      "| trainable_eb105_00016 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.0049  |             48 |\n",
      "| trainable_eb105_00017 | TERMINATED | 127.0.0.1:61148 | adam     |         0.00919 |             64 |\n",
      "| trainable_eb105_00018 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.00369 |             48 |\n",
      "| trainable_eb105_00019 | TERMINATED | 127.0.0.1:61146 | rms      |         0.00652 |             16 |\n",
      "| trainable_eb105_00020 | TERMINATED | 127.0.0.1:61146 | sgd      |         0.00345 |             32 |\n",
      "| trainable_eb105_00021 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.0055  |             16 |\n",
      "| trainable_eb105_00022 | TERMINATED | 127.0.0.1:61147 | adam     |         0.00943 |             64 |\n",
      "| trainable_eb105_00023 | TERMINATED | 127.0.0.1:61148 | rms      |         0.00184 |             64 |\n",
      "| trainable_eb105_00024 | TERMINATED | 127.0.0.1:61147 | sgd      |         0.00977 |             32 |\n",
      "| trainable_eb105_00025 | TERMINATED | 127.0.0.1:61146 | adadelta |         0.00907 |             32 |\n",
      "| trainable_eb105_00026 | TERMINATED | 127.0.0.1:61149 | adagrad  |         0.00902 |             64 |\n",
      "| trainable_eb105_00027 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.00595 |             32 |\n",
      "| trainable_eb105_00028 | TERMINATED | 127.0.0.1:61149 | adadelta |         0.0092  |             16 |\n",
      "| trainable_eb105_00029 | TERMINATED | 127.0.0.1:61146 | adagrad  |         0.00607 |             64 |\n",
      "| trainable_eb105_00030 | TERMINATED | 127.0.0.1:61147 | adagrad  |         0.00933 |             32 |\n",
      "| trainable_eb105_00031 | TERMINATED | 127.0.0.1:61146 | sgd      |         0.00347 |             16 |\n",
      "| trainable_eb105_00032 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.0055  |             48 |\n",
      "| trainable_eb105_00033 | TERMINATED | 127.0.0.1:61148 | adam     |         0.00857 |             64 |\n",
      "| trainable_eb105_00034 | TERMINATED | 127.0.0.1:61149 | sgd      |         0.00031 |             32 |\n",
      "| trainable_eb105_00035 | TERMINATED | 127.0.0.1:61147 | adadelta |         0.00965 |             64 |\n",
      "| trainable_eb105_00036 | TERMINATED | 127.0.0.1:61148 | adam     |         0.00084 |             16 |\n",
      "| trainable_eb105_00037 | TERMINATED | 127.0.0.1:61146 | adagrad  |         0.0015  |             64 |\n",
      "| trainable_eb105_00038 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00458 |             48 |\n",
      "| trainable_eb105_00039 | TERMINATED | 127.0.0.1:61149 | adagrad  |         0.00703 |             48 |\n",
      "| trainable_eb105_00040 | TERMINATED | 127.0.0.1:61146 | adam     |         0.00279 |             64 |\n",
      "| trainable_eb105_00041 | TERMINATED | 127.0.0.1:61147 | rms      |         0.0098  |             16 |\n",
      "| trainable_eb105_00042 | TERMINATED | 127.0.0.1:61149 | rms      |         0.00606 |             16 |\n",
      "| trainable_eb105_00043 | TERMINATED | 127.0.0.1:61146 | adadelta |         0.00144 |             16 |\n",
      "| trainable_eb105_00044 | TERMINATED | 127.0.0.1:61148 | sgd      |         0.00248 |             32 |\n",
      "| trainable_eb105_00045 | TERMINATED | 127.0.0.1:61149 | adagrad  |         0.00861 |             64 |\n",
      "| trainable_eb105_00046 | TERMINATED | 127.0.0.1:61146 | adadelta |         0.00088 |             16 |\n",
      "| trainable_eb105_00047 | TERMINATED | 127.0.0.1:61149 | adagrad  |         0.0005  |             48 |\n",
      "| trainable_eb105_00048 | TERMINATED | 127.0.0.1:61148 | adadelta |         0.00367 |             16 |\n",
      "| trainable_eb105_00049 | TERMINATED | 127.0.0.1:61146 | adagrad  |         0.0039  |             64 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# complete trials\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    tuner.restore(local_dir=temp_dir.name + \"/restore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a0d53",
   "metadata": {},
   "source": [
    "### Cleanup storage\n",
    "\n",
    "Hyperparameter tuning experiments can consume a lot of storage. Take care when setting `local_dir` for more extensive runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5de34731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the temporary directory\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
