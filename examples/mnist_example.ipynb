{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "## MNIST example\n",
    "\n",
    "This notebook demonstrates and end-to-end application of the glimr package.\n",
    "\n",
    "Using MNIST classification as a simple example, we demonstrate the steps to create a search space, model builder, and dataloader for use in tuning. This provides a concrete example of topics like using the `glimr.utils` and `glimr.keras` functions to create hyperparameters and to correctly name losses and metrics for training and reporting.\n",
    "\n",
    "This is followed by a demonstration of the `Search` class to show how to setup and run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af13097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/lcoop22/Desktop/glimr\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow>=2.5 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from glimr==0.1.dev33+ge238514) (2.11.0)\n",
      "Requirement already satisfied: ray>=2.3.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from glimr==0.1.dev33+ge238514) (2.3.0)\n",
      "Requirement already satisfied: jsonschema in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (4.16.0)\n",
      "Requirement already satisfied: aiosignal in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.3.1)\n",
      "Requirement already satisfied: requests in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (2.28.1)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (20.17.1)\n",
      "Requirement already satisfied: grpcio<=1.49.1,>=1.32.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.49.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (3.19.6)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (8.0.4)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.21.5)\n",
      "Requirement already satisfied: attrs in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (21.4.0)\n",
      "Requirement already satisfied: filelock in /Users/lcoop22/.local/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (3.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (6.0)\n",
      "Requirement already satisfied: frozenlist in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.11.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (15.0.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (63.4.1)\n",
      "Requirement already satisfied: packaging in /Users/lcoop22/.local/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (23.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (23.1.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (4.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.14.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.29.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (2.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (3.3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev33+ge238514) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev33+ge238514) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev33+ge238514) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev33+ge238514) (2022.9.24)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=2.3.0->glimr==0.1.dev33+ge238514) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /Users/lcoop22/.local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=2.3.0->glimr==0.1.dev33+ge238514) (2.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from jsonschema->ray>=2.3.0->glimr==0.1.dev33+ge238514) (0.18.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/lcoop22/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev33+ge238514) (3.2.2)\n",
      "Building wheels for collected packages: glimr\n",
      "  Building wheel for glimr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glimr: filename=glimr-0.1.dev33+ge238514-py3-none-any.whl size=18689 sha256=7de82b4f8993feb0a24ea2b75e2183acf6657a6e31cd2ae787d5941edbd5263c\n",
      "  Stored in directory: /private/var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/pip-ephem-wheel-cache-nbc7hzai/wheels/58/08/39/c88c61a75aca3782dfcc11b86c8a6af860f75d1d00fddf72e2\n",
      "Successfully built glimr\n",
      "Installing collected packages: glimr\n",
      "  Attempting uninstall: glimr\n",
      "    Found existing installation: glimr 0.1.dev33+ge238514\n",
      "    Uninstalling glimr-0.1.dev33+ge238514:\n",
      "      Successfully uninstalled glimr-0.1.dev33+ge238514\n",
      "Successfully installed glimr-0.1.dev33+ge238514\n"
     ]
    }
   ],
   "source": [
    "!pip install ../../glimr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "### Creating the search space\n",
    "\n",
    "First let's create a search space for a simple two layer network for a multiclass MNIST classifier.\n",
    "\n",
    "For each layer we define hyperparameters for the number of units, dropout rate, and activation functions. We explore two losses for the single output task (named \"mnist\"), and explore a variety of gradient optimization algorithms and batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c338990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 00:33:46.929005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'layer1': {   'activation': {   'elu',\n",
      "                                    'gelu',\n",
      "                                    'linear',\n",
      "                                    'relu',\n",
      "                                    'selu',\n",
      "                                    'sigmoid',\n",
      "                                    'softplus'},\n",
      "                  'dropout': [0.0, 0.2, 0.05],\n",
      "                  'units': {64, 16, 48, 32}},\n",
      "    'optimization': {   'batch': <ray.tune.search.sample.Categorical object at 0x7fa106e9b220>,\n",
      "                        'beta_1': <ray.tune.search.sample.Float object at 0x7fa0f224e9d0>,\n",
      "                        'beta_2': <ray.tune.search.sample.Float object at 0x7fa0f224ea00>,\n",
      "                        'learning_rate': <ray.tune.search.sample.Float object at 0x7fa106e9b2b0>,\n",
      "                        'method': <ray.tune.search.sample.Categorical object at 0x7fa106e9b310>,\n",
      "                        'momentum': <ray.tune.search.sample.Float object at 0x7fa0f222b8e0>,\n",
      "                        'rho': <ray.tune.search.sample.Float object at 0x7fa0f1c98af0>},\n",
      "    'tasks': {   'mnist': {   'activation': {   'elu',\n",
      "                                                'gelu',\n",
      "                                                'linear',\n",
      "                                                'relu',\n",
      "                                                'selu',\n",
      "                                                'sigmoid',\n",
      "                                                'softplus'},\n",
      "                              'dropout': [0.0, 0.2, 0.05],\n",
      "                              'loss': {   'categorical_crossentropy',\n",
      "                                          'categorical_hinge'},\n",
      "                              'loss_weight': 1.0,\n",
      "                              'metrics': {'auc': 'auc'},\n",
      "                              'units': 10}}}\n"
     ]
    }
   ],
   "source": [
    "# import optimization search space from glimr\n",
    "from glimr.optimization import optimization_space\n",
    "from glimr.utils import set_hyperparameter\n",
    "\n",
    "# define the possible layer activations\n",
    "activations = {\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"}\n",
    "\n",
    "# define the layer 1 hyperparameters\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": [0.0, 0.2, 0.05],\n",
    "    \"units\": {64, 48, 32, 16}\n",
    "}\n",
    "\n",
    "# define the task\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": [0.0, 0.2, 0.05],\n",
    "    \"units\": 10,\n",
    "    \"loss\": {\"categorical_hinge\", \"categorical_crossentropy\"},\n",
    "    \"loss_weight\": 1.0,\n",
    "    \"metrics\": {\"auc\": \"auc\"}\n",
    "}\n",
    "\n",
    "# put it all together\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\n",
    "        \"mnist\": task\n",
    "    }\n",
    "}\n",
    "\n",
    "# display space\n",
    "from pprint import pprint\n",
    "pprint(space, indent=4)\n",
    "\n",
    "# define a recursive procedure for setting hyperparameters for list, set types\n",
    "def recursive_set_hyperparameter(dictionary):\n",
    "    for key in dictionary.keys():\n",
    "        if isinstance(dictionary[key], (list, set)):\n",
    "            dictionary[key] = set_hyperparameter(dictionary[key])\n",
    "        elif isinstance(dictionary[key], dict):\n",
    "            recursive_set_hyperparameter(dictionary[key])\n",
    "            \n",
    "# convert from glimr hyperparameter notation to Ray Tune hyperparameters\n",
    "recursive_set_hyperparameter(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844b5b2",
   "metadata": {},
   "source": [
    "### Implement the model-building function\n",
    "\n",
    "The model-builder function transforms a sample of the space into a `tf.keras.Model`, and loss, loss weight, and metric inputs for model compilation. This is a user-defined function to provide maximum flexibility in the models that can be used with glimr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def builder(config):\n",
    "    \n",
    "    # a helper function for building layers\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        # dense layer\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "\n",
    "        # add dropout if necessary\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # create input layer\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "    \n",
    "    # build layer 1\n",
    "    x = _build_layer(input_layer, \n",
    "                     config[\"layer1\"][\"units\"], \n",
    "                     config[\"layer1\"][\"activation\"], \n",
    "                     config[\"layer1\"][\"dropout\"],\n",
    "                     \"layer1\")\n",
    "    \n",
    "    # build output / task layer\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(input_layer, \n",
    "                     config[\"tasks\"][task_name][\"units\"], \n",
    "                     config[\"tasks\"][task_name][\"activation\"], \n",
    "                     config[\"tasks\"][task_name][\"dropout\"],\n",
    "                     task_name)\n",
    "\n",
    "    # build named output dict\n",
    "    named = {f\"{task_name}\": output}\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "\n",
    "    # create a loss dictionary using utility function\n",
    "    metric_mapper = {\n",
    "        \"categorical_crossentropy\": tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        \"categorical_hinge\": tf.keras.losses.CategoricalHinge()\n",
    "    }\n",
    "    losses, loss_weights = keras_losses(config, metric_mapper)\n",
    "\n",
    "    # create a metric dictionary using utility function\n",
    "    loss_mapper = {\n",
    "        \"auc\": tf.keras.metrics.AUC\n",
    "    }\n",
    "    metrics = keras_metrics(config, loss_mapper)\n",
    "    \n",
    "    return model, losses, loss_weights, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "### Create a data loading function\n",
    "\n",
    "Write a function to load and batch mnist samples. Flatten the images and apply a one-hot encoding to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dataloader(batch):\n",
    "    \n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "    \n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(features.shape[0], features.shape[1]*features.shape[2])\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(train[0]), tf.float32) / 255.\n",
    "    train_labels = train[1]\n",
    "    validation_features = tf.cast(mnist_flat(validation[0]), tf.float32) / 255.\n",
    "    validation_labels = validation[1]\n",
    "    \n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "    \n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch)\n",
    "    validation_ds = validation_ds.batch(batch)\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795438a8",
   "metadata": {},
   "source": [
    "### Test the search space, model builder, and dataloader\n",
    "\n",
    "Before doing a hyperparameter search, let's test this combination to verify that the models can train.\n",
    "\n",
    "We generate a sample configuration from the search space and build, compile, and train a model with this config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a779c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'layer1': {   'activation': 'softplus',\n",
      "                  'dropout': 0.15000000000000002,\n",
      "                  'units': 32},\n",
      "    'optimization': {   'batch': 64,\n",
      "                        'beta_1': 0.54,\n",
      "                        'beta_2': 0.64,\n",
      "                        'learning_rate': 0.008060000000000001,\n",
      "                        'method': 'adam',\n",
      "                        'momentum': 0.06,\n",
      "                        'rho': 0.77},\n",
      "    'tasks': {   'mnist': {   'activation': 'softplus',\n",
      "                              'dropout': 0.05,\n",
      "                              'loss': 'categorical_crossentropy',\n",
      "                              'loss_weight': 1.0,\n",
      "                              'metrics': {'auc': 'auc'},\n",
      "                              'units': 10}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 00:33:55.206294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from glimr.keras import keras_optimizer\n",
    "import ray\n",
    "\n",
    "# define a function for sampling a config from a space - ray will handle this automatically\n",
    "def sample_space(space):\n",
    "    config = {}\n",
    "    for key in space:\n",
    "        if isinstance(space[key], dict):\n",
    "            config[key] = sample_space(space[key])\n",
    "        elif isinstance(space[key], (ray.tune.search.sample.Categorical,\n",
    "                                     ray.tune.search.sample.Integer,\n",
    "                                     ray.tune.search.sample.Float)):\n",
    "            config[key] = space[key].sample()\n",
    "        else: # non sampleable value\n",
    "            config[key] = space[key]\n",
    "    return config\n",
    "\n",
    "# sample a configuration\n",
    "config = sample_space(space)\n",
    "\n",
    "# display the configuration\n",
    "from pprint import pprint\n",
    "pprint(config, indent=4)\n",
    "\n",
    "# build the model\n",
    "model, losses, loss_weights, metrics = builder(config)\n",
    "\n",
    "# build the optimizer\n",
    "optimizer = keras_optimizer(config[\"optimization\"])\n",
    "\n",
    "# test compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=losses,\n",
    "              metrics=metrics,\n",
    "              loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab057a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4975 - auc: 0.8994 - val_loss: 0.2944 - val_auc: 0.9493\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4411 - auc: 0.9245 - val_loss: 0.2993 - val_auc: 0.9545\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4365 - auc: 0.9281 - val_loss: 0.2905 - val_auc: 0.9586\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4326 - auc: 0.9310 - val_loss: 0.3037 - val_auc: 0.9608\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4370 - auc: 0.9315 - val_loss: 0.3019 - val_auc: 0.9597\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4372 - auc: 0.9322 - val_loss: 0.3282 - val_auc: 0.9621\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4367 - auc: 0.9334 - val_loss: 0.3123 - val_auc: 0.9587\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4394 - auc: 0.9328 - val_loss: 0.3237 - val_auc: 0.9619\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4391 - auc: 0.9337 - val_loss: 0.3121 - val_auc: 0.9614\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4394 - auc: 0.9346 - val_loss: 0.3157 - val_auc: 0.9605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0f33fd130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataset and train\n",
    "train_ds, val_ds = dataloader(config[\"optimization\"][\"batch\"])\n",
    "model.fit(x=train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "## Using Search for hyperparameter tuning\n",
    "\n",
    "The `Search` class implements the hyperparameter tuning process of Ray Tune. It is designed to provide sensible defaults for the many options available in Ray Tune, but also allows fine grained access to all Ray Tune options through it's class attributes. It is written ass a builder class that is incrementally changed to add tuning options for things like reporting, checkpointing, and experiment resources.\n",
    "\n",
    "We start by setting up a basic experiment, and then demonstrate how to control tuning options through class methods and class attribute assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264a521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:35:21 (running for 00:00:00.29)\n",
      "Memory usage on this node: 11.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 8/100 (7 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |\n",
      "|-----------------------+----------+-----------------+----------+-----------------|\n",
      "| trainable_2b2b2_00000 | RUNNING  | 127.0.0.1:38406 | rms      |         0.00515 |\n",
      "| trainable_2b2b2_00001 | PENDING  |                 | adadelta |         0.00372 |\n",
      "| trainable_2b2b2_00002 | PENDING  |                 | sgd      |         0.00128 |\n",
      "| trainable_2b2b2_00003 | PENDING  |                 | rms      |         0.00712 |\n",
      "| trainable_2b2b2_00004 | PENDING  |                 | sgd      |         0.00818 |\n",
      "| trainable_2b2b2_00005 | PENDING  |                 | adagrad  |         0.00075 |\n",
      "| trainable_2b2b2_00006 | PENDING  |                 | sgd      |         0.00125 |\n",
      "| trainable_2b2b2_00007 | PENDING  |                 | rms      |         0.0031  |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_2b2b2_00000</td><td>2023-03-21_00-35-47</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.678888</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            17.2701 </td><td style=\"text-align: right;\">           4.03424</td><td style=\"text-align: right;\">      17.2701 </td><td style=\"text-align: right;\"> 1679376947</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00000</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00001</td><td>2023-03-21_00-36-25</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        13</td><td style=\"text-align: right;\">   0.912039</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            46.107  </td><td style=\"text-align: right;\">           3.00604</td><td style=\"text-align: right;\">      46.107  </td><td style=\"text-align: right;\"> 1679376985</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  13</td><td>2b2b2_00001</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00002</td><td>2023-03-21_00-36-05</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.928004</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            25.2455 </td><td style=\"text-align: right;\">           3.20089</td><td style=\"text-align: right;\">      25.2455 </td><td style=\"text-align: right;\"> 1679376965</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>2b2b2_00002</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00003</td><td>2023-03-21_00-36-01</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.972908</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            22.0418 </td><td style=\"text-align: right;\">           4.56483</td><td style=\"text-align: right;\">      22.0418 </td><td style=\"text-align: right;\"> 1679376961</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00003</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00004</td><td>2023-03-21_00-36-01</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.8554  </td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            14.1088 </td><td style=\"text-align: right;\">           4.42581</td><td style=\"text-align: right;\">      14.1088 </td><td style=\"text-align: right;\"> 1679376961</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00004</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00005</td><td>2023-03-21_00-36-23</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.927443</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            20.8828 </td><td style=\"text-align: right;\">           4.81903</td><td style=\"text-align: right;\">      20.8828 </td><td style=\"text-align: right;\"> 1679376983</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00005</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00006</td><td>2023-03-21_00-36-14</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.948686</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            12.0353 </td><td style=\"text-align: right;\">           2.25339</td><td style=\"text-align: right;\">      12.0353 </td><td style=\"text-align: right;\"> 1679376974</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00006</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00007</td><td>2023-03-21_00-36-15</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.964558</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">             9.92862</td><td style=\"text-align: right;\">           1.85538</td><td style=\"text-align: right;\">       9.92862</td><td style=\"text-align: right;\"> 1679376975</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00007</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00008</td><td>2023-03-21_00-36-30</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.769777</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            16.1991 </td><td style=\"text-align: right;\">           2.8684 </td><td style=\"text-align: right;\">      16.1991 </td><td style=\"text-align: right;\"> 1679376990</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00008</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00009</td><td>2023-03-21_00-36-36</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.910548</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            20.8184 </td><td style=\"text-align: right;\">           4.83513</td><td style=\"text-align: right;\">      20.8184 </td><td style=\"text-align: right;\"> 1679376996</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00009</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00010</td><td>2023-03-21_00-36-37</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.833665</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            14.0494 </td><td style=\"text-align: right;\">           2.91789</td><td style=\"text-align: right;\">      14.0494 </td><td style=\"text-align: right;\"> 1679376997</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00010</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00011</td><td>2023-03-21_00-36-56</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.928734</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            30.4616 </td><td style=\"text-align: right;\">           2.75164</td><td style=\"text-align: right;\">      30.4616 </td><td style=\"text-align: right;\"> 1679377016</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00011</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00012</td><td>2023-03-21_00-36-51</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.919307</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            20.6508 </td><td style=\"text-align: right;\">           4.58414</td><td style=\"text-align: right;\">      20.6508 </td><td style=\"text-align: right;\"> 1679377011</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00012</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00013</td><td>2023-03-21_00-36-49</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.970005</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            13.0688 </td><td style=\"text-align: right;\">           2.90266</td><td style=\"text-align: right;\">      13.0688 </td><td style=\"text-align: right;\"> 1679377009</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00013</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00014</td><td>2023-03-21_00-36-57</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965322</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            20.0347 </td><td style=\"text-align: right;\">           4.38983</td><td style=\"text-align: right;\">      20.0347 </td><td style=\"text-align: right;\"> 1679377017</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00014</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00015</td><td>2023-03-21_00-37-02</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.957825</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            13.3163 </td><td style=\"text-align: right;\">           3.20349</td><td style=\"text-align: right;\">      13.3163 </td><td style=\"text-align: right;\"> 1679377022</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00015</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00016</td><td>2023-03-21_00-37-05</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.969045</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            13.4054 </td><td style=\"text-align: right;\">           2.7835 </td><td style=\"text-align: right;\">      13.4054 </td><td style=\"text-align: right;\"> 1679377025</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00016</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00017</td><td>2023-03-21_00-37-19</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.869802</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            22.5946 </td><td style=\"text-align: right;\">           3.20887</td><td style=\"text-align: right;\">      22.5946 </td><td style=\"text-align: right;\"> 1679377039</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00017</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00018</td><td>2023-03-21_00-37-21</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        11</td><td style=\"text-align: right;\">   0.935508</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            23.849  </td><td style=\"text-align: right;\">           2.17608</td><td style=\"text-align: right;\">      23.849  </td><td style=\"text-align: right;\"> 1679377041</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  11</td><td>2b2b2_00018</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00019</td><td>2023-03-21_00-37-16</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.967852</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            12.8503 </td><td style=\"text-align: right;\">           2.94656</td><td style=\"text-align: right;\">      12.8503 </td><td style=\"text-align: right;\"> 1679377036</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00019</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00020</td><td>2023-03-21_00-37-26</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.955524</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            20.4829 </td><td style=\"text-align: right;\">           4.57659</td><td style=\"text-align: right;\">      20.4829 </td><td style=\"text-align: right;\"> 1679377046</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00020</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00021</td><td>2023-03-21_00-37-29</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.961338</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            13.7012 </td><td style=\"text-align: right;\">           2.7095 </td><td style=\"text-align: right;\">      13.7012 </td><td style=\"text-align: right;\"> 1679377049</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00021</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00022</td><td>2023-03-21_00-37-28</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.950467</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">             9.36503</td><td style=\"text-align: right;\">           1.98693</td><td style=\"text-align: right;\">       9.36503</td><td style=\"text-align: right;\"> 1679377048</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00022</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00023</td><td>2023-03-21_00-37-41</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.960248</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            19.991  </td><td style=\"text-align: right;\">           2.38022</td><td style=\"text-align: right;\">      19.991  </td><td style=\"text-align: right;\"> 1679377061</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>2b2b2_00023</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00024</td><td>2023-03-21_00-37-44</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.976951</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            18.7292 </td><td style=\"text-align: right;\">           5.13655</td><td style=\"text-align: right;\">      18.7292 </td><td style=\"text-align: right;\"> 1679377064</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00024</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00025</td><td>2023-03-21_00-38-16</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.901476</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            47.1663 </td><td style=\"text-align: right;\">           4.59613</td><td style=\"text-align: right;\">      47.1663 </td><td style=\"text-align: right;\"> 1679377096</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00025</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00026</td><td>2023-03-21_00-38-00</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.911354</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            30.8119 </td><td style=\"text-align: right;\">           2.79035</td><td style=\"text-align: right;\">      30.8119 </td><td style=\"text-align: right;\"> 1679377080</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00026</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00027</td><td>2023-03-21_00-37-53</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.963041</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            11.5359 </td><td style=\"text-align: right;\">           1.85741</td><td style=\"text-align: right;\">      11.5359 </td><td style=\"text-align: right;\"> 1679377073</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00027</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00028</td><td>2023-03-21_00-37-58</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.96744 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            13.8898 </td><td style=\"text-align: right;\">           2.98041</td><td style=\"text-align: right;\">      13.8898 </td><td style=\"text-align: right;\"> 1679377078</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00028</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00029</td><td>2023-03-21_00-38-11</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.966653</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            18.02   </td><td style=\"text-align: right;\">           2.59147</td><td style=\"text-align: right;\">      18.02   </td><td style=\"text-align: right;\"> 1679377091</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>2b2b2_00029</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00030</td><td>2023-03-21_00-38-11</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.951855</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            12.4952 </td><td style=\"text-align: right;\">           2.56684</td><td style=\"text-align: right;\">      12.4952 </td><td style=\"text-align: right;\"> 1679377091</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00030</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00031</td><td>2023-03-21_00-38-20</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.974983</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            19.5615 </td><td style=\"text-align: right;\">           4.53708</td><td style=\"text-align: right;\">      19.5615 </td><td style=\"text-align: right;\"> 1679377100</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00031</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00032</td><td>2023-03-21_00-38-23</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.972228</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            12.0123 </td><td style=\"text-align: right;\">           2.9401 </td><td style=\"text-align: right;\">      12.0123 </td><td style=\"text-align: right;\"> 1679377103</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00032</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00033</td><td>2023-03-21_00-38-20</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.970508</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">             7.95869</td><td style=\"text-align: right;\">           1.86062</td><td style=\"text-align: right;\">       7.95869</td><td style=\"text-align: right;\"> 1679377100</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00033</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00034</td><td>2023-03-21_00-38-26</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965402</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">             9.50646</td><td style=\"text-align: right;\">           1.82562</td><td style=\"text-align: right;\">       9.50646</td><td style=\"text-align: right;\"> 1679377106</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00034</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00035</td><td>2023-03-21_00-38-29</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.817462</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">             9.53348</td><td style=\"text-align: right;\">           1.9525 </td><td style=\"text-align: right;\">       9.53348</td><td style=\"text-align: right;\"> 1679377109</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00035</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00036</td><td>2023-03-21_00-38-33</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.944828</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            12.8813 </td><td style=\"text-align: right;\">           2.89035</td><td style=\"text-align: right;\">      12.8813 </td><td style=\"text-align: right;\"> 1679377113</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00036</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00037</td><td>2023-03-21_00-38-39</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.762585</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            15.7072 </td><td style=\"text-align: right;\">           2.86579</td><td style=\"text-align: right;\">      15.7072 </td><td style=\"text-align: right;\"> 1679377119</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00037</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00038</td><td>2023-03-21_00-38-37</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.950977</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            11.5647 </td><td style=\"text-align: right;\">           1.93191</td><td style=\"text-align: right;\">      11.5647 </td><td style=\"text-align: right;\"> 1679377117</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00038</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00039</td><td>2023-03-21_00-38-44</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.961163</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            14.511  </td><td style=\"text-align: right;\">           2.54768</td><td style=\"text-align: right;\">      14.511  </td><td style=\"text-align: right;\"> 1679377124</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00039</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00040</td><td>2023-03-21_00-38-57</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.93476 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            23.6267 </td><td style=\"text-align: right;\">           4.24859</td><td style=\"text-align: right;\">      23.6267 </td><td style=\"text-align: right;\"> 1679377137</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00040</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00041</td><td>2023-03-21_00-38-48</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.812842</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            10.4114 </td><td style=\"text-align: right;\">           2.08614</td><td style=\"text-align: right;\">      10.4114 </td><td style=\"text-align: right;\"> 1679377128</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00041</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00042</td><td>2023-03-21_00-39-01</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.896848</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            21.9656 </td><td style=\"text-align: right;\">           1.91756</td><td style=\"text-align: right;\">      21.9656 </td><td style=\"text-align: right;\"> 1679377141</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00042</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00043</td><td>2023-03-21_00-39-06</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.729822</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            21.7175 </td><td style=\"text-align: right;\">           4.85651</td><td style=\"text-align: right;\">      21.7175 </td><td style=\"text-align: right;\"> 1679377146</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00043</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00044</td><td>2023-03-21_00-38-59</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.542055</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            10.4076 </td><td style=\"text-align: right;\">           2.01556</td><td style=\"text-align: right;\">      10.4076 </td><td style=\"text-align: right;\"> 1679377139</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00044</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00045</td><td>2023-03-21_00-39-07</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.548731</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">             9.70126</td><td style=\"text-align: right;\">           1.8281 </td><td style=\"text-align: right;\">       9.70126</td><td style=\"text-align: right;\"> 1679377147</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00045</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00046</td><td>2023-03-21_00-39-30</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.891591</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            31.38   </td><td style=\"text-align: right;\">           3.02101</td><td style=\"text-align: right;\">      31.38   </td><td style=\"text-align: right;\"> 1679377170</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00046</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00047</td><td>2023-03-21_00-39-33</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.797669</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            31.371  </td><td style=\"text-align: right;\">           2.81004</td><td style=\"text-align: right;\">      31.371  </td><td style=\"text-align: right;\"> 1679377173</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00047</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00048</td><td>2023-03-21_00-39-58</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.774247</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            51.3194 </td><td style=\"text-align: right;\">           5.19259</td><td style=\"text-align: right;\">      51.3194 </td><td style=\"text-align: right;\"> 1679377198</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00048</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00049</td><td>2023-03-21_00-39-21</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.958869</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            13.4896 </td><td style=\"text-align: right;\">           3.13519</td><td style=\"text-align: right;\">      13.4896 </td><td style=\"text-align: right;\"> 1679377161</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00049</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00050</td><td>2023-03-21_00-39-31</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.969905</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">             9.47845</td><td style=\"text-align: right;\">           1.8012 </td><td style=\"text-align: right;\">       9.47845</td><td style=\"text-align: right;\"> 1679377171</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00050</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00051</td><td>2023-03-21_00-40-12</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         9</td><td style=\"text-align: right;\">   0.933752</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            41.789  </td><td style=\"text-align: right;\">           4.24719</td><td style=\"text-align: right;\">      41.789  </td><td style=\"text-align: right;\"> 1679377212</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   9</td><td>2b2b2_00051</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00052</td><td>2023-03-21_00-39-51</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.955665</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            20.372  </td><td style=\"text-align: right;\">           4.61849</td><td style=\"text-align: right;\">      20.372  </td><td style=\"text-align: right;\"> 1679377191</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00052</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00053</td><td>2023-03-21_00-39-54</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.587753</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            21.0926 </td><td style=\"text-align: right;\">           2.07892</td><td style=\"text-align: right;\">      21.0926 </td><td style=\"text-align: right;\"> 1679377194</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00053</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00054</td><td>2023-03-21_00-40-07</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.965947</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            15.2669 </td><td style=\"text-align: right;\">           2.64895</td><td style=\"text-align: right;\">      15.2669 </td><td style=\"text-align: right;\"> 1679377207</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00054</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00055</td><td>2023-03-21_00-40-13</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.5     </td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            18.7623 </td><td style=\"text-align: right;\">           3.85058</td><td style=\"text-align: right;\">      18.7623 </td><td style=\"text-align: right;\"> 1679377213</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00055</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00056</td><td>2023-03-21_00-40-21</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.716317</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            23.3967 </td><td style=\"text-align: right;\">           4.61055</td><td style=\"text-align: right;\">      23.3967 </td><td style=\"text-align: right;\"> 1679377221</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00056</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00057</td><td>2023-03-21_00-40-28</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.91901 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            20.984  </td><td style=\"text-align: right;\">           2.93116</td><td style=\"text-align: right;\">      20.984  </td><td style=\"text-align: right;\"> 1679377228</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>2b2b2_00057</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00058</td><td>2023-03-21_00-40-25</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.500706</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            12.4907 </td><td style=\"text-align: right;\">           1.68001</td><td style=\"text-align: right;\">      12.4907 </td><td style=\"text-align: right;\"> 1679377225</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>2b2b2_00058</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00059</td><td>2023-03-21_00-40-28</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.471961</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            13.917  </td><td style=\"text-align: right;\">           2.7899 </td><td style=\"text-align: right;\">      13.917  </td><td style=\"text-align: right;\"> 1679377228</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00059</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00060</td><td>2023-03-21_00-40-31</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.961669</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">             9.47867</td><td style=\"text-align: right;\">           1.84761</td><td style=\"text-align: right;\">       9.47867</td><td style=\"text-align: right;\"> 1679377231</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00060</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00061</td><td>2023-03-21_00-40-45</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.970979</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            19.3918 </td><td style=\"text-align: right;\">           4.34917</td><td style=\"text-align: right;\">      19.3918 </td><td style=\"text-align: right;\"> 1679377245</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00061</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00062</td><td>2023-03-21_00-40-38</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.97348 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">             9.75421</td><td style=\"text-align: right;\">           2.28657</td><td style=\"text-align: right;\">       9.75421</td><td style=\"text-align: right;\"> 1679377238</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00062</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00063</td><td>2023-03-21_00-40-43</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.964174</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            14.6632 </td><td style=\"text-align: right;\">           2.39725</td><td style=\"text-align: right;\">      14.6632 </td><td style=\"text-align: right;\"> 1679377243</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00063</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00064</td><td>2023-03-21_00-41-36</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        11</td><td style=\"text-align: right;\">   0.934665</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            64.7683 </td><td style=\"text-align: right;\">           4.37259</td><td style=\"text-align: right;\">      64.7683 </td><td style=\"text-align: right;\"> 1679377296</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  11</td><td>2b2b2_00064</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00065</td><td>2023-03-21_00-40-45</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.968515</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">             7.41456</td><td style=\"text-align: right;\">           1.78027</td><td style=\"text-align: right;\">       7.41456</td><td style=\"text-align: right;\"> 1679377245</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00065</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00066</td><td>2023-03-21_00-40-58</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.954497</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            14.5004 </td><td style=\"text-align: right;\">           4.0431 </td><td style=\"text-align: right;\">      14.5004 </td><td style=\"text-align: right;\"> 1679377258</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00066</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00067</td><td>2023-03-21_00-40-54</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.844487</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">             9.33781</td><td style=\"text-align: right;\">           2.19972</td><td style=\"text-align: right;\">       9.33781</td><td style=\"text-align: right;\"> 1679377254</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00067</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00068</td><td>2023-03-21_00-41-38</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.779073</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            52.4304 </td><td style=\"text-align: right;\">           4.22227</td><td style=\"text-align: right;\">      52.4304 </td><td style=\"text-align: right;\"> 1679377298</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>2b2b2_00068</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00069</td><td>2023-03-21_00-41-07</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.901627</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            12.0045 </td><td style=\"text-align: right;\">           1.82569</td><td style=\"text-align: right;\">      12.0045 </td><td style=\"text-align: right;\"> 1679377267</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00069</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00070</td><td>2023-03-21_00-41-23</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965827</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            25.1035 </td><td style=\"text-align: right;\">           4.88046</td><td style=\"text-align: right;\">      25.1035 </td><td style=\"text-align: right;\"> 1679377283</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00070</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00071</td><td>2023-03-21_00-41-35</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.960416</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            27.7172 </td><td style=\"text-align: right;\">           4.49955</td><td style=\"text-align: right;\">      27.7172 </td><td style=\"text-align: right;\"> 1679377295</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00071</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00072</td><td>2023-03-21_00-41-35</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.953444</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            12.1701 </td><td style=\"text-align: right;\">           2.61545</td><td style=\"text-align: right;\">      12.1701 </td><td style=\"text-align: right;\"> 1679377295</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00072</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00073</td><td>2023-03-21_00-41-53</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.549197</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            18.3888 </td><td style=\"text-align: right;\">           4.1483 </td><td style=\"text-align: right;\">      18.3888 </td><td style=\"text-align: right;\"> 1679377313</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00073</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00074</td><td>2023-03-21_00-41-55</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.955836</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            19.5867 </td><td style=\"text-align: right;\">           4.61962</td><td style=\"text-align: right;\">      19.5867 </td><td style=\"text-align: right;\"> 1679377315</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00074</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00075</td><td>2023-03-21_00-41-48</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.649539</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            11.3305 </td><td style=\"text-align: right;\">           2.62754</td><td style=\"text-align: right;\">      11.3305 </td><td style=\"text-align: right;\"> 1679377308</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00075</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00076</td><td>2023-03-21_00-41-58</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.972798</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            20.1802 </td><td style=\"text-align: right;\">           5.20316</td><td style=\"text-align: right;\">      20.1802 </td><td style=\"text-align: right;\"> 1679377318</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00076</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00077</td><td>2023-03-21_00-42-01</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.96547 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            12.8416 </td><td style=\"text-align: right;\">           2.48911</td><td style=\"text-align: right;\">      12.8416 </td><td style=\"text-align: right;\"> 1679377321</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00077</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00078</td><td>2023-03-21_00-42-05</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.968716</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            11.126  </td><td style=\"text-align: right;\">           1.8987 </td><td style=\"text-align: right;\">      11.126  </td><td style=\"text-align: right;\"> 1679377325</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00078</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00079</td><td>2023-03-21_00-42-17</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.974361</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            22.009  </td><td style=\"text-align: right;\">           5.44757</td><td style=\"text-align: right;\">      22.009  </td><td style=\"text-align: right;\"> 1679377337</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00079</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00080</td><td>2023-03-21_00-42-11</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.951188</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            11.7821 </td><td style=\"text-align: right;\">           2.14807</td><td style=\"text-align: right;\">      11.7821 </td><td style=\"text-align: right;\"> 1679377331</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00080</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00081</td><td>2023-03-21_00-42-11</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.979019</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">             9.65367</td><td style=\"text-align: right;\">           2.12666</td><td style=\"text-align: right;\">       9.65367</td><td style=\"text-align: right;\"> 1679377331</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00081</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00082</td><td>2023-03-21_00-42-19</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.874652</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            14.0702 </td><td style=\"text-align: right;\">           3.01955</td><td style=\"text-align: right;\">      14.0702 </td><td style=\"text-align: right;\"> 1679377339</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00082</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00083</td><td>2023-03-21_00-42-30</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.959849</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            19.3706 </td><td style=\"text-align: right;\">           2.65798</td><td style=\"text-align: right;\">      19.3706 </td><td style=\"text-align: right;\"> 1679377350</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>2b2b2_00083</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00084</td><td>2023-03-21_00-42-32</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.967817</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            20.873  </td><td style=\"text-align: right;\">           4.15906</td><td style=\"text-align: right;\">      20.873  </td><td style=\"text-align: right;\"> 1679377352</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00084</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00085</td><td>2023-03-21_00-42-32</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.59867 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            14.2585 </td><td style=\"text-align: right;\">           2.79958</td><td style=\"text-align: right;\">      14.2585 </td><td style=\"text-align: right;\"> 1679377352</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00085</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00086</td><td>2023-03-21_00-42-32</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.946243</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            12.4444 </td><td style=\"text-align: right;\">           2.14826</td><td style=\"text-align: right;\">      12.4444 </td><td style=\"text-align: right;\"> 1679377352</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00086</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00087</td><td>2023-03-21_00-42-44</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.973818</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            13.2764 </td><td style=\"text-align: right;\">           3.03788</td><td style=\"text-align: right;\">      13.2764 </td><td style=\"text-align: right;\"> 1679377364</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00087</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00088</td><td>2023-03-21_00-42-52</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.975036</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            20.0135 </td><td style=\"text-align: right;\">           4.74619</td><td style=\"text-align: right;\">      20.0135 </td><td style=\"text-align: right;\"> 1679377372</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00088</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00089</td><td>2023-03-21_00-42-45</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0       </td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            12.9222 </td><td style=\"text-align: right;\">           2.63918</td><td style=\"text-align: right;\">      12.9222 </td><td style=\"text-align: right;\"> 1679377365</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00089</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00090</td><td>2023-03-21_00-42-48</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.855793</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            15.3453 </td><td style=\"text-align: right;\">           2.96936</td><td style=\"text-align: right;\">      15.3453 </td><td style=\"text-align: right;\"> 1679377368</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>2b2b2_00090</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00091</td><td>2023-03-21_00-43-04</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.974772</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            20.2095 </td><td style=\"text-align: right;\">           4.92726</td><td style=\"text-align: right;\">      20.2095 </td><td style=\"text-align: right;\"> 1679377384</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00091</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00092</td><td>2023-03-21_00-43-07</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.954771</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            22.08   </td><td style=\"text-align: right;\">           3.87007</td><td style=\"text-align: right;\">      22.08   </td><td style=\"text-align: right;\"> 1679377387</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>2b2b2_00092</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00093</td><td>2023-03-21_00-42-58</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.952585</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            10.0282 </td><td style=\"text-align: right;\">           2.14793</td><td style=\"text-align: right;\">      10.0282 </td><td style=\"text-align: right;\"> 1679377378</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00093</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00094</td><td>2023-03-21_00-43-15</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.95886 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            22.407  </td><td style=\"text-align: right;\">           4.80623</td><td style=\"text-align: right;\">      22.407  </td><td style=\"text-align: right;\"> 1679377395</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00094</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "<tr><td>trainable_2b2b2_00095</td><td>2023-03-21_00-43-09</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.95417 </td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            10.9547 </td><td style=\"text-align: right;\">           2.70027</td><td style=\"text-align: right;\">      10.9547 </td><td style=\"text-align: right;\"> 1679377389</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00095</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00096</td><td>2023-03-21_00-43-26</td><td>True  </td><td>                </td><td>7f62d6d622a24cb68e58839afc4b4b77</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.887562</td><td>127.0.0.1</td><td style=\"text-align: right;\">38406</td><td>True               </td><td style=\"text-align: right;\">            21.3102 </td><td style=\"text-align: right;\">           3.51271</td><td style=\"text-align: right;\">      21.3102 </td><td style=\"text-align: right;\"> 1679377406</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00096</td><td style=\"text-align: right;\">    0.0124123</td></tr>\n",
       "<tr><td>trainable_2b2b2_00097</td><td>2023-03-21_00-43-20</td><td>True  </td><td>                </td><td>9321de50b9454ec99518f35bcb03332f</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.798638</td><td>127.0.0.1</td><td style=\"text-align: right;\">38418</td><td>True               </td><td style=\"text-align: right;\">            12.0247 </td><td style=\"text-align: right;\">           2.71434</td><td style=\"text-align: right;\">      12.0247 </td><td style=\"text-align: right;\"> 1679377400</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00097</td><td style=\"text-align: right;\">    0.0147252</td></tr>\n",
       "<tr><td>trainable_2b2b2_00098</td><td>2023-03-21_00-43-38</td><td>True  </td><td>                </td><td>81c4d710a5984eb79cea751efb9a4abd</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.691849</td><td>127.0.0.1</td><td style=\"text-align: right;\">38419</td><td>True               </td><td style=\"text-align: right;\">            27.7486 </td><td style=\"text-align: right;\">           2.61631</td><td style=\"text-align: right;\">      27.7486 </td><td style=\"text-align: right;\"> 1679377418</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>2b2b2_00098</td><td style=\"text-align: right;\">    0.0148399</td></tr>\n",
       "<tr><td>trainable_2b2b2_00099</td><td>2023-03-21_00-43-32</td><td>True  </td><td>                </td><td>a4a6cd44fb71432280d39eca62e0c174</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.923318</td><td>127.0.0.1</td><td style=\"text-align: right;\">38417</td><td>True               </td><td style=\"text-align: right;\">            16.9765 </td><td style=\"text-align: right;\">           3.4626 </td><td style=\"text-align: right;\">      16.9765 </td><td style=\"text-align: right;\"> 1679377412</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>2b2b2_00099</td><td style=\"text-align: right;\">    0.0139692</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:35:51 (running for 00:00:30.38)\n",
      "Memory usage on this node: 11.9/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00003 with mnist_auc=0.978256106376648 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0071200000000000005}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 9/100 (4 PENDING, 4 RUNNING, 1 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00001 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00372 |    0.655278 |\n",
      "| trainable_2b2b2_00002 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00128 |    0.855575 |\n",
      "| trainable_2b2b2_00003 | RUNNING    | 127.0.0.1:38419 | rms      |         0.00712 |    0.978256 |\n",
      "| trainable_2b2b2_00004 | RUNNING    | 127.0.0.1:38406 | sgd      |         0.00818 |    0.851943 |\n",
      "| trainable_2b2b2_00005 | PENDING    |                 | adagrad  |         0.00075 |             |\n",
      "| trainable_2b2b2_00006 | PENDING    |                 | sgd      |         0.00125 |             |\n",
      "| trainable_2b2b2_00007 | PENDING    |                 | rms      |         0.0031  |             |\n",
      "| trainable_2b2b2_00008 | PENDING    |                 | rms      |         0.00135 |             |\n",
      "| trainable_2b2b2_00000 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00515 |    0.678888 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:36:22 (running for 00:01:00.68)\n",
      "Memory usage on this node: 12.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8864532113075256\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00003 with mnist_auc=0.9729078412055969 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0071200000000000005}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 14/100 (4 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00001 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00372 |    0.896454 |\n",
      "| trainable_2b2b2_00005 | RUNNING    | 127.0.0.1:38419 | adagrad  |         0.00075 |    0.930681 |\n",
      "| trainable_2b2b2_00008 | RUNNING    | 127.0.0.1:38406 | rms      |         0.00135 |    0.766803 |\n",
      "| trainable_2b2b2_00009 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00102 |             |\n",
      "| trainable_2b2b2_00010 | PENDING    |                 | rms      |         0.00044 |             |\n",
      "| trainable_2b2b2_00011 | PENDING    |                 | adadelta |         0.00641 |             |\n",
      "| trainable_2b2b2_00012 | PENDING    |                 | rms      |         0.0003  |             |\n",
      "| trainable_2b2b2_00013 | PENDING    |                 | adagrad  |         0.00149 |             |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00006 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00125 |    0.948686 |\n",
      "| trainable_2b2b2_00002 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00128 |    0.928004 |\n",
      "| trainable_2b2b2_00004 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00818 |    0.8554   |\n",
      "| trainable_2b2b2_00000 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00515 |    0.678888 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:36:53 (running for 00:01:31.67)\n",
      "Memory usage on this node: 12.3/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.8864532113075256\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00003 with mnist_auc=0.9729078412055969 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0071200000000000005}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 21/100 (4 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00011 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00641 |    0.915383 |\n",
      "| trainable_2b2b2_00014 | RUNNING    | 127.0.0.1:38419 | rms      |         0.00161 |    0.965464 |\n",
      "| trainable_2b2b2_00015 | RUNNING    | 127.0.0.1:38418 | adam     |         0.00883 |             |\n",
      "| trainable_2b2b2_00016 | RUNNING    | 127.0.0.1:38406 | sgd      |         0.00797 |             |\n",
      "| trainable_2b2b2_00017 | PENDING    |                 | adadelta |         0.00498 |             |\n",
      "| trainable_2b2b2_00018 | PENDING    |                 | adadelta |         0.00489 |             |\n",
      "| trainable_2b2b2_00019 | PENDING    |                 | adagrad  |         0.00273 |             |\n",
      "| trainable_2b2b2_00020 | PENDING    |                 | adam     |         0.00716 |             |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00006 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00125 |    0.948686 |\n",
      "| trainable_2b2b2_00002 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00128 |    0.928004 |\n",
      "| trainable_2b2b2_00005 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00075 |    0.927443 |\n",
      "| trainable_2b2b2_00012 | TERMINATED | 127.0.0.1:38406 | rms      |         0.0003  |    0.919307 |\n",
      "| trainable_2b2b2_00001 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00372 |    0.912039 |\n",
      "| trainable_2b2b2_00009 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00102 |    0.910548 |\n",
      "| trainable_2b2b2_00004 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00818 |    0.8554   |\n",
      "| trainable_2b2b2_00010 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00044 |    0.833665 |\n",
      "| trainable_2b2b2_00008 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00135 |    0.769777 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 1 more trials not shown (1 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:37:23 (running for 00:02:01.82)\n",
      "Memory usage on this node: 11.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9288615882396698\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00003 with mnist_auc=0.9729078412055969 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0071200000000000005}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 28/100 (4 PENDING, 4 RUNNING, 20 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00020 | RUNNING    | 127.0.0.1:38406 | adam     |         0.00716 |    0.952291 |\n",
      "| trainable_2b2b2_00021 | RUNNING    | 127.0.0.1:38418 | rms      |         0.00789 |    0.9487   |\n",
      "| trainable_2b2b2_00022 | RUNNING    | 127.0.0.1:38417 | adagrad  |         0.00191 |    0.93716  |\n",
      "| trainable_2b2b2_00023 | RUNNING    | 127.0.0.1:38419 | sgd      |         0.00189 |             |\n",
      "| trainable_2b2b2_00024 | PENDING    |                 | adagrad  |         0.00267 |             |\n",
      "| trainable_2b2b2_00025 | PENDING    |                 | adadelta |         0.00419 |             |\n",
      "| trainable_2b2b2_00026 | PENDING    |                 | adadelta |         0.00593 |             |\n",
      "| trainable_2b2b2_00027 | PENDING    |                 | adagrad  |         0.00317 |             |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00015 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00883 |    0.957825 |\n",
      "| trainable_2b2b2_00006 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00125 |    0.948686 |\n",
      "| trainable_2b2b2_00018 | TERMINATED | 127.0.0.1:38419 | adadelta |         0.00489 |    0.935508 |\n",
      "| trainable_2b2b2_00011 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00641 |    0.928734 |\n",
      "| trainable_2b2b2_00002 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00128 |    0.928004 |\n",
      "| trainable_2b2b2_00005 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00075 |    0.927443 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 8 more trials not shown (8 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:37:53 (running for 00:02:32.04)\n",
      "Memory usage on this node: 11.5/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9288615882396698\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 33/100 (4 PENDING, 4 RUNNING, 25 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00025 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00419 |    0.801197 |\n",
      "| trainable_2b2b2_00026 | RUNNING    | 127.0.0.1:38418 | adadelta |         0.00593 |    0.866209 |\n",
      "| trainable_2b2b2_00027 | RUNNING    | 127.0.0.1:38419 | adagrad  |         0.00317 |    0.960571 |\n",
      "| trainable_2b2b2_00028 | RUNNING    | 127.0.0.1:38406 | adam     |         0.00396 |    0.971017 |\n",
      "| trainable_2b2b2_00029 | PENDING    |                 | sgd      |         0.00714 |             |\n",
      "| trainable_2b2b2_00030 | PENDING    |                 | adam     |         0.0074  |             |\n",
      "| trainable_2b2b2_00031 | PENDING    |                 | rms      |         0.00561 |             |\n",
      "| trainable_2b2b2_00032 | PENDING    |                 | sgd      |         0.00344 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00021 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00789 |    0.961338 |\n",
      "| trainable_2b2b2_00023 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00189 |    0.960248 |\n",
      "| trainable_2b2b2_00015 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00883 |    0.957825 |\n",
      "| trainable_2b2b2_00020 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00716 |    0.955524 |\n",
      "| trainable_2b2b2_00022 | TERMINATED | 127.0.0.1:38417 | adagrad  |         0.00191 |    0.950467 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 13 more trials not shown (13 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:38:23 (running for 00:03:02.36)\n",
      "Memory usage on this node: 11.6/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9243887066841125\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 41/100 (4 PENDING, 4 RUNNING, 33 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00032 | RUNNING    | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00034 | RUNNING    | 127.0.0.1:38417 | rms      |         0.00519 |    0.968617 |\n",
      "| trainable_2b2b2_00035 | RUNNING    | 127.0.0.1:38419 | adam     |         0.00699 |             |\n",
      "| trainable_2b2b2_00036 | RUNNING    | 127.0.0.1:38418 | rms      |         0.00765 |             |\n",
      "| trainable_2b2b2_00037 | PENDING    |                 | adagrad  |         0.0018  |             |\n",
      "| trainable_2b2b2_00038 | PENDING    |                 | rms      |         0.00091 |             |\n",
      "| trainable_2b2b2_00039 | PENDING    |                 | adagrad  |         0.00065 |             |\n",
      "| trainable_2b2b2_00040 | PENDING    |                 | adam     |         0.00171 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00027 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00317 |    0.963041 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 21 more trials not shown (21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:38:54 (running for 00:03:32.47)\n",
      "Memory usage on this node: 11.9/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9243887066841125\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 49/100 (4 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00040 | RUNNING    | 127.0.0.1:38418 | adam     |         0.00171 |    0.927488 |\n",
      "| trainable_2b2b2_00042 | RUNNING    | 127.0.0.1:38406 | adadelta |         0.00965 |    0.825729 |\n",
      "| trainable_2b2b2_00043 | RUNNING    | 127.0.0.1:38419 | adam     |         0.00493 |    0.726144 |\n",
      "| trainable_2b2b2_00044 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.0005  |    0.529063 |\n",
      "| trainable_2b2b2_00045 | PENDING    |                 | sgd      |         0.00095 |             |\n",
      "| trainable_2b2b2_00046 | PENDING    |                 | adadelta |         0.00481 |             |\n",
      "| trainable_2b2b2_00047 | PENDING    |                 | adadelta |         0.00236 |             |\n",
      "| trainable_2b2b2_00048 | PENDING    |                 | adadelta |         0.00326 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00034 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00519 |    0.965402 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 29 more trials not shown (29 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:39:24 (running for 00:04:03.06)\n",
      "Memory usage on this node: 12.0/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9200438857078552\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 55/100 (4 PENDING, 4 RUNNING, 47 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00046 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00481 |    0.83435  |\n",
      "| trainable_2b2b2_00047 | RUNNING    | 127.0.0.1:38406 | adadelta |         0.00236 |    0.726141 |\n",
      "| trainable_2b2b2_00048 | RUNNING    | 127.0.0.1:38419 | adadelta |         0.00326 |    0.633261 |\n",
      "| trainable_2b2b2_00050 | RUNNING    | 127.0.0.1:38418 | adagrad  |         0.00736 |             |\n",
      "| trainable_2b2b2_00051 | PENDING    |                 | adadelta |         0.00969 |             |\n",
      "| trainable_2b2b2_00052 | PENDING    |                 | rms      |         0.00019 |             |\n",
      "| trainable_2b2b2_00053 | PENDING    |                 | adam     |         0.00899 |             |\n",
      "| trainable_2b2b2_00054 | PENDING    |                 | adagrad  |         0.00477 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00034 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00519 |    0.965402 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 35 more trials not shown (35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:39:55 (running for 00:04:33.47)\n",
      "Memory usage on this node: 12.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.908884584903717\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 59/100 (4 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00048 | RUNNING    | 127.0.0.1:38419 | adadelta |         0.00326 |    0.754661 |\n",
      "| trainable_2b2b2_00051 | RUNNING    | 127.0.0.1:38417 | adadelta |         0.00969 |    0.868942 |\n",
      "| trainable_2b2b2_00053 | RUNNING    | 127.0.0.1:38406 | adam     |         0.00899 |    0.587753 |\n",
      "| trainable_2b2b2_00054 | RUNNING    | 127.0.0.1:38418 | adagrad  |         0.00477 |             |\n",
      "| trainable_2b2b2_00055 | PENDING    |                 | adam     |         0.0034  |             |\n",
      "| trainable_2b2b2_00056 | PENDING    |                 | sgd      |         0.00905 |             |\n",
      "| trainable_2b2b2_00057 | PENDING    |                 | sgd      |         0.00112 |             |\n",
      "| trainable_2b2b2_00058 | PENDING    |                 | rms      |         0.00507 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00034 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00519 |    0.965402 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 39 more trials not shown (39 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:40:25 (running for 00:05:03.81)\n",
      "Memory usage on this node: 12.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9064149260520935\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 65/100 (4 PENDING, 4 RUNNING, 57 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00057 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00112 |    0.906228 |\n",
      "| trainable_2b2b2_00058 | RUNNING    | 127.0.0.1:38417 | rms      |         0.00507 |    0.503022 |\n",
      "| trainable_2b2b2_00059 | RUNNING    | 127.0.0.1:38406 | adam     |         0.00282 |    0.471961 |\n",
      "| trainable_2b2b2_00060 | RUNNING    | 127.0.0.1:38419 | rms      |         0.00172 |             |\n",
      "| trainable_2b2b2_00061 | PENDING    |                 | sgd      |         0.0076  |             |\n",
      "| trainable_2b2b2_00062 | PENDING    |                 | rms      |         0.00259 |             |\n",
      "| trainable_2b2b2_00063 | PENDING    |                 | sgd      |         0.00296 |             |\n",
      "| trainable_2b2b2_00064 | PENDING    |                 | adadelta |         0.00357 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00054 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00477 |    0.965947 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 45 more trials not shown (45 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:40:58 (running for 00:05:36.72)\n",
      "Memory usage on this node: 11.8/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9064149260520935\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 74/100 (4 PENDING, 4 RUNNING, 66 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00064 | RUNNING    | 127.0.0.1:38419 | adadelta |         0.00357 |    0.727319 |\n",
      "| trainable_2b2b2_00066 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00303 |    0.954497 |\n",
      "| trainable_2b2b2_00068 | RUNNING    | 127.0.0.1:38406 | rms      |         0.00073 |    0.94276  |\n",
      "| trainable_2b2b2_00069 | RUNNING    | 127.0.0.1:38417 | adam     |         0.00055 |             |\n",
      "| trainable_2b2b2_00070 | PENDING    |                 | rms      |         0.00481 |             |\n",
      "| trainable_2b2b2_00071 | PENDING    |                 | rms      |         0.00107 |             |\n",
      "| trainable_2b2b2_00072 | PENDING    |                 | sgd      |         0.00658 |             |\n",
      "| trainable_2b2b2_00073 | PENDING    |                 | adagrad  |         2e-05   |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00065 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00167 |    0.968515 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 54 more trials not shown (54 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:41:30 (running for 00:06:08.55)\n",
      "Memory usage on this node: 11.8/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9064149260520935\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 77/100 (4 PENDING, 4 RUNNING, 69 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00064 | RUNNING    | 127.0.0.1:38419 | adadelta |         0.00357 |    0.920007 |\n",
      "| trainable_2b2b2_00068 | RUNNING    | 127.0.0.1:38406 | rms      |         0.00073 |    0.792058 |\n",
      "| trainable_2b2b2_00071 | RUNNING    | 127.0.0.1:38417 | rms      |         0.00107 |    0.961121 |\n",
      "| trainable_2b2b2_00072 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00658 |    0.941456 |\n",
      "| trainable_2b2b2_00073 | PENDING    |                 | adagrad  |         2e-05   |             |\n",
      "| trainable_2b2b2_00074 | PENDING    |                 | adam     |         0.00459 |             |\n",
      "| trainable_2b2b2_00075 | PENDING    |                 | adagrad  |         0.00538 |             |\n",
      "| trainable_2b2b2_00076 | PENDING    |                 | sgd      |         0.00625 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00065 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00167 |    0.968515 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 57 more trials not shown (57 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:42:01 (running for 00:06:39.51)\n",
      "Memory usage on this node: 11.5/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9113542437553406\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00024 with mnist_auc=0.9769511222839355 and parameters={'optimization/method': 'adagrad', 'optimization/learning_rate': 0.00267}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 85/100 (4 PENDING, 4 RUNNING, 77 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00077 | RUNNING    | 127.0.0.1:38419 | sgd      |         0.00557 |    0.965227 |\n",
      "| trainable_2b2b2_00078 | RUNNING    | 127.0.0.1:38417 | adam     |         0.00862 |    0.967013 |\n",
      "| trainable_2b2b2_00079 | RUNNING    | 127.0.0.1:38418 | rms      |         0.0004  |             |\n",
      "| trainable_2b2b2_00080 | RUNNING    | 127.0.0.1:38406 | adam     |         0.00037 |             |\n",
      "| trainable_2b2b2_00081 | PENDING    |                 | rms      |         0.00464 |             |\n",
      "| trainable_2b2b2_00082 | PENDING    |                 | adagrad  |         0.00888 |             |\n",
      "| trainable_2b2b2_00083 | PENDING    |                 | sgd      |         0.00228 |             |\n",
      "| trainable_2b2b2_00084 | PENDING    |                 | sgd      |         0.00625 |             |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00076 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00625 |    0.972798 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00065 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00167 |    0.968515 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 65 more trials not shown (65 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:42:31 (running for 00:07:09.61)\n",
      "Memory usage on this node: 11.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9113542437553406\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00081 with mnist_auc=0.9790194630622864 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00464}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 92/100 (4 PENDING, 4 RUNNING, 84 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00084 | RUNNING    | 127.0.0.1:38419 | sgd      |         0.00625 |    0.966042 |\n",
      "| trainable_2b2b2_00085 | RUNNING    | 127.0.0.1:38418 | adadelta |         0.00067 |    0.591023 |\n",
      "| trainable_2b2b2_00086 | RUNNING    | 127.0.0.1:38417 | sgd      |         0.00192 |    0.944634 |\n",
      "| trainable_2b2b2_00087 | RUNNING    | 127.0.0.1:38406 | adagrad  |         0.00875 |             |\n",
      "| trainable_2b2b2_00088 | PENDING    |                 | adam     |         0.00251 |             |\n",
      "| trainable_2b2b2_00089 | PENDING    |                 | adam     |         0.00679 |             |\n",
      "| trainable_2b2b2_00090 | PENDING    |                 | adam     |         0.00061 |             |\n",
      "| trainable_2b2b2_00091 | PENDING    |                 | sgd      |         0.00571 |             |\n",
      "| trainable_2b2b2_00081 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00464 |    0.979019 |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00079 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0004  |    0.974361 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00076 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00625 |    0.972798 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 72 more trials not shown (72 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:43:01 (running for 00:07:39.91)\n",
      "Memory usage on this node: 11.9/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9113542437553406\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00081 with mnist_auc=0.9790194630622864 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00464}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 100/100 (4 PENDING, 4 RUNNING, 92 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00091 | RUNNING    | 127.0.0.1:38406 | sgd      |         0.00571 |    0.974419 |\n",
      "| trainable_2b2b2_00092 | RUNNING    | 127.0.0.1:38418 | sgd      |         0.00033 |    0.942374 |\n",
      "| trainable_2b2b2_00094 | RUNNING    | 127.0.0.1:38417 | sgd      |         0.00276 |    0.952947 |\n",
      "| trainable_2b2b2_00095 | RUNNING    | 127.0.0.1:38419 | adagrad  |         0.00592 |             |\n",
      "| trainable_2b2b2_00096 | PENDING    |                 | adagrad  |         0.00423 |             |\n",
      "| trainable_2b2b2_00097 | PENDING    |                 | rms      |         0.00979 |             |\n",
      "| trainable_2b2b2_00098 | PENDING    |                 | sgd      |         0.0009  |             |\n",
      "| trainable_2b2b2_00099 | PENDING    |                 | sgd      |         0.00345 |             |\n",
      "| trainable_2b2b2_00081 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00464 |    0.979019 |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00088 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00251 |    0.975036 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00079 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0004  |    0.974361 |\n",
      "| trainable_2b2b2_00087 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00875 |    0.973818 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00076 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00625 |    0.972798 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 80 more trials not shown (80 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 00:43:32 (running for 00:08:10.95)\n",
      "Memory usage on this node: 11.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9113542437553406\n",
      "Resources requested: 4.0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00081 with mnist_auc=0.9790194630622864 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00464}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 100/100 (2 RUNNING, 98 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00098 | RUNNING    | 127.0.0.1:38419 | sgd      |         0.0009  |    0.682153 |\n",
      "| trainable_2b2b2_00099 | RUNNING    | 127.0.0.1:38417 | sgd      |         0.00345 |    0.923318 |\n",
      "| trainable_2b2b2_00081 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00464 |    0.979019 |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00088 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00251 |    0.975036 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00091 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00571 |    0.974772 |\n",
      "| trainable_2b2b2_00079 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0004  |    0.974361 |\n",
      "| trainable_2b2b2_00087 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00875 |    0.973818 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00076 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00625 |    0.972798 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00078 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00862 |    0.968716 |\n",
      "| trainable_2b2b2_00065 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00167 |    0.968515 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 80 more trials not shown (80 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 00:43:38 (running for 00:08:16.60)\n",
      "Memory usage on this node: 10.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.9113542437553406\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/3.02 GiB heap, 0.0/1.51 GiB objects\n",
      "Current best trial: 2b2b2_00081 with mnist_auc=0.9790194630622864 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.00464}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmp584ijb11/2023_03_21_00_35_13\n",
      "Number of trials: 100/100 (100 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_2b2b2_00081 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00464 |    0.979019 |\n",
      "| trainable_2b2b2_00024 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00267 |    0.976951 |\n",
      "| trainable_2b2b2_00088 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00251 |    0.975036 |\n",
      "| trainable_2b2b2_00031 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00561 |    0.974983 |\n",
      "| trainable_2b2b2_00091 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00571 |    0.974772 |\n",
      "| trainable_2b2b2_00079 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0004  |    0.974361 |\n",
      "| trainable_2b2b2_00087 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00875 |    0.973818 |\n",
      "| trainable_2b2b2_00062 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00259 |    0.97348  |\n",
      "| trainable_2b2b2_00003 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00712 |    0.972908 |\n",
      "| trainable_2b2b2_00076 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00625 |    0.972798 |\n",
      "| trainable_2b2b2_00032 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00344 |    0.972228 |\n",
      "| trainable_2b2b2_00061 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.0076  |    0.970979 |\n",
      "| trainable_2b2b2_00033 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00498 |    0.970508 |\n",
      "| trainable_2b2b2_00013 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00149 |    0.970005 |\n",
      "| trainable_2b2b2_00050 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00736 |    0.969905 |\n",
      "| trainable_2b2b2_00016 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00797 |    0.969045 |\n",
      "| trainable_2b2b2_00078 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00862 |    0.968716 |\n",
      "| trainable_2b2b2_00065 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00167 |    0.968515 |\n",
      "| trainable_2b2b2_00019 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00273 |    0.967852 |\n",
      "| trainable_2b2b2_00084 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00625 |    0.967817 |\n",
      "| trainable_2b2b2_00028 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00396 |    0.96744  |\n",
      "| trainable_2b2b2_00029 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00714 |    0.966653 |\n",
      "| trainable_2b2b2_00054 | TERMINATED | 127.0.0.1:38418 | adagrad  |         0.00477 |    0.965947 |\n",
      "| trainable_2b2b2_00070 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00481 |    0.965827 |\n",
      "| trainable_2b2b2_00077 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00557 |    0.96547  |\n",
      "| trainable_2b2b2_00034 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00519 |    0.965402 |\n",
      "| trainable_2b2b2_00014 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00161 |    0.965322 |\n",
      "| trainable_2b2b2_00007 | TERMINATED | 127.0.0.1:38418 | rms      |         0.0031  |    0.964558 |\n",
      "| trainable_2b2b2_00063 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00296 |    0.964174 |\n",
      "| trainable_2b2b2_00027 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00317 |    0.963041 |\n",
      "| trainable_2b2b2_00060 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00172 |    0.961669 |\n",
      "| trainable_2b2b2_00021 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00789 |    0.961338 |\n",
      "| trainable_2b2b2_00039 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00065 |    0.961163 |\n",
      "| trainable_2b2b2_00071 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00107 |    0.960416 |\n",
      "| trainable_2b2b2_00023 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00189 |    0.960248 |\n",
      "| trainable_2b2b2_00083 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00228 |    0.959849 |\n",
      "| trainable_2b2b2_00049 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00513 |    0.958869 |\n",
      "| trainable_2b2b2_00094 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.00276 |    0.95886  |\n",
      "| trainable_2b2b2_00015 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00883 |    0.957825 |\n",
      "| trainable_2b2b2_00074 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00459 |    0.955836 |\n",
      "| trainable_2b2b2_00052 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00019 |    0.955665 |\n",
      "| trainable_2b2b2_00020 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00716 |    0.955524 |\n",
      "| trainable_2b2b2_00092 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00033 |    0.954771 |\n",
      "| trainable_2b2b2_00066 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00303 |    0.954497 |\n",
      "| trainable_2b2b2_00095 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00592 |    0.95417  |\n",
      "| trainable_2b2b2_00072 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00658 |    0.953444 |\n",
      "| trainable_2b2b2_00093 | TERMINATED | 127.0.0.1:38419 | adam     |         0.00201 |    0.952585 |\n",
      "| trainable_2b2b2_00030 | TERMINATED | 127.0.0.1:38406 | adam     |         0.0074  |    0.951855 |\n",
      "| trainable_2b2b2_00080 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00037 |    0.951188 |\n",
      "| trainable_2b2b2_00038 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00091 |    0.950977 |\n",
      "| trainable_2b2b2_00022 | TERMINATED | 127.0.0.1:38417 | adagrad  |         0.00191 |    0.950467 |\n",
      "| trainable_2b2b2_00006 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00125 |    0.948686 |\n",
      "| trainable_2b2b2_00086 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.00192 |    0.946243 |\n",
      "| trainable_2b2b2_00036 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00765 |    0.944828 |\n",
      "| trainable_2b2b2_00018 | TERMINATED | 127.0.0.1:38419 | adadelta |         0.00489 |    0.935508 |\n",
      "| trainable_2b2b2_00040 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00171 |    0.93476  |\n",
      "| trainable_2b2b2_00064 | TERMINATED | 127.0.0.1:38419 | adadelta |         0.00357 |    0.934665 |\n",
      "| trainable_2b2b2_00051 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00969 |    0.933752 |\n",
      "| trainable_2b2b2_00011 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00641 |    0.928734 |\n",
      "| trainable_2b2b2_00002 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00128 |    0.928004 |\n",
      "| trainable_2b2b2_00005 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00075 |    0.927443 |\n",
      "| trainable_2b2b2_00099 | TERMINATED | 127.0.0.1:38417 | sgd      |         0.00345 |    0.923318 |\n",
      "| trainable_2b2b2_00012 | TERMINATED | 127.0.0.1:38406 | rms      |         0.0003  |    0.919307 |\n",
      "| trainable_2b2b2_00057 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00112 |    0.91901  |\n",
      "| trainable_2b2b2_00001 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00372 |    0.912039 |\n",
      "| trainable_2b2b2_00026 | TERMINATED | 127.0.0.1:38418 | adadelta |         0.00593 |    0.911354 |\n",
      "| trainable_2b2b2_00009 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00102 |    0.910548 |\n",
      "| trainable_2b2b2_00069 | TERMINATED | 127.0.0.1:38417 | adam     |         0.00055 |    0.901627 |\n",
      "| trainable_2b2b2_00025 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00419 |    0.901476 |\n",
      "| trainable_2b2b2_00042 | TERMINATED | 127.0.0.1:38406 | adadelta |         0.00965 |    0.896848 |\n",
      "| trainable_2b2b2_00046 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00481 |    0.891591 |\n",
      "| trainable_2b2b2_00096 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.00423 |    0.887562 |\n",
      "| trainable_2b2b2_00082 | TERMINATED | 127.0.0.1:38417 | adagrad  |         0.00888 |    0.874652 |\n",
      "| trainable_2b2b2_00017 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.00498 |    0.869802 |\n",
      "| trainable_2b2b2_00090 | TERMINATED | 127.0.0.1:38419 | adam     |         0.00061 |    0.855793 |\n",
      "| trainable_2b2b2_00004 | TERMINATED | 127.0.0.1:38406 | sgd      |         0.00818 |    0.8554   |\n",
      "| trainable_2b2b2_00067 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00843 |    0.844487 |\n",
      "| trainable_2b2b2_00010 | TERMINATED | 127.0.0.1:38419 | rms      |         0.00044 |    0.833665 |\n",
      "| trainable_2b2b2_00035 | TERMINATED | 127.0.0.1:38419 | adam     |         0.00699 |    0.817462 |\n",
      "| trainable_2b2b2_00041 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00312 |    0.812842 |\n",
      "| trainable_2b2b2_00097 | TERMINATED | 127.0.0.1:38418 | rms      |         0.00979 |    0.798638 |\n",
      "| trainable_2b2b2_00047 | TERMINATED | 127.0.0.1:38406 | adadelta |         0.00236 |    0.797669 |\n",
      "| trainable_2b2b2_00068 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00073 |    0.779073 |\n",
      "| trainable_2b2b2_00048 | TERMINATED | 127.0.0.1:38419 | adadelta |         0.00326 |    0.774247 |\n",
      "| trainable_2b2b2_00008 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00135 |    0.769777 |\n",
      "| trainable_2b2b2_00037 | TERMINATED | 127.0.0.1:38406 | adagrad  |         0.0018  |    0.762585 |\n",
      "| trainable_2b2b2_00043 | TERMINATED | 127.0.0.1:38419 | adam     |         0.00493 |    0.729822 |\n",
      "| trainable_2b2b2_00056 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.00905 |    0.716317 |\n",
      "| trainable_2b2b2_00098 | TERMINATED | 127.0.0.1:38419 | sgd      |         0.0009  |    0.691849 |\n",
      "| trainable_2b2b2_00000 | TERMINATED | 127.0.0.1:38406 | rms      |         0.00515 |    0.678888 |\n",
      "| trainable_2b2b2_00075 | TERMINATED | 127.0.0.1:38419 | adagrad  |         0.00538 |    0.649539 |\n",
      "| trainable_2b2b2_00085 | TERMINATED | 127.0.0.1:38418 | adadelta |         0.00067 |    0.59867  |\n",
      "| trainable_2b2b2_00053 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00899 |    0.587753 |\n",
      "| trainable_2b2b2_00073 | TERMINATED | 127.0.0.1:38417 | adagrad  |         2e-05   |    0.549197 |\n",
      "| trainable_2b2b2_00045 | TERMINATED | 127.0.0.1:38418 | sgd      |         0.00095 |    0.548731 |\n",
      "| trainable_2b2b2_00044 | TERMINATED | 127.0.0.1:38417 | adadelta |         0.0005  |    0.542055 |\n",
      "| trainable_2b2b2_00058 | TERMINATED | 127.0.0.1:38417 | rms      |         0.00507 |    0.500706 |\n",
      "| trainable_2b2b2_00055 | TERMINATED | 127.0.0.1:38406 | adam     |         0.0034  |    0.5      |\n",
      "| trainable_2b2b2_00059 | TERMINATED | 127.0.0.1:38406 | adam     |         0.00282 |    0.471961 |\n",
      "| trainable_2b2b2_00089 | TERMINATED | 127.0.0.1:38418 | adam     |         0.00679 |    0        |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:43:48,617 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12729610240; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:43:58,677 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12729614336; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:08,705 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12728401920; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:18,773 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12728414208; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:28,840 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12728283136; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:38,905 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 12728111104; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:48,908 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13802491904; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:44:58,962 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13802225664; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:09,045 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13802000384; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:19,067 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13805215744; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:29,093 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13805158400; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:39,135 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801361408; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:49,152 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801385984; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:45:59,161 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801394176; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:46:09,255 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801345024; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:46:19,267 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801349120; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:46:29,297 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801361408; capacity: 1000240963584. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-21 00:46:39,341 E 38389 13848610] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-21_00-35-13_211893_38207 is over 95% full, available space: 13801570304; capacity: 1000240963584. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "###############################\n",
    "space[\"epochs\"] = 100\n",
    "###############################\n",
    "\n",
    "# Initialize the class using the search space, model builder, data loader, \n",
    "# and the name of the metric to optimize. The metric name for this single-task\n",
    "# model has format task_metric. This is the standard convention when using\n",
    "# glimr.keras.keras_metrics.\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# setup a temporary directory to hold tune outputs\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run the experiment in this folder\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    tuner.experiment(temp_dir.name)\n",
    "\n",
    "# cleanup the temporary folder\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
