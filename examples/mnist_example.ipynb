{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "## MNIST example\n",
    "\n",
    "This notebook demonstrates and end-to-end application of the glimr package.\n",
    "\n",
    "Using MNIST classification as a simple example, we demonstrate the steps to create a search space, model builder, and dataloader for use in tuning. This provides a concrete example of topics like using the `glimr.utils` and `glimr.keras` functions to create hyperparameters and to correctly name losses and metrics for training and reporting.\n",
    "\n",
    "This is followed by a demonstration of the `Search` class to show how to setup and run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af13097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/lcoop22/Desktop/glimr\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ray>=2.3.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from glimr==0.1.dev44+ga2ac0e7.d20230322) (2.3.0)\n",
      "Requirement already satisfied: tensorflow>=2.5 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from glimr==0.1.dev44+ga2ac0e7.d20230322) (2.11.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.0.3)\n",
      "Requirement already satisfied: grpcio<=1.49.1,>=1.32.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.49.1)\n",
      "Requirement already satisfied: filelock in /Users/lcoop22/.local/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (6.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (8.0.4)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (20.17.1)\n",
      "Requirement already satisfied: attrs in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (21.4.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.19.6)\n",
      "Requirement already satisfied: frozenlist in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.3.3)\n",
      "Requirement already satisfied: aiosignal in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.21.5)\n",
      "Requirement already satisfied: requests in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.28.1)\n",
      "Requirement already satisfied: jsonschema in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (4.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (23.1.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (15.0.6.1)\n",
      "Requirement already satisfied: packaging in /Users/lcoop22/.local/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (23.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.29.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.11.0)\n",
      "Requirement already satisfied: setuptools in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (63.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (4.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.0.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /Users/lcoop22/.local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (2.6.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.3.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from jsonschema->ray>=2.3.0->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.18.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/lcoop22/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.5->glimr==0.1.dev44+ga2ac0e7.d20230322) (3.2.2)\n",
      "Building wheels for collected packages: glimr\n",
      "  Building wheel for glimr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glimr: filename=glimr-0.1.dev44+ga2ac0e7.d20230322-py3-none-any.whl size=18229 sha256=b6b84d7edbb7f8e33d6e8afa8cfd34c75177e74fc23537a9d65a9ebf3512a2de\n",
      "  Stored in directory: /private/var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/pip-ephem-wheel-cache-xp9gwehi/wheels/58/08/39/c88c61a75aca3782dfcc11b86c8a6af860f75d1d00fddf72e2\n",
      "Successfully built glimr\n",
      "Installing collected packages: glimr\n",
      "  Attempting uninstall: glimr\n",
      "    Found existing installation: glimr 0.1.dev44+ga2ac0e7.d20230322\n",
      "    Uninstalling glimr-0.1.dev44+ga2ac0e7.d20230322:\n",
      "      Successfully uninstalled glimr-0.1.dev44+ga2ac0e7.d20230322\n",
      "Successfully installed glimr-0.1.dev44+ga2ac0e7.d20230322\n"
     ]
    }
   ],
   "source": [
    "!pip install ../../glimr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "# Creating the search space\n",
    "\n",
    "First let's create a search space for a simple two layer network for a multiclass MNIST classifier.\n",
    "\n",
    "This search space will consist of hyperparameters for each layer, for loss, for gradient optimization, and for data loading and preprocessing. Below we build these components incrementally and examine each in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b201379",
   "metadata": {},
   "source": [
    "### The first layer\n",
    "\n",
    "For the first layer we define the possible layer activations, dropout rate, and number of units. Where defining a range hyperparameter, we use `tune.quniform` which creates a quantized floating point hyperparameter. Where choosing among discrete options, we use `tune.choice` which performs a random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optimization search space from glimr\n",
    "from pprint import pprint\n",
    "from ray import tune\n",
    "\n",
    "# define the possible layer activations\n",
    "activations = tune.choice(\n",
    "    [\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"]\n",
    ")\n",
    "\n",
    "# define the layer 1 hyperparameters\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": tune.choice([64, 48, 32, 16]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03432503",
   "metadata": {},
   "source": [
    "### Defining losses and metrics\n",
    "\n",
    "Since losses can have a significant impact on performance, we may want to treat loss as a hyperparameter. Additionally, losses may have hyperparameters like label smoothting that can impact performance. Here we define a nested dictionary that randomizes choice of a hinge or cross entropy loss, and that defines label smoothing as a hyperparameter for cross entropy. Each loss has a `name` that is decoded by the model builder function to generate a `tf.keras.losses.Loss` object, and an optional `kwargs` dictionary that is used to create this object.\n",
    "\n",
    "Loss weights are assigned for each loss, and can set as hyperparameters, although here we set the loss weight to 1.\n",
    "\n",
    "Metrics provide feedback on model performance and are how Ray Tune ranks models, so they are not hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6f3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the loss as a hyperparameter\n",
    "loss = tune.choice(\n",
    "    [\n",
    "        {\"name\": \"categorical_hinge\"},\n",
    "        {\n",
    "            \"name\": \"categorical_crossentropy\",\n",
    "            \"kwargs\": {\"label_smoothing\": tune.quniform(0.0, 0.2, 0.01)},\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# use a fixed loss weight\n",
    "loss_weight = (1.0,)\n",
    "\n",
    "# set fixed metrics for reporting to Ray Tune\n",
    "metrics = {\n",
    "    \"auc\": {\n",
    "        \"name\": \"auc\",\n",
    "        \"kwargs\": {\"from_logits\": True},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf253b9",
   "metadata": {},
   "source": [
    "### Define the second layer / task\n",
    "\n",
    "We refer to the terminal outputs / layers of a network as _tasks_. Each task is named to allow automatic linking of metrics and losses at compilation time for multi-task networks, and to simplify the naming and selection of the metric used by Ray to identify the best model/trial.\n",
    "\n",
    "The specific formulation of a task depends on the model builder function, but here we define a task as a layer that has additional loss, loss weight, and metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857a5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": 10,\n",
    "    \"loss\": loss,\n",
    "    \"loss_weight\": loss_weight,\n",
    "    \"metrics\": metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d63479",
   "metadata": {},
   "source": [
    "### Optimization hyperparameters\n",
    "\n",
    "Optimization hyperparameters include the maximum number of epochs for a trial, the gradient descent algorithm, and the algorithm hyperparameters like learning rate or momentum.\n",
    "\n",
    "Glimr defines an optimization search space and an optimization builder in `glimr.keras.keras_optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e9c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 23:41:52.465531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from glimr.optimization import optimization_space\n",
    "\n",
    "optimization = optimization_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90526c8d",
   "metadata": {},
   "source": [
    "### Data loader hyperparameters\n",
    "\n",
    "Data loader hyperparameters include a required `batch_size` hyperparameter, as well as user-defined hyperparameters to control loading and preprocessing behavior. Here we define a variable batch size, and randomize the application of a brightness transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader keyword arguments to control loading, augmentation, and batching\n",
    "data = {\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"random_brightness\": tune.choice(\n",
    "        [True, False]\n",
    "    ),  # whether to perform random brightness transformation\n",
    "    \"max_delta\": tune.quniform(0.01, 0.15, 0.01),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e4c92",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The keys `data`, `optimization`, and `tasks` are all required keys that `glimr.search.Search` uses to build models during trials. For `tasks`, a dictionary maps the user-designated task names to the task dictionaries like the one defined above. A multi-task model will contain multiple task key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6784ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {   'batch_size': <ray.tune.search.sample.Categorical object at 0x7fb822c49bb0>,\n",
      "                'max_delta': <ray.tune.search.sample.Float object at 0x7fb80e8620a0>,\n",
      "                'random_brightness': <ray.tune.search.sample.Categorical object at 0x7fb822c49790>},\n",
      "    'layer1': {   'activation': <ray.tune.search.sample.Categorical object at 0x7fb822c74f10>,\n",
      "                  'dropout': <ray.tune.search.sample.Float object at 0x7fb822c74220>,\n",
      "                  'units': <ray.tune.search.sample.Categorical object at 0x7fb825bb2820>},\n",
      "    'optimization': {   'batch': <ray.tune.search.sample.Categorical object at 0x7fb825bb2640>,\n",
      "                        'beta_1': <ray.tune.search.sample.Float object at 0x7fb80c3a1340>,\n",
      "                        'beta_2': <ray.tune.search.sample.Float object at 0x7fb80cee7d60>,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': <ray.tune.search.sample.Float object at 0x7fb80c38ce50>,\n",
      "                        'method': <ray.tune.search.sample.Categorical object at 0x7fb80bcc4ca0>,\n",
      "                        'momentum': <ray.tune.search.sample.Float object at 0x7fb80c398c10>,\n",
      "                        'rho': <ray.tune.search.sample.Float object at 0x7fb80c398af0>},\n",
      "    'tasks': {   'mnist': {   'activation': <ray.tune.search.sample.Categorical object at 0x7fb822c74f10>,\n",
      "                              'dropout': <ray.tune.search.sample.Float object at 0x7fb825ba6460>,\n",
      "                              'loss': <ray.tune.search.sample.Categorical object at 0x7fb825bb2be0>,\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'auc': {   'kwargs': {   'from_logits': True},\n",
      "                                                        'name': 'auc'}},\n",
      "                              'units': 10}}}\n"
     ]
    }
   ],
   "source": [
    "# put it all together\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\"mnist\": task},\n",
    "    \"data\": data,\n",
    "}\n",
    "\n",
    "# display search space\n",
    "pprint(space, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd4332",
   "metadata": {},
   "source": [
    "### Sample a config from the search space and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec37d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {'batch_size': 32, 'max_delta': 0.06, 'random_brightness': False},\n",
      "    'layer1': {'activation': 'sigmoid', 'dropout': 0.0, 'units': 16},\n",
      "    'optimization': {   'batch': 32,\n",
      "                        'beta_1': 0.6,\n",
      "                        'beta_2': 0.62,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': 0.0017000000000000001,\n",
      "                        'method': 'adadelta',\n",
      "                        'momentum': 0.1,\n",
      "                        'rho': 0.6},\n",
      "    'tasks': {   'mnist': {   'activation': 'softplus',\n",
      "                              'dropout': 0.15000000000000002,\n",
      "                              'loss': {'name': 'categorical_hinge'},\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'auc': {   'kwargs': {   'from_logits': True},\n",
      "                                                        'name': 'auc'}},\n",
      "                              'units': 10}}}\n"
     ]
    }
   ],
   "source": [
    "from glimr.utils import sample_space\n",
    "\n",
    "config = sample_space(space)\n",
    "pprint(config, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844b5b2",
   "metadata": {},
   "source": [
    "# Implement the model-building function\n",
    "\n",
    "The model-builder function transforms a sample of the space into a `tf.keras.Model`, and loss, loss weight, and metric inputs for model compilation. This is a user-defined function to provide maximum flexibility in the models that can be used with glimr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f39255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def builder(config):\n",
    "    # a helper function for building layers\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        # dense layer\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "\n",
    "        # add dropout if necessary\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # create input layer\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "\n",
    "    # build layer 1\n",
    "    x = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"layer1\"][\"units\"],\n",
    "        config[\"layer1\"][\"activation\"],\n",
    "        config[\"layer1\"][\"dropout\"],\n",
    "        \"layer1\",\n",
    "    )\n",
    "\n",
    "    # build output / task layer\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"tasks\"][task_name][\"units\"],\n",
    "        config[\"tasks\"][task_name][\"activation\"],\n",
    "        config[\"tasks\"][task_name][\"dropout\"],\n",
    "        task_name,\n",
    "    )\n",
    "\n",
    "    # build named output dict\n",
    "    named = {f\"{task_name}\": output}\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "\n",
    "    # create a loss dictionary using utility function\n",
    "    loss_mapper = {\n",
    "        \"categorical_crossentropy\": tf.keras.losses.CategoricalCrossentropy,\n",
    "        \"categorical_hinge\": tf.keras.losses.CategoricalHinge,\n",
    "    }\n",
    "    losses, loss_weights = keras_losses(config, loss_mapper)\n",
    "\n",
    "    # create a metric dictionary using utility function\n",
    "    metric_mapper = {\"auc\": tf.keras.metrics.AUC}\n",
    "    metrics = keras_metrics(config, metric_mapper)\n",
    "\n",
    "    return model, losses, loss_weights, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "# Create a data loading function\n",
    "\n",
    "Write a function to load and batch mnist samples. Flatten the images and apply a one-hot encoding to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dataloader(batch_size, random_brightness, max_delta):\n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(\n",
    "            features.shape[0], features.shape[1] * features.shape[2]\n",
    "        )\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(train[0]), tf.float32) / 255.0\n",
    "    train_labels = train[1]\n",
    "    validation_features = tf.cast(mnist_flat(validation[0]), tf.float32) / 255.0\n",
    "    validation_labels = validation[1]\n",
    "\n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "\n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    validation_ds = validation_ds.batch(batch_size)\n",
    "\n",
    "    # apply augmentation\n",
    "    if random_brightness:\n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta), y)\n",
    "        )\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795438a8",
   "metadata": {},
   "source": [
    "### Test the search space, model builder, and dataloader\n",
    "\n",
    "Before doing a hyperparameter search, let's test this combination to verify that the models can train.\n",
    "\n",
    "We generate a sample configuration from the search space and build, compile, and train a model with this config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a779c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': {'batch_size': 128, 'max_delta': 0.09, 'random_brightness': True},\n",
      "    'layer1': {'activation': 'linear', 'dropout': 0.0, 'units': 48},\n",
      "    'optimization': {   'batch': 64,\n",
      "                        'beta_1': 0.68,\n",
      "                        'beta_2': 0.53,\n",
      "                        'epochs': 100,\n",
      "                        'learning_rate': 0.00068,\n",
      "                        'method': 'adadelta',\n",
      "                        'momentum': 0.03,\n",
      "                        'rho': 0.54},\n",
      "    'tasks': {   'mnist': {   'activation': 'linear',\n",
      "                              'dropout': 0.05,\n",
      "                              'loss': {'name': 'categorical_hinge'},\n",
      "                              'loss_weight': (1.0,),\n",
      "                              'metrics': {   'auc': {   'kwargs': {   'from_logits': True},\n",
      "                                                        'name': 'auc'}},\n",
      "                              'units': 10}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 23:41:58.888908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from glimr.keras import keras_optimizer\n",
    "import ray\n",
    "\n",
    "# sample a configuration\n",
    "config = sample_space(space)\n",
    "\n",
    "# display the configuration\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config, indent=4)\n",
    "\n",
    "# build the model\n",
    "model, losses, loss_weights, metrics = builder(config)\n",
    "\n",
    "# build the optimizer\n",
    "optimizer = keras_optimizer(config[\"optimization\"])\n",
    "\n",
    "# test compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=losses, metrics=metrics, loss_weights=loss_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab057a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lcoop22/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 1.6836 - auc: 0.5086 - val_loss: 1.6534 - val_auc: 0.5102\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.6606 - auc: 0.5138 - val_loss: 1.6326 - val_auc: 0.5152\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.6427 - auc: 0.5182 - val_loss: 1.6124 - val_auc: 0.5204\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.6210 - auc: 0.5238 - val_loss: 1.5931 - val_auc: 0.5256\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.6013 - auc: 0.5287 - val_loss: 1.5744 - val_auc: 0.5311\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5856 - auc: 0.5336 - val_loss: 1.5567 - val_auc: 0.5366\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5661 - auc: 0.5392 - val_loss: 1.5397 - val_auc: 0.5422\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.5507 - auc: 0.5445 - val_loss: 1.5236 - val_auc: 0.5480\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.5328 - auc: 0.5502 - val_loss: 1.5078 - val_auc: 0.5537\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 1.5184 - auc: 0.5553 - val_loss: 1.4928 - val_auc: 0.5595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb825ba6ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build dataset and train\n",
    "train_ds, val_ds = dataloader(**config[\"data\"])\n",
    "model.fit(x=train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "## Using Search for hyperparameter tuning\n",
    "\n",
    "The `Search` class implements the hyperparameter tuning process of Ray Tune. It is designed to provide sensible defaults for the many options available in Ray Tune, but also allows fine grained access to all Ray Tune options through it's class attributes. It is written ass a builder class that is incrementally changed to add tuning options for things like reporting, checkpointing, and experiment resources.\n",
    "\n",
    "We start by setting up a basic experiment, and then demonstrate how to control tuning options through class methods and class attribute assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264a521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 23:42:36 (running for 00:00:00.34)\n",
      "Memory usage on this node: 12.2/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 8/100 (7 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |\n",
      "|-----------------------+----------+-----------------+----------+-----------------|\n",
      "| trainable_f66bc_00000 | RUNNING  | 127.0.0.1:78727 | adadelta |         0.00189 |\n",
      "| trainable_f66bc_00001 | PENDING  |                 | sgd      |         0.00293 |\n",
      "| trainable_f66bc_00002 | PENDING  |                 | adagrad  |         0.00107 |\n",
      "| trainable_f66bc_00003 | PENDING  |                 | adagrad  |         0.00247 |\n",
      "| trainable_f66bc_00004 | PENDING  |                 | adam     |         0.00815 |\n",
      "| trainable_f66bc_00005 | PENDING  |                 | sgd      |         0.00933 |\n",
      "| trainable_f66bc_00006 | PENDING  |                 | adagrad  |         0.00072 |\n",
      "| trainable_f66bc_00007 | PENDING  |                 | rms      |         0.00264 |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname              </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mnist_auc</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_f66bc_00000</td><td>2023-03-21_23-43-34</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.678531</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">            48.9315 </td><td style=\"text-align: right;\">           4.91987</td><td style=\"text-align: right;\">      48.9315 </td><td style=\"text-align: right;\"> 1679460214</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>f66bc_00000</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00001</td><td>2023-03-21_23-43-09</td><td>True  </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.967127</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            13.24   </td><td style=\"text-align: right;\">           2.08665</td><td style=\"text-align: right;\">      13.24   </td><td style=\"text-align: right;\"> 1679460189</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>f66bc_00001</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00002</td><td>2023-03-21_23-43-24</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.850068</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            28.886  </td><td style=\"text-align: right;\">           4.16357</td><td style=\"text-align: right;\">      28.886  </td><td style=\"text-align: right;\"> 1679460204</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>f66bc_00002</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00003</td><td>2023-03-21_23-43-11</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965212</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            15.4015 </td><td style=\"text-align: right;\">           3.20595</td><td style=\"text-align: right;\">      15.4015 </td><td style=\"text-align: right;\"> 1679460191</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00003</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00004</td><td>2023-03-21_23-43-22</td><td>True  </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965887</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            13.3639 </td><td style=\"text-align: right;\">           2.88627</td><td style=\"text-align: right;\">      13.3639 </td><td style=\"text-align: right;\"> 1679460202</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00004</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00005</td><td>2023-03-21_23-43-42</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">   0.561184</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            31.1069 </td><td style=\"text-align: right;\">           4.48724</td><td style=\"text-align: right;\">      31.1069 </td><td style=\"text-align: right;\"> 1679460222</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>f66bc_00005</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00006</td><td>2023-03-21_23-43-38</td><td>True  </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.968633</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            15.9164 </td><td style=\"text-align: right;\">           2.89567</td><td style=\"text-align: right;\">      15.9164 </td><td style=\"text-align: right;\"> 1679460218</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>f66bc_00006</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00007</td><td>2023-03-21_23-43-44</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.986881</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            19.7609 </td><td style=\"text-align: right;\">           4.25161</td><td style=\"text-align: right;\">      19.7609 </td><td style=\"text-align: right;\"> 1679460224</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00007</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00008</td><td>2023-03-21_23-44-12</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         8</td><td style=\"text-align: right;\">   0.959884</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">            37.6765 </td><td style=\"text-align: right;\">           4.51655</td><td style=\"text-align: right;\">      37.6765 </td><td style=\"text-align: right;\"> 1679460252</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   8</td><td>f66bc_00008</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00009</td><td>2023-03-21_23-44-02</td><td>True  </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.949996</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            23.131  </td><td style=\"text-align: right;\">           4.37918</td><td style=\"text-align: right;\">      23.131  </td><td style=\"text-align: right;\"> 1679460242</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>f66bc_00009</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00010</td><td>2023-03-21_23-44-02</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.977821</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            19.2232 </td><td style=\"text-align: right;\">           4.44674</td><td style=\"text-align: right;\">      19.2232 </td><td style=\"text-align: right;\"> 1679460242</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00010</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00011</td><td>2023-03-21_23-43-54</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.965862</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">             9.32879</td><td style=\"text-align: right;\">           1.9555 </td><td style=\"text-align: right;\">       9.32879</td><td style=\"text-align: right;\"> 1679460234</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00011</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00012</td><td>2023-03-21_23-44-12</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.625618</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            18.2934 </td><td style=\"text-align: right;\">           4.02653</td><td style=\"text-align: right;\">      18.2934 </td><td style=\"text-align: right;\"> 1679460252</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00012</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00013</td><td>2023-03-21_23-44-16</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.942883</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            13.8571 </td><td style=\"text-align: right;\">           1.74028</td><td style=\"text-align: right;\">      13.8571 </td><td style=\"text-align: right;\"> 1679460256</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>f66bc_00013</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00014</td><td>2023-03-21_23-44-48</td><td>True  </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">   0.663578</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            45.8702 </td><td style=\"text-align: right;\">           4.37352</td><td style=\"text-align: right;\">      45.8702 </td><td style=\"text-align: right;\"> 1679460288</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  10</td><td>f66bc_00014</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00015</td><td>2023-03-21_23-44-21</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.437913</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">             9.08326</td><td style=\"text-align: right;\">           1.87924</td><td style=\"text-align: right;\">       9.08326</td><td style=\"text-align: right;\"> 1679460261</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00015</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00016</td><td>2023-03-21_23-44-22</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.961553</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">             9.42991</td><td style=\"text-align: right;\">           1.88121</td><td style=\"text-align: right;\">       9.42991</td><td style=\"text-align: right;\"> 1679460262</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00016</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00017</td><td>2023-03-21_23-44-29</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.985798</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            13.6113 </td><td style=\"text-align: right;\">           2.74582</td><td style=\"text-align: right;\">      13.6113 </td><td style=\"text-align: right;\"> 1679460269</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00017</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00018</td><td>2023-03-21_23-44-31</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.982314</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">             9.59937</td><td style=\"text-align: right;\">           1.64796</td><td style=\"text-align: right;\">       9.59937</td><td style=\"text-align: right;\"> 1679460271</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00018</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00019</td><td>2023-03-21_23-44-36</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.507705</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            13.5226 </td><td style=\"text-align: right;\">           2.73889</td><td style=\"text-align: right;\">      13.5226 </td><td style=\"text-align: right;\"> 1679460276</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00019</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00020</td><td>2023-03-21_23-44-48</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.974027</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            18.5804 </td><td style=\"text-align: right;\">           4.25445</td><td style=\"text-align: right;\">      18.5804 </td><td style=\"text-align: right;\"> 1679460288</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00020</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00021</td><td>2023-03-21_23-44-40</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.979545</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">             8.60644</td><td style=\"text-align: right;\">           1.6864 </td><td style=\"text-align: right;\">       8.60644</td><td style=\"text-align: right;\"> 1679460280</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00021</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00022</td><td>2023-03-21_23-45-00</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.868362</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            24.2257 </td><td style=\"text-align: right;\">           4.47572</td><td style=\"text-align: right;\">      24.2257 </td><td style=\"text-align: right;\"> 1679460300</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>f66bc_00022</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "<tr><td>trainable_f66bc_00023</td><td>2023-03-21_23-44-48</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.980818</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">             8.32905</td><td style=\"text-align: right;\">           1.62311</td><td style=\"text-align: right;\">       8.32905</td><td style=\"text-align: right;\"> 1679460288</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00023</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00024</td><td>2023-03-21_23-45-10</td><td>False </td><td>                </td><td>d715d7731f604c66b0e5ac11425600d0</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">   0.915044</td><td>127.0.0.1</td><td style=\"text-align: right;\">78735</td><td>True               </td><td style=\"text-align: right;\">            21.7842 </td><td style=\"text-align: right;\">           2.76561</td><td style=\"text-align: right;\">      21.7842 </td><td style=\"text-align: right;\"> 1679460310</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   7</td><td>f66bc_00024</td><td style=\"text-align: right;\">    0.0175021</td></tr>\n",
       "<tr><td>trainable_f66bc_00025</td><td>2023-03-21_23-44-58</td><td>True  </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.983379</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">             9.80198</td><td style=\"text-align: right;\">           1.8626 </td><td style=\"text-align: right;\">       9.80198</td><td style=\"text-align: right;\"> 1679460298</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00025</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00026</td><td>2023-03-21_23-45-00</td><td>True  </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">   0.960231</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            11.2863 </td><td style=\"text-align: right;\">           2.06651</td><td style=\"text-align: right;\">      11.2863 </td><td style=\"text-align: right;\"> 1679460300</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   5</td><td>f66bc_00026</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00027</td><td>2023-03-21_23-45-13</td><td>False </td><td>                </td><td>d9db0132e4634401ade3dfa9e1562aba</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">   0.761295</td><td>127.0.0.1</td><td style=\"text-align: right;\">78727</td><td>True               </td><td style=\"text-align: right;\">            14.9978 </td><td style=\"text-align: right;\">           4.41237</td><td style=\"text-align: right;\">      14.9978 </td><td style=\"text-align: right;\"> 1679460313</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   3</td><td>f66bc_00027</td><td style=\"text-align: right;\">    0.0142858</td></tr>\n",
       "<tr><td>trainable_f66bc_00028</td><td>2023-03-21_23-45-14</td><td>False </td><td>                </td><td>e315cd9bd3c64197bbf1a75c15fb3ca6</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">   0.967326</td><td>127.0.0.1</td><td style=\"text-align: right;\">78737</td><td>True               </td><td style=\"text-align: right;\">            14.0854 </td><td style=\"text-align: right;\">           4.36434</td><td style=\"text-align: right;\">      14.0854 </td><td style=\"text-align: right;\"> 1679460314</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   3</td><td>f66bc_00028</td><td style=\"text-align: right;\">    0.0200629</td></tr>\n",
       "<tr><td>trainable_f66bc_00029</td><td>2023-03-21_23-45-13</td><td>True  </td><td>                </td><td>257dafc66be64ad9a8bf3a00e92908d2</td><td>Lees-MacBook-Pro.local</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">   0.966896</td><td>127.0.0.1</td><td style=\"text-align: right;\">78736</td><td>True               </td><td style=\"text-align: right;\">            12.7841 </td><td style=\"text-align: right;\">           2.84669</td><td style=\"text-align: right;\">      12.7841 </td><td style=\"text-align: right;\"> 1679460313</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   4</td><td>f66bc_00029</td><td style=\"text-align: right;\">    0.0177209</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 23:43:07 (running for 00:00:31.42)\n",
      "Memory usage on this node: 11.9/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00001 with mnist_auc=0.96419358253479 and parameters={'optimization/method': 'sgd', 'optimization/learning_rate': 0.0029300000000000003}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 8/100 (4 PENDING, 4 RUNNING)\n",
      "+-----------------------+----------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status   | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+----------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00000 | RUNNING  | 127.0.0.1:78727 | adadelta |         0.00189 |    0.615816 |\n",
      "| trainable_f66bc_00001 | RUNNING  | 127.0.0.1:78735 | sgd      |         0.00293 |    0.964194 |\n",
      "| trainable_f66bc_00002 | RUNNING  | 127.0.0.1:78736 | adagrad  |         0.00107 |    0.771102 |\n",
      "| trainable_f66bc_00003 | RUNNING  | 127.0.0.1:78737 | adagrad  |         0.00247 |    0.963022 |\n",
      "| trainable_f66bc_00004 | PENDING  |                 | adam     |         0.00815 |             |\n",
      "| trainable_f66bc_00005 | PENDING  |                 | sgd      |         0.00933 |             |\n",
      "| trainable_f66bc_00006 | PENDING  |                 | adagrad  |         0.00072 |             |\n",
      "| trainable_f66bc_00007 | PENDING  |                 | rms      |         0.00264 |             |\n",
      "+-----------------------+----------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 23:43:38 (running for 00:01:02.44)\n",
      "Memory usage on this node: 12.0/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.6785305738449097\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00007 with mnist_auc=0.9851184487342834 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0026400000000000004}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 13/100 (4 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00005 | RUNNING    | 127.0.0.1:78737 | sgd      |         0.00933 |    0.549135 |\n",
      "| trainable_f66bc_00006 | RUNNING    | 127.0.0.1:78735 | adagrad  |         0.00072 |    0.965233 |\n",
      "| trainable_f66bc_00007 | RUNNING    | 127.0.0.1:78736 | rms      |         0.00264 |    0.985118 |\n",
      "| trainable_f66bc_00008 | RUNNING    | 127.0.0.1:78727 | adadelta |         0.00967 |             |\n",
      "| trainable_f66bc_00009 | PENDING    |                 | sgd      |         0.00176 |             |\n",
      "| trainable_f66bc_00010 | PENDING    |                 | adagrad  |         0.00311 |             |\n",
      "| trainable_f66bc_00011 | PENDING    |                 | rms      |         0.00711 |             |\n",
      "| trainable_f66bc_00012 | PENDING    |                 | rms      |         0.00998 |             |\n",
      "| trainable_f66bc_00001 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00293 |    0.967127 |\n",
      "| trainable_f66bc_00004 | TERMINATED | 127.0.0.1:78735 | adam     |         0.00815 |    0.965887 |\n",
      "| trainable_f66bc_00003 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00247 |    0.965212 |\n",
      "| trainable_f66bc_00002 | TERMINATED | 127.0.0.1:78736 | adagrad  |         0.00107 |    0.850068 |\n",
      "| trainable_f66bc_00000 | TERMINATED | 127.0.0.1:78727 | adadelta |         0.00189 |    0.678531 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 23:44:08 (running for 00:01:32.56)\n",
      "Memory usage on this node: 11.4/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.6785305738449097\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00007 with mnist_auc=0.98688143491745 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0026400000000000004}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 19/100 (4 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00008 | RUNNING    | 127.0.0.1:78727 | adadelta |         0.00967 |    0.955056 |\n",
      "| trainable_f66bc_00012 | RUNNING    | 127.0.0.1:78736 | rms      |         0.00998 |    0.631159 |\n",
      "| trainable_f66bc_00013 | RUNNING    | 127.0.0.1:78737 | sgd      |         0.00369 |    0.875168 |\n",
      "| trainable_f66bc_00014 | RUNNING    | 127.0.0.1:78735 | sgd      |         0.00408 |    0.552926 |\n",
      "| trainable_f66bc_00015 | PENDING    |                 | adagrad  |         0.0049  |             |\n",
      "| trainable_f66bc_00016 | PENDING    |                 | adam     |         0.00866 |             |\n",
      "| trainable_f66bc_00017 | PENDING    |                 | adam     |         0.00641 |             |\n",
      "| trainable_f66bc_00018 | PENDING    |                 | adam     |         0.00014 |             |\n",
      "| trainable_f66bc_00007 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00264 |    0.986881 |\n",
      "| trainable_f66bc_00010 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00311 |    0.977821 |\n",
      "| trainable_f66bc_00006 | TERMINATED | 127.0.0.1:78735 | adagrad  |         0.00072 |    0.968633 |\n",
      "| trainable_f66bc_00001 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00293 |    0.967127 |\n",
      "| trainable_f66bc_00004 | TERMINATED | 127.0.0.1:78735 | adam     |         0.00815 |    0.965887 |\n",
      "| trainable_f66bc_00011 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00711 |    0.965862 |\n",
      "| trainable_f66bc_00003 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00247 |    0.965212 |\n",
      "| trainable_f66bc_00009 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00176 |    0.949996 |\n",
      "| trainable_f66bc_00002 | TERMINATED | 127.0.0.1:78736 | adagrad  |         0.00107 |    0.850068 |\n",
      "| trainable_f66bc_00000 | TERMINATED | 127.0.0.1:78727 | adadelta |         0.00189 |    0.678531 |\n",
      "| trainable_f66bc_00005 | TERMINATED | 127.0.0.1:78737 | sgd      |         0.00933 |    0.561184 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 23:44:38 (running for 00:02:02.63)\n",
      "Memory usage on this node: 11.7/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.6785305738449097\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00007 with mnist_auc=0.98688143491745 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0026400000000000004}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 27/100 (4 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00014 | RUNNING    | 127.0.0.1:78735 | sgd      |         0.00408 |    0.653305 |\n",
      "| trainable_f66bc_00020 | RUNNING    | 127.0.0.1:78737 | adam     |         0.00427 |    0.975527 |\n",
      "| trainable_f66bc_00021 | RUNNING    | 127.0.0.1:78727 | rms      |         0.00056 |    0.979297 |\n",
      "| trainable_f66bc_00022 | RUNNING    | 127.0.0.1:78736 | rms      |         0.00036 |             |\n",
      "| trainable_f66bc_00023 | PENDING    |                 | sgd      |         0.00956 |             |\n",
      "| trainable_f66bc_00024 | PENDING    |                 | adadelta |         0.00539 |             |\n",
      "| trainable_f66bc_00025 | PENDING    |                 | adam     |         0.00705 |             |\n",
      "| trainable_f66bc_00026 | PENDING    |                 | sgd      |         0.00915 |             |\n",
      "| trainable_f66bc_00007 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00264 |    0.986881 |\n",
      "| trainable_f66bc_00017 | TERMINATED | 127.0.0.1:78737 | adam     |         0.00641 |    0.985798 |\n",
      "| trainable_f66bc_00018 | TERMINATED | 127.0.0.1:78727 | adam     |         0.00014 |    0.982314 |\n",
      "| trainable_f66bc_00010 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00311 |    0.977821 |\n",
      "| trainable_f66bc_00006 | TERMINATED | 127.0.0.1:78735 | adagrad  |         0.00072 |    0.968633 |\n",
      "| trainable_f66bc_00001 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00293 |    0.967127 |\n",
      "| trainable_f66bc_00004 | TERMINATED | 127.0.0.1:78735 | adam     |         0.00815 |    0.965887 |\n",
      "| trainable_f66bc_00011 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00711 |    0.965862 |\n",
      "| trainable_f66bc_00003 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00247 |    0.965212 |\n",
      "| trainable_f66bc_00016 | TERMINATED | 127.0.0.1:78736 | adam     |         0.00866 |    0.961553 |\n",
      "| trainable_f66bc_00008 | TERMINATED | 127.0.0.1:78727 | adadelta |         0.00967 |    0.959884 |\n",
      "| trainable_f66bc_00009 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00176 |    0.949996 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 7 more trials not shown (7 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-03-21 23:45:09 (running for 00:02:33.78)\n",
      "Memory usage on this node: 12.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.6747923344373703\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00007 with mnist_auc=0.98688143491745 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0026400000000000004}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 34/100 (4 PENDING, 4 RUNNING, 26 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00024 | RUNNING    | 127.0.0.1:78735 | adadelta |         0.00539 |    0.899234 |\n",
      "| trainable_f66bc_00027 | RUNNING    | 127.0.0.1:78727 | rms      |         0.00788 |    0.760393 |\n",
      "| trainable_f66bc_00028 | RUNNING    | 127.0.0.1:78737 | adagrad  |         0.00092 |    0.953925 |\n",
      "| trainable_f66bc_00029 | RUNNING    | 127.0.0.1:78736 | adagrad  |         0.00745 |    0.962011 |\n",
      "| trainable_f66bc_00030 | PENDING    |                 | adam     |         0.00641 |             |\n",
      "| trainable_f66bc_00031 | PENDING    |                 | sgd      |         0.00929 |             |\n",
      "| trainable_f66bc_00032 | PENDING    |                 | sgd      |         0.0092  |             |\n",
      "| trainable_f66bc_00033 | PENDING    |                 | sgd      |         0.00679 |             |\n",
      "| trainable_f66bc_00007 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00264 |    0.986881 |\n",
      "| trainable_f66bc_00017 | TERMINATED | 127.0.0.1:78737 | adam     |         0.00641 |    0.985798 |\n",
      "| trainable_f66bc_00025 | TERMINATED | 127.0.0.1:78727 | adam     |         0.00705 |    0.983379 |\n",
      "| trainable_f66bc_00018 | TERMINATED | 127.0.0.1:78727 | adam     |         0.00014 |    0.982314 |\n",
      "| trainable_f66bc_00023 | TERMINATED | 127.0.0.1:78727 | sgd      |         0.00956 |    0.980818 |\n",
      "| trainable_f66bc_00021 | TERMINATED | 127.0.0.1:78727 | rms      |         0.00056 |    0.979545 |\n",
      "| trainable_f66bc_00010 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00311 |    0.977821 |\n",
      "| trainable_f66bc_00020 | TERMINATED | 127.0.0.1:78737 | adam     |         0.00427 |    0.974027 |\n",
      "| trainable_f66bc_00006 | TERMINATED | 127.0.0.1:78735 | adagrad  |         0.00072 |    0.968633 |\n",
      "| trainable_f66bc_00001 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00293 |    0.967127 |\n",
      "| trainable_f66bc_00004 | TERMINATED | 127.0.0.1:78735 | adam     |         0.00815 |    0.965887 |\n",
      "| trainable_f66bc_00011 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00711 |    0.965862 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "... 14 more trials not shown (14 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-03-21 23:45:14 (running for 00:02:38.91)\n",
      "Memory usage on this node: 12.1/16.0 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 40.000: None | Iter 10.000: 0.6747923344373703\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/2.92 GiB heap, 0.0/1.46 GiB objects\n",
      "Current best trial: f66bc_00007 with mnist_auc=0.98688143491745 and parameters={'optimization/method': 'rms', 'optimization/learning_rate': 0.0026400000000000004}\n",
      "Result logdir: /var/folders/p8/2m9hqfn51c3_zkpq1894xzf80000gn/T/tmpjpedswwi/2023_03_21_23_42_28\n",
      "Number of trials: 35/100 (4 PENDING, 4 RUNNING, 27 TERMINATED)\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "| Trial name            | status     | loc             | method   |   learning rate |   mnist_auc |\n",
      "|-----------------------+------------+-----------------+----------+-----------------+-------------|\n",
      "| trainable_f66bc_00024 | RUNNING    | 127.0.0.1:78735 | adadelta |         0.00539 |    0.924617 |\n",
      "| trainable_f66bc_00027 | RUNNING    | 127.0.0.1:78727 | rms      |         0.00788 |    0.761295 |\n",
      "| trainable_f66bc_00028 | RUNNING    | 127.0.0.1:78737 | adagrad  |         0.00092 |    0.967326 |\n",
      "| trainable_f66bc_00030 | RUNNING    | 127.0.0.1:78736 | adam     |         0.00641 |             |\n",
      "| trainable_f66bc_00031 | PENDING    |                 | sgd      |         0.00929 |             |\n",
      "| trainable_f66bc_00032 | PENDING    |                 | sgd      |         0.0092  |             |\n",
      "| trainable_f66bc_00033 | PENDING    |                 | sgd      |         0.00679 |             |\n",
      "| trainable_f66bc_00034 | PENDING    |                 | sgd      |         0.00255 |             |\n",
      "| trainable_f66bc_00007 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00264 |    0.986881 |\n",
      "| trainable_f66bc_00017 | TERMINATED | 127.0.0.1:78737 | adam     |         0.00641 |    0.985798 |\n",
      "| trainable_f66bc_00025 | TERMINATED | 127.0.0.1:78727 | adam     |         0.00705 |    0.983379 |\n",
      "| trainable_f66bc_00018 | TERMINATED | 127.0.0.1:78727 | adam     |         0.00014 |    0.982314 |\n",
      "| trainable_f66bc_00023 | TERMINATED | 127.0.0.1:78727 | sgd      |         0.00956 |    0.980818 |\n",
      "| trainable_f66bc_00021 | TERMINATED | 127.0.0.1:78727 | rms      |         0.00056 |    0.979545 |\n",
      "| trainable_f66bc_00010 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00311 |    0.977821 |\n",
      "| trainable_f66bc_00020 | TERMINATED | 127.0.0.1:78737 | adam     |         0.00427 |    0.974027 |\n",
      "| trainable_f66bc_00006 | TERMINATED | 127.0.0.1:78735 | adagrad  |         0.00072 |    0.968633 |\n",
      "| trainable_f66bc_00001 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00293 |    0.967127 |\n",
      "| trainable_f66bc_00029 | TERMINATED | 127.0.0.1:78736 | adagrad  |         0.00745 |    0.966896 |\n",
      "| trainable_f66bc_00004 | TERMINATED | 127.0.0.1:78735 | adam     |         0.00815 |    0.965887 |\n",
      "| trainable_f66bc_00011 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00711 |    0.965862 |\n",
      "| trainable_f66bc_00003 | TERMINATED | 127.0.0.1:78737 | adagrad  |         0.00247 |    0.965212 |\n",
      "| trainable_f66bc_00016 | TERMINATED | 127.0.0.1:78736 | adam     |         0.00866 |    0.961553 |\n",
      "| trainable_f66bc_00026 | TERMINATED | 127.0.0.1:78737 | sgd      |         0.00915 |    0.960231 |\n",
      "| trainable_f66bc_00008 | TERMINATED | 127.0.0.1:78727 | adadelta |         0.00967 |    0.959884 |\n",
      "| trainable_f66bc_00009 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00176 |    0.949996 |\n",
      "| trainable_f66bc_00013 | TERMINATED | 127.0.0.1:78737 | sgd      |         0.00369 |    0.942883 |\n",
      "| trainable_f66bc_00022 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00036 |    0.868362 |\n",
      "| trainable_f66bc_00002 | TERMINATED | 127.0.0.1:78736 | adagrad  |         0.00107 |    0.850068 |\n",
      "| trainable_f66bc_00000 | TERMINATED | 127.0.0.1:78727 | adadelta |         0.00189 |    0.678531 |\n",
      "| trainable_f66bc_00014 | TERMINATED | 127.0.0.1:78735 | sgd      |         0.00408 |    0.663578 |\n",
      "| trainable_f66bc_00012 | TERMINATED | 127.0.0.1:78736 | rms      |         0.00998 |    0.625618 |\n",
      "| trainable_f66bc_00005 | TERMINATED | 127.0.0.1:78737 | sgd      |         0.00933 |    0.561184 |\n",
      "| trainable_f66bc_00019 | TERMINATED | 127.0.0.1:78736 | adadelta |         0.00196 |    0.507705 |\n",
      "| trainable_f66bc_00015 | TERMINATED | 127.0.0.1:78727 | adagrad  |         0.0049  |    0.437913 |\n",
      "+-----------------------+------------+-----------------+----------+-----------------+-------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Initialize the class using the search space, model builder, data loader,\n",
    "# and the name of the metric to optimize. The metric name for this single-task\n",
    "# model has format task_metric. This is the standard convention when using\n",
    "# glimr.keras.keras_metrics.\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# setup a temporary directory to hold tune outputs\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run the experiment in this folder\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    tuner.experiment(temp_dir.name)\n",
    "\n",
    "# cleanup the temporary folder\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
