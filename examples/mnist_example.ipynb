{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9676b",
   "metadata": {},
   "source": [
    "## MNIST example\n",
    "\n",
    "This notebook demonstrates and end-to-end application of the glimr package.\n",
    "\n",
    "Using MNIST classification as a simple example, we demonstrate the steps to create a search space, model builder, and dataloader for use in tuning. This provides a concrete example of topics like using the `glimr.utils` and `glimr.keras` functions to create hyperparameters and to correctly name losses and metrics for training and reporting.\n",
    "\n",
    "This is followed by a demonstration of the `Search` class to show how to setup and run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af13097",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../../glimr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2a3d6",
   "metadata": {},
   "source": [
    "# Creating the search space\n",
    "\n",
    "First let's create a search space for a simple two layer network for a multiclass MNIST classifier.\n",
    "\n",
    "This search space will consist of hyperparameters for each layer, for loss, for gradient optimization, and for data loading and preprocessing. Below we build these components incrementally and examine each in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b201379",
   "metadata": {},
   "source": [
    "### The first layer\n",
    "\n",
    "For the first layer we define the possible layer activations, dropout rate, and number of units. Where defining a range hyperparameter, we use `tune.quniform` which creates a quantized floating point hyperparameter. Where choosing among discrete options, we use `tune.choice` which performs a random selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c338990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optimization search space from glimr\n",
    "from pprint import pprint\n",
    "from ray import tune\n",
    "\n",
    "# define the possible layer activations\n",
    "activations = tune.choice(\n",
    "    [\"elu\", \"gelu\", \"linear\", \"relu\", \"selu\", \"sigmoid\", \"softplus\"]\n",
    ")\n",
    "\n",
    "# define the layer 1 hyperparameters\n",
    "layer1 = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": tune.choice([64, 48, 32, 16]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03432503",
   "metadata": {},
   "source": [
    "### Defining losses and metrics\n",
    "\n",
    "Since losses and their parameters can have a significant impact on performance, we may want to treat them as tunable hyperparameters. For example, properties like label smoothing thresholds can be searched to identify optimal values. Here we define a nested dictionary that randomizes choice of a hinge or cross entropy loss, and that defines label smoothing as a hyperparameter for cross entropy. Each loss has a `name` that defines how this loss is registered and reported by Ray Tune, and a `loss` parameter that defines a `tf.keras.losses.Loss` subclass. An optional `kwargs` dictionary is used to customize the class instance when it is created during a trial.\n",
    "\n",
    "Loss weights are assigned for each loss, and can set as hyperparameters, although here we set the loss weight to 1.\n",
    "\n",
    "Metrics provide feedback on model performance and are how Ray Tune ranks models, so they are not hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# set the loss as a hyperparameter\n",
    "loss = tune.choice(\n",
    "    [\n",
    "        {\"name\": \"categorical_hinge\", \"loss\": tf.keras.losses.CategoricalHinge},\n",
    "        {\n",
    "            \"name\": \"categorical_crossentropy\",\n",
    "            \"loss\": tf.keras.losses.CategoricalCrossentropy,\n",
    "            \"kwargs\": {\"label_smoothing\": tune.quniform(0.0, 0.2, 0.01)},\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# use a fixed loss weight\n",
    "loss_weight = (1.0,)\n",
    "\n",
    "# set fixed metrics for reporting to Ray Tune\n",
    "metrics = {\n",
    "    \"name\": \"auc\",\n",
    "    \"metric\": tf.keras.metrics.AUC,\n",
    "    \"kwargs\": {\"from_logits\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf253b9",
   "metadata": {},
   "source": [
    "### Define the second layer / task\n",
    "\n",
    "We refer to the terminal outputs / layers of a network as _tasks_. Each task is named to allow automatic linking of metrics and losses at compilation time for multi-task networks, and to simplify the naming and selection of the metric used by Ray to identify the best model/trial.\n",
    "\n",
    "The specific formulation of a task depends on the model builder function, but here we define a task as a layer that has additional loss, loss weight, and metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task\n",
    "task = {\n",
    "    \"activation\": activations,\n",
    "    \"dropout\": tune.quniform(0.0, 0.2, 0.05),\n",
    "    \"units\": 10,\n",
    "    \"loss\": loss,\n",
    "    \"loss_weight\": loss_weight,\n",
    "    \"metrics\": metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d63479",
   "metadata": {},
   "source": [
    "### Optimization hyperparameters\n",
    "\n",
    "Optimization hyperparameters include the maximum number of epochs for a trial, the gradient descent algorithm, and the algorithm hyperparameters like learning rate or momentum.\n",
    "\n",
    "Glimr defines an optimization search space and an optimization builder in `glimr.keras.keras_optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.optimization import optimization_space\n",
    "\n",
    "optimization = optimization_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90526c8d",
   "metadata": {},
   "source": [
    "### Data loader hyperparameters\n",
    "\n",
    "Data loader hyperparameters include a required `batch_size` hyperparameter, as well as user-defined hyperparameters to control loading and preprocessing behavior. Here we define a variable batch size, and randomize the application of a brightness transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader keyword arguments to control loading, augmentation, and batching\n",
    "data = {\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "    \"random_brightness\": tune.choice(\n",
    "        [True, False]\n",
    "    ),  # whether to perform random brightness transformation\n",
    "    \"max_delta\": tune.quniform(0.01, 0.15, 0.01),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e4c92",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The keys `data`, `optimization`, and `tasks` are all required keys that `glimr.search.Search` uses to build models during trials. For `tasks`, a dictionary maps the user-designated task names to the task dictionaries like the one defined above. A multi-task model will contain multiple task key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6784ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all together\n",
    "space = {\n",
    "    \"layer1\": layer1,\n",
    "    \"optimization\": optimization_space(),\n",
    "    \"tasks\": {\"mnist\": task},\n",
    "    \"data\": data,\n",
    "}\n",
    "\n",
    "# display search space\n",
    "pprint(space, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd4332",
   "metadata": {},
   "source": [
    "### Sample a config from the search space and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec37d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.utils import sample_space\n",
    "\n",
    "config = sample_space(space)\n",
    "pprint(config, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844b5b2",
   "metadata": {},
   "source": [
    "# Implement the model-building function\n",
    "\n",
    "The model-builder function transforms a sample of the space into a `tf.keras.Model`, and loss, loss weight, and metric inputs for model compilation. This is a user-defined function to provide maximum flexibility in the models that can be used with glimr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_losses, keras_metrics\n",
    "\n",
    "\n",
    "def builder(config):\n",
    "    # a helper function for building layers\n",
    "    def _build_layer(x, units, activation, dropout, name):\n",
    "        # dense layer\n",
    "        x = tf.keras.layers.Dense(units, activation=activation, name=name)(x)\n",
    "\n",
    "        # add dropout if necessary\n",
    "        if dropout > 0.0:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # create input layer\n",
    "    input_layer = tf.keras.Input([784], name=\"input\")\n",
    "\n",
    "    # build layer 1\n",
    "    x = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"layer1\"][\"units\"],\n",
    "        config[\"layer1\"][\"activation\"],\n",
    "        config[\"layer1\"][\"dropout\"],\n",
    "        \"layer1\",\n",
    "    )\n",
    "\n",
    "    # build output / task layer\n",
    "    task_name = list(config[\"tasks\"].keys())[0]\n",
    "    output = _build_layer(\n",
    "        input_layer,\n",
    "        config[\"tasks\"][task_name][\"units\"],\n",
    "        config[\"tasks\"][task_name][\"activation\"],\n",
    "        config[\"tasks\"][task_name][\"dropout\"],\n",
    "        task_name,\n",
    "    )\n",
    "\n",
    "    # build named output dict\n",
    "    named = {f\"{task_name}\": output}\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=named)\n",
    "\n",
    "    # create a loss dictionary\n",
    "    losses, loss_weights = keras_losses(config)\n",
    "\n",
    "    # create a metric dictionary\n",
    "    metrics = keras_metrics(config)\n",
    "\n",
    "    return model, losses, loss_weights, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f8176",
   "metadata": {},
   "source": [
    "# Create a data loading function\n",
    "\n",
    "Write a function to load and batch mnist samples. Flatten the images and apply a one-hot encoding to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dataloader(batch_size, random_brightness, max_delta):\n",
    "    # load mnist data\n",
    "    train, validation = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "    # flattening function\n",
    "    def mnist_flat(features):\n",
    "        return features.reshape(\n",
    "            features.shape[0], features.shape[1] * features.shape[2]\n",
    "        )\n",
    "\n",
    "    # extract features, labels\n",
    "    train_features = tf.cast(mnist_flat(train[0]), tf.float32) / 255.0\n",
    "    train_labels = train[1]\n",
    "    validation_features = tf.cast(mnist_flat(validation[0]), tf.float32) / 255.0\n",
    "    validation_labels = validation[1]\n",
    "\n",
    "    # build datasets\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (train_features, {\"mnist\": tf.one_hot(train_labels, 10)})\n",
    "    )\n",
    "    validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (validation_features, {\"mnist\": tf.one_hot(validation_labels, 10)})\n",
    "    )\n",
    "\n",
    "    # batch\n",
    "    train_ds = train_ds.shuffle(len(train_labels), reshuffle_each_iteration=True)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    validation_ds = validation_ds.batch(batch_size)\n",
    "\n",
    "    # apply augmentation\n",
    "    if random_brightness:\n",
    "        train_ds = train_ds.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta), y)\n",
    "        )\n",
    "\n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795438a8",
   "metadata": {},
   "source": [
    "### Test the search space, model builder, and dataloader\n",
    "\n",
    "Before doing a hyperparameter search, let's test this combination to verify that the models can train.\n",
    "\n",
    "We generate a sample configuration from the search space and build, compile, and train a model with this config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a779c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glimr.keras import keras_optimizer\n",
    "import ray\n",
    "\n",
    "# sample a configuration\n",
    "config = sample_space(space)\n",
    "\n",
    "# display the configuration\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config, indent=4)\n",
    "\n",
    "# build the model\n",
    "model, losses, loss_weights, metrics = builder(config)\n",
    "\n",
    "# build the optimizer\n",
    "optimizer = keras_optimizer(config[\"optimization\"])\n",
    "\n",
    "# test compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=losses, metrics=metrics, loss_weights=loss_weights\n",
    ")\n",
    "\n",
    "# build dataset and train\n",
    "train_ds, val_ds = dataloader(**config[\"data\"])\n",
    "model.fit(x=train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7afc",
   "metadata": {},
   "source": [
    "# Using Search for hyperparameter tuning\n",
    "\n",
    "The `Search` class implements the hyperparameter tuning process of Ray Tune. It provides sensible defaults for the many options available in Ray Tune, but also allows fine grained access to these options through class methods and attributes. Options can be added or assigned incrementally to alter reporting, checkpointing, trial stopping criteria, and resources used in experiments.\n",
    "\n",
    "We begin with a basic experiment using the AsyncHyperBandScheduler which performs a random search but terminates poorly performing trials early.\n",
    "\n",
    "By default if a reporter is not set, however, Ray Tune will display a dynamic table of ongoing experiments and results if running in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from glimr.search import Search\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Initialize a Search instance with the search space, model builder, and\n",
    "# data loader. The name of the metric and indicate to Ray how to measure\n",
    "# model performance, and are provided in format task_metric. This is the\n",
    "# convention when building models using glimr.keras.keras_metrics.\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# make a temporary directory to store outputs - cleanup at end\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# run trials using default settings\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"default\", num_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175cfde",
   "metadata": {},
   "source": [
    "### Display information about the best trial\n",
    "\n",
    "The output from `Search.experiment` contains information on each trial's performance and configuration, and can be used for trial analysis and for keeping the best checkpointed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about the best trial\n",
    "best_result = results.get_best_result()\n",
    "best_auc = best_result.metrics[\"mnist_auc\"]\n",
    "best_config = best_result.metrics[\"config\"]\n",
    "best_checkpoint = best_result.checkpoint.to_directory()\n",
    "\n",
    "# display\n",
    "print(f\"best result auc: {best_auc}\")\n",
    "print(\"best configuration:\")\n",
    "pprint(best_config, indent=4)\n",
    "print(\"contents of best trial checkpoint:\")\n",
    "print(os.listdir(os.path.join(best_checkpoint, \"checkpoint\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a830f",
   "metadata": {},
   "source": [
    "### Experiment performance statistics for default settings\n",
    "\n",
    "Let's plot the performance of trials from the default experiment which uses an AsyncHyperband scheduler with a random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf4d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe from default experiment\n",
    "default_table = results.get_dataframe()\n",
    "default_auc = np.array(default_table[\"mnist_auc\"])\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(-np.sort(-default_auc))\n",
    "plt.xlabel(\"trial\")\n",
    "plt.ylabel(\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4ba37",
   "metadata": {},
   "source": [
    "### Using a population-based training scheduler\n",
    "\n",
    "Let's change the scheduler to population-based training (PBT). PBT optimizes resource utililzation by replacing poorly performing trials with \"mutated\" versions of top performing trials.\n",
    "\n",
    "We recommend creating a new `Search` object for every experiment to avoid issues with Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# create the PBT trainer - the entire search space eligible for mutation\n",
    "scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"training_iteration\", hyperparam_mutations=space\n",
    ")\n",
    "\n",
    "# run trials with the PBT trainer\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"pbt\", num_samples=20, scheduler=scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d0c46",
   "metadata": {},
   "source": [
    "### Compare PBT and default experiment performance statistics\n",
    "\n",
    "Plot the PBT trial performance alongside the default AsyncHyperband results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70760bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe from default experiment\n",
    "pbt_table = results.get_dataframe()\n",
    "pbt_auc = np.array(pbt_table[\"mnist_auc\"])\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(-np.sort(-default_auc))\n",
    "ax1.plot(-np.sort(-pbt_auc))\n",
    "ax1.set_title(\"All trials\")\n",
    "ax1.set_xlabel(\"trial\")\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.legend([\"random\", \"population-based\"])\n",
    "ax2.plot(-np.sort(-default_auc)[0:5])\n",
    "ax2.plot(-np.sort(-pbt_auc)[0:5])\n",
    "ax2.set_title(\"Top 5 trials\")\n",
    "ax2.set_xlabel(\"trial\")\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.legend([\"random\", \"population-based\"])\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108775e7",
   "metadata": {},
   "source": [
    "### Change trial resources\n",
    "\n",
    "The `ray.air.ScalingConfig` determines the resources available during experiments, and can be used to set the number of workers and availability of GPUs. Additional parameters are available for running on multiple machine using a Ray cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a3111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# alter the scaling parameters so that each trial gets 2 cores\n",
    "tuner.set_scaling(\n",
    "    num_workers=1,\n",
    "    use_gpu=False,\n",
    "    resources_per_worker={\"CPU\": 2, \"GPU\": 0},\n",
    ")\n",
    "\n",
    "# run 10 trials with the PBT trainer\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(\n",
    "        local_dir=temp_dir.name, name=\"resources\", num_samples=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfefe22",
   "metadata": {},
   "source": [
    "### Reporting\n",
    "\n",
    "Reporting options can also be set by using `Search.set_reporter` method or by creating a reporter object and assigning this directly to the `Search.reporter` attribute. This allows use of additional parameters not exposed by `set_reporter`.\n",
    "\n",
    "Here we setup a CLI trainer with customized report columns and re-run an experiment. Since we are running in Jupyter, the dynamic table is also automatically displayed too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune import CLIReporter\n",
    "\n",
    "# report every 30 seconds\n",
    "max_report_frequency = 30\n",
    "\n",
    "# set Jupyter preference\n",
    "jupyter = False\n",
    "\n",
    "# set metrics, parameters to display\n",
    "metrics = [f\"{t}_{m}\" for t in space[\"tasks\"] for m in space[\"tasks\"][t][\"metrics\"]]\n",
    "parameters = {\n",
    "    \"optimization/method\": \"method\",\n",
    "    \"optimization/learning_rate\": \"learning rate\",\n",
    "    \"layer1/units\": \"layer1_units\",\n",
    "}\n",
    "\n",
    "# set reporter kwargs\n",
    "reporter_kwargs = {\n",
    "    \"metric_columns\": metrics,\n",
    "    \"parameter_columns\": parameters,\n",
    "    \"max_report_frequency\": max_report_frequency,\n",
    "}\n",
    "\n",
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# assign reporter to attribute and run a short trial\n",
    "tuner.reporter = CLIReporter(**reporter_kwargs)\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"try\", num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab9d8c",
   "metadata": {},
   "source": [
    "### Restarting an interrupted experiment\n",
    "\n",
    "We can restart an experiment that has been interrupted to complete unfinished trials using `Search.restore`.\n",
    "\n",
    "Interrupt the execution of this cell and then execute the cell below to complete the unexecuted trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Search object instance\n",
    "tuner = Search(space, builder, dataloader, \"mnist_auc\")\n",
    "\n",
    "# assign reporter to attribute and run a short trial\n",
    "tuner.reporter = CLIReporter(**reporter_kwargs)\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    results = tuner.experiment(local_dir=temp_dir.name, name=\"restore\", num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete trials\n",
    "with contextlib.redirect_stderr(open(os.devnull, \"w\")):\n",
    "    tuner.restore(local_dir=temp_dir.name + \"/restore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a0d53",
   "metadata": {},
   "source": [
    "### Cleanup storage\n",
    "\n",
    "Hyperparameter tuning experiments can consume a lot of storage. Take care when setting `local_dir` for more extensive runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de34731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the temporary directory\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
